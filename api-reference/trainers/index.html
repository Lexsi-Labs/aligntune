<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Comprehensive fine-tuning library for SFT and RL training with multi-backend support">
    <meta name="author" content="AlignTune Contributors">
    <link rel="canonical" href="https://aligntune.github.io/api-reference/trainers/">
    <link rel="shortcut icon" href="../../img/favicon.ico">

    
<title>Trainers - AlignTune</title>


    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../css/base.min.css" rel="stylesheet">
    <link href="../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    
    <link href="../../assets/_mkdocstrings.css" rel="stylesheet">
    <link href="../../assets/overrides.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

    
<!-- Favicons -->
<link rel="apple-touch-icon" sizes="180x180" href="../../assets/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../assets/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../assets/favicon-16x16.png">
<link rel="manifest" href="../../assets/site.webmanifest">
<link rel="shortcut icon" href="../../assets/favicon.ico">

<!-- Android Chrome Icons -->
<link rel="icon" type="image/png" sizes="192x192" href="../../assets/android-chrome-192x192.png">
<link rel="icon" type="image/png" sizes="512x512" href="../../assets/android-chrome-512x512.png">

 

</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
 <div class="container">

 <!-- Collapsed navigation -->
 <div class="navbar-header">
 <!-- Expander button -->
 <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
 <span class="sr-only">Toggle navigation</span>
 <span class="icon-bar"></span>
 <span class="icon-bar"></span>
 <span class="icon-bar"></span>
 </button>
 

 <!-- Main title -->

 
 <a class="navbar-brand" href="../..">AlignTune</a>
 
 </div>

 <!-- Expanded navigation -->
 <div class="navbar-collapse collapse">
 <!-- Main navigation -->
 <ul class="nav navbar-nav">
 
 
 <li class="dropdown">
 <a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started <b class="caret"></b></a>
 <ul class="dropdown-menu">
 
 
<li >
    <a href="../..">Home</a>
</li>

 
 
<li >
    <a href="../../getting-started/installation/">Installation</a>
</li>

 
 
<li >
    <a href="../../getting-started/quickstart/">Quick Start</a>
</li>

 
 
<li >
    <a href="../../getting-started/basic-concepts/">Basic Concepts</a>
</li>

 
 
<li >
    <a href="../../getting-started/configuration/">Configuration</a>
</li>

 
 
<li >
    <a href="../../getting-started/backend-selection/">Backend Selection</a>
</li>

 
 </ul>
 </li>
 
 
 
 <li class="dropdown">
 <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
 <ul class="dropdown-menu">
 
 
<li >
    <a href="../../user-guide/overview/">Overview</a>
</li>

 
 
<li >
    <a href="../../user-guide/sft/">Supervised Fine-Tuning (SFT)</a>
</li>

 
 
<li >
    <a href="../../user-guide/rl/">Reinforcement Learning (RL)</a>
</li>

 
 
<li >
    <a href="../../user-guide/reward-functions/">Reward Functions</a>
</li>

 
 
<li >
    <a href="../../user-guide/reward-model-training/">Reward Model Training</a>
</li>

 
 
<li >
    <a href="../../user-guide/evaluation/">Evaluation</a>
</li>

 
 
<li >
    <a href="../../user-guide/model-management/">Model Management</a>
</li>

 
 
<li >
    <a href="../../user-guide/sample-logging/">Sample Logging</a>
</li>

 
 
<li >
    <a href="../../user-guide/troubleshooting/">Troubleshooting</a>
</li>

 
 
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Algorithms</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../algorithms/overview/">Overview</a>
</li>

        
            
<li >
    <a href="../../algorithms/dpo/">DPO</a>
</li>

        
            
<li >
    <a href="../../algorithms/ppo/">PPO</a>
</li>

        
            
<li >
    <a href="../../algorithms/grpo/">GRPO</a>
</li>

        
            
<li >
    <a href="../../algorithms/gspo/">GSPO</a>
</li>

        
            
<li >
    <a href="../../algorithms/dapo/">DAPO</a>
</li>

        
            
<li >
    <a href="../../algorithms/dr-grpo/">Dr. GRPO</a>
</li>

        
    </ul>
  </li>

 
 
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Backends</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../backends/overview/">Overview</a>
</li>

        
            
<li >
    <a href="../../backends/trl/">TRL Backend</a>
</li>

        
            
<li >
    <a href="../../backends/unsloth/">Unsloth Backend</a>
</li>

        
            
<li >
    <a href="../../backends/comparison/">Comparison</a>
</li>

        
    </ul>
  </li>

 
 </ul>
 </li>
 
 
 
 <li class="dropdown">
 <a href="#" class="dropdown-toggle" data-toggle="dropdown">Advanced Topics <b class="caret"></b></a>
 <ul class="dropdown-menu">
 
 
<li >
    <a href="../../advanced/architecture/">Architecture</a>
</li>

 
 
<li >
    <a href="../../advanced/custom-backends.md">Custom Backends</a>
</li>

 
 
<li >
    <a href="../../advanced/distributed.md">Distributed Training</a>
</li>

 
 
<li >
    <a href="../../advanced/performance.md">Performance Optimization</a>
</li>

 
 </ul>
 </li>
 
 
 
 <li class="dropdown active">
 <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Reference <b class="caret"></b></a>
 <ul class="dropdown-menu">
 
 
<li >
    <a href="../overview/">Overview</a>
</li>

 
 
<li >
    <a href="../core/">Core API</a>
</li>

 
 
<li >
    <a href="../backend-factory/">Backend Factory</a>
</li>

 
 
<li >
    <a href="../configuration/">Configuration Classes</a>
</li>

 
 
<li class="active">
    <a href="./">Trainers</a>
</li>

 
 </ul>
 </li>
 
 
 
 <li class="dropdown">
 <a href="#" class="dropdown-toggle" data-toggle="dropdown">Examples <b class="caret"></b></a>
 <ul class="dropdown-menu">
 
 
<li >
    <a href="../../examples/overview/">Overview</a>
</li>

 
 
<li >
    <a href="../../examples/sft/">SFT Examples</a>
</li>

 
 
<li >
    <a href="../../examples/rl/">RL Examples</a>
</li>

 
 
<li >
    <a href="../../examples/advanced/">Advanced Examples</a>
</li>

 
 
<li >
    <a href="../../notebooks/">Notebooks</a>
</li>

 
 </ul>
 </li>
 
 
 
 <li class="dropdown">
 <a href="#" class="dropdown-toggle" data-toggle="dropdown">Project <b class="caret"></b></a>
 <ul class="dropdown-menu">
 
 
<li >
    <a href="../../cli-reference/">CLI Reference</a>
</li>

 
 
<li >
    <a href="../../cli/commands/">CLI Commands</a>
</li>

 
 
<li >
    <a href="../../cli/configuration/">CLI Configuration Files</a>
</li>

 
 
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Compatibility</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../unsloth_compatibility/">Unsloth Compatibility</a>
</li>

        
            
<li >
    <a href="../../compatibility/backend-matrix/">Backend Support Matrix</a>
</li>

        
    </ul>
  </li>

 
 
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Contributing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../contributing/guide/">Contributing Guide</a>
</li>

        
            
<li >
    <a href="../../contributing/code-style/">Code Style</a>
</li>

        
            
<li >
    <a href="../../contributing/testing/">Testing</a>
</li>

        
    </ul>
  </li>

 
 </ul>
 </li>
 
 
 </ul>

 <ul class="nav navbar-nav navbar-right">
 <li>
 <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
 <i class="fas fa-search"></i> Search
 </a>
 </li>
 <li >
 <a rel="prev" href="../configuration/">
 <i class="fas fa-arrow-left"></i> Previous
 </a>
 </li>
 <li >
 <a rel="next" href="../../examples/overview/">
 Next <i class="fas fa-arrow-right"></i>
 </a>
 </li>
 
 </ul>
 </div>
 </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#trainers-api-reference">Trainers API Reference</a></li>
            <li class="second-level"><a href="#base-trainers">Base Trainers</a></li>
                
                <li class="third-level"><a href="#trainerbase-rl">TrainerBase (RL)</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase">TrainerBase</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.__enter__">__enter__</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.__exit__">__exit__</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.__init__">__init__</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.cleanup">cleanup</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.get_next_batch">get_next_batch</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.get_sample_outputs">get_sample_outputs</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.load_checkpoint">load_checkpoint</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.on_eval">on_eval</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.on_step">on_step</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.predict">predict</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.push_to_hub">push_to_hub</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.save_checkpoint">save_checkpoint</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.setup_custom_evaluator">setup_custom_evaluator</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.train">train</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainerBase.train_step">train_step</a></li>
                <li class="third-level"><a href="#sfttrainerbase">SFTTrainerBase</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase">SFTTrainerBase</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.__init__">__init__</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.cleanup">cleanup</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.get_next_batch">get_next_batch</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.load_checkpoint">load_checkpoint</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.on_eval">on_eval</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.on_step">on_step</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.predict">predict</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.push_to_hub">push_to_hub</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.save_checkpoint">save_checkpoint</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.train">train</a></li>
                <li class="third-level"><a href="#core.sft.trainer_base.SFTTrainerBase.train_step">train_step</a></li>
                <li class="third-level"><a href="#trainingstate">TrainingState</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainingState">TrainingState</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainingState.get_elapsed_time">get_elapsed_time</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainingState.update_best_metric">update_best_metric</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainingState.update_epoch">update_epoch</a></li>
                <li class="third-level"><a href="#core.rl.trainer_base.TrainingState.update_step">update_step</a></li>
            <li class="second-level"><a href="#backend-trainers">Backend Trainers</a></li>
                
                <li class="third-level"><a href="#trl-backends">TRL Backends</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer">TRLSFTTrainer</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.cleanup">cleanup</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.generate_samples">generate_samples</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.get_sample_outputs">get_sample_outputs</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.get_training_stats">get_training_stats</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.run_experiment">run_experiment</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.run_zero_shot_evaluation">run_zero_shot_evaluation</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.save_config">save_config</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.trl.sft.sft.TRLSFTTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer">TRLDPOTrainer</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.__init__">__init__</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_dataset">setup_dataset</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer">TRLPPOTrainer</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.get_training_stats">get_training_stats</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.save_config">save_config</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer">TRLGRPOTrainer</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.get_training_stats">get_training_stats</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.save_config">save_config</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#unsloth-backends">Unsloth Backends</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer">UnslothSFTTrainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.generate_samples">generate_samples</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_dataset">setup_dataset</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer">UnslothDPOTrainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.__init__">__init__</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.generate_preference_samples">generate_preference_samples</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_dataset">setup_dataset</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer">UnslothPPOTrainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.train_step">train_step</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer">UnslothGRPOTrainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.create_data_loader">create_data_loader</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.is_available">is_available</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.load_model">load_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_dataset">setup_dataset</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_rewards">setup_rewards</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_trainer">setup_trainer</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.train">train</a></li>
                <li class="third-level"><a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.train_step">train_step</a></li>
            <li class="second-level"><a href="#specialized-trainers">Specialized Trainers</a></li>
                
                <li class="third-level"><a href="#classificationtrainer">ClassificationTrainer</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer">ClassificationTrainer</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.__init__">__init__</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.evaluate">evaluate</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.run_experiment">run_experiment</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.save_model">save_model</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_data">setup_data</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_model">setup_model</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_training">setup_training</a></li>
                <li class="third-level"><a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.train">train</a></li>
            <li class="second-level"><a href="#usage-examples">Usage Examples</a></li>
                
                <li class="third-level"><a href="#sft-training">SFT Training</a></li>
                <li class="third-level"><a href="#rl-training">RL Training</a></li>
            <li class="second-level"><a href="#next-steps">Next Steps</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="trainers-api-reference">Trainers API Reference<a class="headerlink" href="#trainers-api-reference" title="Permanent link">&para;</a></h1>
<p>Complete API reference for AlignTune trainer classes.</p>
<hr />
<h2 id="base-trainers">Base Trainers<a class="headerlink" href="#base-trainers" title="Permanent link">&para;</a></h2>
<h3 id="trainerbase-rl"><code>TrainerBase</code> (RL)<a class="headerlink" href="#trainerbase-rl" title="Permanent link">&para;</a></h3>
<p>Abstract base trainer for RL training with lifecycle management.</p>


<div class="doc doc-object doc-class">



<a id="core.rl.trainer_base.TrainerBase"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base trainer with lifecycle management.</p>
<p>All RLHF trainers should inherit from this class and implement
the abstract methods for model, data, and reward setup.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TrainerBase</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base trainer with lifecycle management.</span>

<span class="sd">    All RLHF trainers should inherit from this class and implement</span>
<span class="sd">    the abstract methods for model, data, and reward setup.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TrainerCallback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize trainer with configuration.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainingState</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">control</span> <span class="o">=</span> <span class="n">TrainerControl</span><span class="p">()</span>

        <span class="c1"># Initialize distributed backend</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">BackendFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">distributed</span><span class="p">)</span>

        <span class="c1"># Initialize logging (rank-0 only)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">UnifiedLogger</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">)</span>

        <span class="c1"># Initialize evaluator (rank-0 only)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">UnifiedEvaluator</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Training components (to be set by subclasses)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Setup callbacks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be initialized after model/tokenizer setup</span>

        <span class="c1"># Evaluation components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># To be set by subclasses</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">algo</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> algorithm&quot;</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup model, tokenizer, and optimization.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets and data loaders.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup reward functions and evaluators.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute single training step.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Main training loop with hooks.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>

        <span class="c1"># Setup phase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>

        <span class="c1"># CRITICAL FIX: Create data loader AFTER setup_data()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_data_loader</span><span class="p">()</span>

        <span class="c1"># Initialize callback handler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> 
            <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># RL trainers usually wrap optimizer internally</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>  <span class="c1"># Add self as callback for simple hooks</span>

        <span class="c1"># Call on_init_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_init_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Log initial configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Training loop</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
        <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Calculate steps from epochs</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either max_steps or epochs must be specified in training config&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training for </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2"> steps&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

            <span class="c1"># Get next batch</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_next_batch</span><span class="p">()</span>

            <span class="c1"># Execute training step</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># Update state</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_step</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

            <span class="c1"># Log metrics</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

            <span class="c1"># Hook for step operations</span>
            <span class="c1"># self.on_step(step, metrics) # Handled by callback_handler now</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

            <span class="c1"># Evaluation</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
                <span class="c1"># self.on_eval(eval_metrics) # Handled by callback_handler</span>

            <span class="c1"># Checkpointing</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training stopped by callback&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Final evaluation and checkpoint</span>
        <span class="n">final_eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
        <span class="c1"># self.on_eval(final_eval_metrics)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training completed&quot;</span><span class="p">)</span>


    <span class="c1"># def evaluate(</span>
    <span class="c1">#     self,</span>
    <span class="c1">#     eval_dataset=None,</span>
    <span class="c1">#     metric_key_prefix: str = &quot;eval&quot;,</span>
    <span class="c1">#     **kwargs</span>
    <span class="c1"># ) -&gt; Dict[str, float]:</span>
    <span class="c1">#     &quot;&quot;&quot;Run evaluation and return metrics.</span>

    <span class="c1">#     Args:</span>
    <span class="c1">#         eval_dataset: Dataset to evaluate on (defaults to validation set)</span>
    <span class="c1">#         metric_key_prefix: Prefix for metric keys</span>
    <span class="c1">#         **kwargs: Additional evaluation arguments</span>

    <span class="c1">#     Returns:</span>
    <span class="c1">#         Dictionary of evaluation metrics</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     if not self.backend.is_rank_0():</span>
    <span class="c1">#         return {}</span>

    <span class="c1">#     logger.info(&quot;Running evaluation...&quot;)</span>

    <span class="c1">#     # Use provided dataset or fall back to configured dataset</span>
    <span class="c1">#     dataset_to_use = eval_dataset if eval_dataset is not None else self.dataset</span>

    <span class="c1">#     if dataset_to_use is None:</span>
    <span class="c1">#         logger.warning(&quot;No evaluation dataset provided or configured&quot;)</span>
    <span class="c1">#         return {}</span>

    <span class="c1">#     eval_metrics = self.evaluator.evaluate(</span>
    <span class="c1">#         model=self.model,</span>
    <span class="c1">#         tokenizer=self.tokenizer,</span>
    <span class="c1">#         dataset=dataset_to_use,</span>
    <span class="c1">#         config=self.config,</span>
    <span class="c1">#         **kwargs</span>
    <span class="c1">#     )</span>

    <span class="c1">#     # Apply metric key prefix</span>
    <span class="c1">#     if metric_key_prefix:</span>
    <span class="c1">#         prefixed_metrics = {f&quot;{metric_key_prefix}/{k}&quot;: v for k, v in eval_metrics.items()}</span>
    <span class="c1">#         eval_metrics = prefixed_metrics</span>

    <span class="c1">#     # Log evaluation metrics</span>
    <span class="c1">#     self.logger.log_metrics(eval_metrics, self.state.step, prefix=&quot;eval/&quot;)</span>

    <span class="c1">#     self.callback_handler.on_evaluate(self.config, self.state, self.control, metrics=eval_metrics)</span>

    <span class="c1">#     # Update best metric</span>
    <span class="c1">#     accuracy_key = f&quot;{metric_key_prefix}/accuracy&quot; if metric_key_prefix else &quot;accuracy&quot;</span>
    <span class="c1">#     if accuracy_key in eval_metrics:</span>
    <span class="c1">#         improved = self.state.update_best_metric(eval_metrics[accuracy_key])</span>
    <span class="c1">#         if improved:</span>
    <span class="c1">#             logger.info(f&quot;New best metric: {eval_metrics[accuracy_key]:.4f}&quot;)</span>

    <span class="c1">#     return eval_metrics</span>

<span class="c1">#     def evaluate(</span>
<span class="c1">#         self,</span>
<span class="c1">#         eval_dataset=None,</span>
<span class="c1">#         metric_key_prefix: str = &quot;eval&quot;,</span>
<span class="c1">#         use_custom_evaluator: bool = False,</span>
<span class="c1">#         metrics: Optional[List] = None,</span>
<span class="c1">#         **kwargs</span>
<span class="c1">#     ) -&gt; Dict[str, float]:</span>
<span class="c1">#         &quot;&quot;&quot;Run evaluation and return metrics.</span>

<span class="c1">#         Args:</span>
<span class="c1">#             eval_dataset: Dataset to evaluate on (defaults to self.eval_dataset)</span>
<span class="c1">#             metric_key_prefix: Prefix for metric keys</span>
<span class="c1">#             use_custom_evaluator: If True, use BaseEvaluator/RLEvaluator. If False, use native.</span>
<span class="c1">#             metrics: Metrics to compute (only for custom evaluator, overrides setup)</span>
<span class="c1">#             **kwargs: Additional evaluation arguments (e.g., reference_model, reward_model for RL)</span>

<span class="c1">#         Returns:</span>
<span class="c1">#             Dictionary of evaluation metrics</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         if not self.backend.is_rank_0():</span>
<span class="c1">#             return {}</span>

<span class="c1">#         logger.info(&quot;Running evaluation...&quot;)</span>

<span class="c1">#         # Route to appropriate evaluator</span>
<span class="c1">#         if use_custom_evaluator:</span>
<span class="c1">#             eval_metrics = self._evaluate_with_custom(eval_dataset, metrics, **kwargs)</span>
<span class="c1">#         else:</span>
<span class="c1">#             eval_metrics = self._evaluate_native(eval_dataset, **kwargs)</span>

<span class="c1">#         # Apply metric key prefix</span>
<span class="c1">#         if metric_key_prefix and eval_metrics:</span>
<span class="c1">#             prefixed_metrics = {f&quot;{metric_key_prefix}/{k}&quot;: v for k, v in eval_metrics.items()}</span>
<span class="c1">#             eval_metrics = prefixed_metrics</span>

<span class="c1">#         # Log evaluation metrics</span>
<span class="c1">#         if eval_metrics:</span>
<span class="c1">#             self.logger.log_metrics(eval_metrics, self.state.step, prefix=&quot;eval/&quot;)</span>
<span class="c1">#             self.callback_handler.on_evaluate(self.config, self.state, self.control, metrics=eval_metrics)</span>

<span class="c1">#             # Update best metric</span>
<span class="c1">#             accuracy_key = f&quot;{metric_key_prefix}/accuracy&quot; if metric_key_prefix else &quot;accuracy&quot;</span>
<span class="c1">#             if accuracy_key in eval_metrics:</span>
<span class="c1">#                 improved = self.state.update_best_metric(eval_metrics[accuracy_key])</span>
<span class="c1">#                 if improved:</span>
<span class="c1">#                     logger.info(f&quot;New best metric: {eval_metrics[accuracy_key]:.4f}&quot;)</span>

<span class="c1">#         return eval_metrics</span>

<span class="c1">#     def _evaluate_with_custom(</span>
<span class="c1">#         self, </span>
<span class="c1">#         eval_dataset, </span>
<span class="c1">#         metrics: Optional[List],</span>
<span class="c1">#         **kwargs</span>
<span class="c1">#     ) -&gt; Dict[str, float]:</span>
<span class="c1">#         &quot;&quot;&quot;Evaluate using BaseEvaluator or RLEvaluator.&quot;&quot;&quot;</span>

<span class="c1">#         # Auto-setup if not configured</span>
<span class="c1">#         if self.custom_evaluator is None:</span>
<span class="c1">#             self.setup_custom_evaluator(evaluator_type=&quot;auto&quot;, metrics=metrics)</span>

<span class="c1">#         # Use provided dataset or fall back to configured dataset</span>
<span class="c1">#         dataset = eval_dataset or self.eval_dataset</span>

<span class="c1">#         if dataset is None:</span>
<span class="c1">#             logger.warning(&quot;No evaluation dataset provided or configured&quot;)</span>
<span class="c1">#             return {}</span>

<span class="c1">#         # RL Evaluation</span>
<span class="c1">#         if isinstance(self.custom_evaluator, RLEvaluator):</span>
<span class="c1">#             # Get reference model (defaults to policy model if not provided)</span>
<span class="c1">#             reference_model = kwargs.pop(&#39;reference_model&#39;, self.model)</span>
<span class="c1">#             reward_model = kwargs.pop(&#39;reward_model&#39;, None)</span>

<span class="c1">#             return self.custom_evaluator.evaluate_rl(</span>
<span class="c1">#                 policy_model=self.model,</span>
<span class="c1">#                 reference_model=reference_model,</span>
<span class="c1">#                 tokenizer=self.tokenizer,</span>
<span class="c1">#                 dataset=dataset,</span>
<span class="c1">#                 reward_model=reward_model,</span>
<span class="c1">#                 **kwargs</span>
<span class="c1">#             )</span>

<span class="c1">#         # Base Evaluation (SFT)</span>
<span class="c1">#         else:</span>
<span class="c1">#             task_name = kwargs.pop(&#39;task_name&#39;, &#39;text_generation&#39;)</span>
<span class="c1">#             return self.custom_evaluator.evaluate(</span>
<span class="c1">#                 model=self.model,</span>
<span class="c1">#                 tokenizer=self.tokenizer,</span>
<span class="c1">#                 dataset=dataset,</span>
<span class="c1">#                 task_name=task_name,</span>
<span class="c1">#                 **kwargs</span>
<span class="c1">#             )</span>

<span class="c1">#     def _evaluate_native(</span>
<span class="c1">#         self,</span>
<span class="c1">#         eval_dataset=None,</span>
<span class="c1">#         **kwargs</span>
<span class="c1">#     ) -&gt; Dict[str, float]:</span>
<span class="c1">#         &quot;&quot;&quot;Use UnifiedEvaluator (native evaluation).</span>

<span class="c1">#         Subclasses can override this to use their trainer-specific evaluation.</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         dataset = eval_dataset or self.eval_dataset</span>

<span class="c1">#         if dataset is None:</span>
<span class="c1">#             logger.warning(&quot;No evaluation dataset provided or configured&quot;)</span>
<span class="c1">#             return {}</span>

<span class="c1">#         return self.evaluator.evaluate(</span>
<span class="c1">#             model=self.model,</span>
<span class="c1">#             tokenizer=self.tokenizer,</span>
<span class="c1">#             dataset=dataset,</span>
<span class="c1">#             config=self.config,</span>
<span class="c1">#             **kwargs</span>
<span class="c1">#         )</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_custom_evaluator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">evaluator_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup custom evaluators (BaseEvaluator/RLEvaluator).</span>

<span class="sd">        Args:</span>
<span class="sd">            evaluator_type: &quot;base&quot;, &quot;rl&quot;, or &quot;auto&quot; (auto-detects based on algorithm)</span>
<span class="sd">            metrics: Optional list of metrics to use (overrides defaults)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> 
                <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="mi">4</span>
            <span class="p">)</span>

            <span class="c1"># Setup BaseEvaluator for text generation metrics</span>
            <span class="k">if</span> <span class="n">evaluator_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;base&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="o">=</span> <span class="n">BaseEvaluator</span><span class="p">(</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span> <span class="ow">or</span> <span class="p">[</span><span class="n">RougeMetric</span><span class="p">(),</span> <span class="n">BleuMetric</span><span class="p">(),</span><span class="n">PerplexityMetric</span><span class="p">()],</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">eval_batch_size</span><span class="p">,</span>
                    <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BaseEvaluator initialized (batch_size=</span><span class="si">{</span><span class="n">eval_batch_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Setup RLEvaluator for RL-specific metrics</span>
            <span class="k">if</span> <span class="n">evaluator_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;rl&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="o">=</span> <span class="n">RLEvaluator</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">eval_batch_size</span><span class="p">,</span>
                    <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RLEvaluator initialized (batch_size=</span><span class="si">{</span><span class="n">eval_batch_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not initialize custom evaluators: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_with_custom_evaluator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Custom evaluation using unified framework (BaseEvaluator + RLEvaluator).&quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No eval dataset available for custom evaluation&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="n">eval_results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># 1. BaseEvaluator: Text generation metrics (ROUGE, BLEU, Perplexity)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running BaseEvaluator for text generation metrics...&quot;</span><span class="p">)</span>
                <span class="n">base_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                    <span class="n">task_name</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;task_name&#39;</span><span class="p">,</span> <span class="s1">&#39;text_generation&#39;</span><span class="p">),</span>
                    <span class="n">max_samples</span><span class="o">=</span><span class="n">max_samples</span>
                <span class="p">)</span>
                <span class="n">eval_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">base_metrics</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BaseEvaluator completed: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">base_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BaseEvaluator failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;BaseEvaluator error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 2. RLEvaluator: RL-specific metrics (KL Divergence, Reward Accuracy)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running RLEvaluator for RL-specific metrics...&quot;</span><span class="p">)</span>

                <span class="c1"># Get reference model and reward model from kwargs or use defaults</span>
                <span class="n">reference_model</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;reference_model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
                <span class="n">reward_model</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;reward_model&#39;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_combined_reward_function&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

                <span class="c1"># Run RL evaluation</span>
                <span class="n">rl_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span><span class="o">.</span><span class="n">evaluate_rl</span><span class="p">(</span>
                    <span class="n">policy_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">reference_model</span><span class="o">=</span><span class="n">reference_model</span><span class="p">,</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                    <span class="n">reward_model</span><span class="o">=</span><span class="n">reward_model</span><span class="p">,</span>
                    <span class="n">max_samples</span><span class="o">=</span><span class="n">max_samples</span>
                <span class="p">)</span>
                <span class="n">eval_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">rl_metrics</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RLEvaluator completed: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">rl_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RLEvaluator failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;RLEvaluator error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">eval_results</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No evaluation metrics were computed successfully&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">eval_results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_native</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Native evaluation - uses UnifiedEvaluator or trainer&#39;s built-in evaluate.</span>

<span class="sd">        Subclasses can override this to use their trainer-specific evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span>

        <span class="k">if</span> <span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset provided or configured&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Try trainer&#39;s built-in evaluate first (if exists)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;trainer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;evaluate&#39;</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trainer evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Fallback to UnifiedEvaluator</span>
        <span class="c1"># return self.evaluator.evaluate(</span>
        <span class="c1">#     model=self.model,</span>
        <span class="c1">#     tokenizer=self.tokenizer,</span>
        <span class="c1">#     dataset=dataset,</span>
        <span class="c1">#     config=self.config,</span>
        <span class="c1">#     **kwargs</span>
        <span class="c1"># )</span>
        <span class="k">return</span> <span class="p">{}</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span><span class="p">,</span>
        <span class="n">use_custom_evaluator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the trained model with flexible evaluation strategies.</span>

<span class="sd">        Args:</span>
<span class="sd">            eval_dataset: Dataset to evaluate on (uses self.eval_dataset if None)</span>
<span class="sd">            metric_key_prefix: Prefix for metric names in results</span>
<span class="sd">            use_custom_evaluator: If True, use unified evaluation framework (BaseEvaluator + RLEvaluator)</span>
<span class="sd">                                 If False, use native TRL trainer evaluation</span>
<span class="sd">            metrics: Optional list of additional metrics to compute</span>
<span class="sd">            **kwargs: Additional arguments:</span>
<span class="sd">                - max_samples: Maximum number of samples to evaluate (default: 50)</span>
<span class="sd">                - compute_text_metrics: Force text generation metrics (ROUGE, BLEU)</span>
<span class="sd">                - compute_rl_metrics: Force RL metrics (KL, Reward Accuracy)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of evaluation metrics with the specified prefix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
            <span class="k">return</span> <span class="p">{}</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">CallbackHandler</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Initialized minimal callback handler for standalone evaluation&quot;</span><span class="p">)</span>


        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Evaluation&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Use custom evaluator: </span><span class="si">{</span><span class="n">use_custom_evaluator</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Metric prefix: </span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="n">eval_results</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Strategy 1: Use unified evaluation framework (BaseEvaluator + RLEvaluator)</span>
        <span class="k">if</span> <span class="n">use_custom_evaluator</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Custom evaluators not available, falling back to native evaluation&quot;</span><span class="p">)</span>
                <span class="n">use_custom_evaluator</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">custom_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_with_custom_evaluator</span><span class="p">(</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs</span>
                <span class="p">)</span>
                <span class="n">eval_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">custom_results</span><span class="p">)</span>

        <span class="c1"># Strategy 2: Use native evaluation (fallback or if custom disabled)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_custom_evaluator</span><span class="p">:</span>
            <span class="n">native_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_native</span><span class="p">(</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="n">eval_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">native_results</span><span class="p">)</span>

        <span class="c1"># Apply metric prefix to all keys</span>
        <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="ow">and</span> <span class="n">eval_results</span><span class="p">:</span>
            <span class="n">prefixed_results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">else</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">eval_results</span> <span class="o">=</span> <span class="n">prefixed_results</span>

        <span class="c1"># Log evaluation metrics</span>
        <span class="k">if</span> <span class="n">eval_results</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">eval_results</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;eval/&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_results</span><span class="p">)</span>

            <span class="c1"># Update best metric</span>
            <span class="n">accuracy_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/accuracy&quot;</span> <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="k">else</span> <span class="s2">&quot;accuracy&quot;</span>
            <span class="k">if</span> <span class="n">accuracy_key</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
                <span class="n">improved</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_best_metric</span><span class="p">(</span><span class="n">eval_results</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">improved</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New best metric: </span><span class="si">{</span><span class="n">eval_results</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Log summary</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Evaluation Results Summary&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_value</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eval_results</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">metric_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">metric_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">eval_results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save checkpoint (rank-0 only).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
            <span class="k">return</span>

        <span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;checkpoint-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">checkpoint_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving checkpoint to </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save model and tokenizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

        <span class="c1"># Save training state</span>
        <span class="n">state_path</span> <span class="o">=</span> <span class="n">checkpoint_dir</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span>
                <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span>
                <span class="s2">&quot;best_metric&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span><span class="p">,</span>
                <span class="s2">&quot;elapsed_time&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_elapsed_time</span><span class="p">()</span>
            <span class="p">},</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Save resolved configuration</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.config_loader</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConfigLoader</span>
        <span class="n">ConfigLoader</span><span class="o">.</span><span class="n">save_resolved_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint saved: </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load checkpoint and broadcast to all ranks.&quot;&quot;&quot;</span>
        <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">checkpoint_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint not found: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading checkpoint from </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span> <span class="o">/</span> <span class="s2">&quot;pytorch_model.bin&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

        <span class="c1"># Load training state</span>
        <span class="n">state_path</span> <span class="o">=</span> <span class="n">checkpoint_path</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
        <span class="k">if</span> <span class="n">state_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">state_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;best_metric&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

        <span class="c1"># Broadcast checkpoint path to all ranks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">broadcast_checkpoint_path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint loaded: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_next_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get next batch from data loader.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Data loader not initialized. Call setup_data() first.&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">StopIteration</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
            <span class="c1"># Restart data loader if exhausted or not an iterator</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_data_loader</span><span class="p">())</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create data loader (to be implemented by subclasses).&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Subclasses must implement create_data_loader&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hook for step-level operations.&quot;&quot;&quot;</span>
        <span class="c1"># Log sample outputs periodically</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_sample_outputs</span><span class="p">(),</span> <span class="n">step</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hook for evaluation operations.&quot;&quot;&quot;</span>
        <span class="c1"># Update learning rate scheduler if needed</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scheduler&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_sample_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get sample outputs for logging (to be implemented by subclasses).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">push_to_hub</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">private</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">commit_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Upload fine-tuned model&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Push model to HuggingFace Hub.</span>

<span class="sd">        Args:</span>
<span class="sd">            repo_id: Repository ID on HuggingFace Hub (e.g., &#39;username/model-name&#39;)</span>
<span class="sd">            private: Whether the repository should be private</span>
<span class="sd">            token: HuggingFace token (if not provided, uses logged-in token)</span>
<span class="sd">            commit_message: Commit message for the upload</span>
<span class="sd">            **kwargs: Additional arguments for upload_folder</span>

<span class="sd">        Returns:</span>
<span class="sd">            URL of the uploaded repository</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">            ImportError: If huggingface_hub not installed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;push_to_hub should only be called on rank 0&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="s2">&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfApi</span><span class="p">,</span> <span class="n">login</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;huggingface_hub is required for push_to_hub. &quot;</span>
                <span class="s2">&quot;Install with: pip install huggingface_hub&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Login if token provided</span>
        <span class="k">if</span> <span class="n">token</span><span class="p">:</span>
            <span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>

        <span class="c1"># Save model first (if not already saved)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_last_save_path&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;save_model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Fallback: save to temp directory</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span>

        <span class="c1"># Push to hub</span>
        <span class="n">api</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">()</span>
        <span class="n">api</span><span class="o">.</span><span class="n">upload_folder</span><span class="p">(</span>
            <span class="n">folder_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
            <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
            <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
            <span class="n">private</span><span class="o">=</span><span class="n">private</span><span class="p">,</span>
            <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

        <span class="n">repo_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://huggingface.co/</span><span class="si">{</span><span class="n">repo_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model pushed to </span><span class="si">{</span><span class="n">repo_url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">repo_url</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate predictions from trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: Input text(s) to generate from</span>
<span class="sd">            max_new_tokens: Maximum number of tokens to generate</span>
<span class="sd">            temperature: Sampling temperature (higher = more random)</span>
<span class="sd">            top_p: Nucleus sampling parameter</span>
<span class="sd">            do_sample: Whether to use sampling</span>
<span class="sd">            **kwargs: Additional generation arguments</span>

<span class="sd">        Returns:</span>
<span class="sd">            Generated text(s) - single string if input was string, list if input was list</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;predict should only be called on rank 0&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="n">is_single</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_single</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>

        <span class="c1"># Tokenize</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Move to device</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="c1"># Generate</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="o">**</span><span class="n">tokenized</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
                <span class="n">do_sample</span><span class="o">=</span><span class="n">do_sample</span><span class="p">,</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="n">eos_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="c1"># Decode</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Remove input prefix from predictions</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">prediction</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If input wasn&#39;t at start, just return the full prediction</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single</span> <span class="k">else</span> <span class="n">predictions</span>

    <span class="c1"># TrainerCallback methods (can be overridden by subclasses if needed)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_init_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Original hook call</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Original hook call</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cleanup resources.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;backend&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Trainer cleanup completed&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager entry.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Context manager exit.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">exc_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training failed with </span><span class="si">{</span><span class="n">exc_type</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">exc_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.__enter__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__enter__</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.__enter__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Context manager entry.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Context manager entry.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.__exit__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__exit__</span><span class="p">(</span><span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.__exit__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Context manager exit.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Context manager exit.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">exc_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training failed with </span><span class="si">{</span><span class="n">exc_type</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">exc_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize trainer with configuration.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TrainerCallback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize trainer with configuration.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainingState</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">control</span> <span class="o">=</span> <span class="n">TrainerControl</span><span class="p">()</span>

    <span class="c1"># Initialize distributed backend</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">BackendFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">distributed</span><span class="p">)</span>

    <span class="c1"># Initialize logging (rank-0 only)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">UnifiedLogger</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">)</span>

    <span class="c1"># Initialize evaluator (rank-0 only)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">UnifiedEvaluator</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Training components (to be set by subclasses)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Setup callbacks</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be initialized after model/tokenizer setup</span>

    <span class="c1"># Evaluation components</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># To be set by subclasses</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">algo</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> algorithm&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.cleanup" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">cleanup</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.cleanup" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Cleanup resources.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup resources.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;backend&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Trainer cleanup completed&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create data loader (to be implemented by subclasses).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create data loader (to be implemented by subclasses).&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Subclasses must implement create_data_loader&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="n">use_custom_evaluator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Evaluate the trained model with flexible evaluation strategies.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>eval_dataset</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataset to evaluate on (uses self.eval_dataset if None)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric_key_prefix</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prefix for metric names in results</p>
              </div>
            </td>
            <td>
                  <code>&#39;eval&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_custom_evaluator</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use unified evaluation framework (BaseEvaluator + RLEvaluator)
                 If False, use native TRL trainer evaluation</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metrics</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional list of additional metrics to compute</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments:
- max_samples: Maximum number of samples to evaluate (default: 50)
- compute_text_metrics: Force text generation metrics (ROUGE, BLEU)
- compute_rl_metrics: Force RL metrics (KL, Reward Accuracy)</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary of evaluation metrics with the specified prefix</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span><span class="p">,</span>
    <span class="n">use_custom_evaluator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the trained model with flexible evaluation strategies.</span>

<span class="sd">    Args:</span>
<span class="sd">        eval_dataset: Dataset to evaluate on (uses self.eval_dataset if None)</span>
<span class="sd">        metric_key_prefix: Prefix for metric names in results</span>
<span class="sd">        use_custom_evaluator: If True, use unified evaluation framework (BaseEvaluator + RLEvaluator)</span>
<span class="sd">                             If False, use native TRL trainer evaluation</span>
<span class="sd">        metrics: Optional list of additional metrics to compute</span>
<span class="sd">        **kwargs: Additional arguments:</span>
<span class="sd">            - max_samples: Maximum number of samples to evaluate (default: 50)</span>
<span class="sd">            - compute_text_metrics: Force text generation metrics (ROUGE, BLEU)</span>
<span class="sd">            - compute_rl_metrics: Force RL metrics (KL, Reward Accuracy)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dictionary of evaluation metrics with the specified prefix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">{}</span>


    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">CallbackHandler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Initialized minimal callback handler for standalone evaluation&quot;</span><span class="p">)</span>


    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Evaluation&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Use custom evaluator: </span><span class="si">{</span><span class="n">use_custom_evaluator</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Metric prefix: </span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="n">eval_results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Strategy 1: Use unified evaluation framework (BaseEvaluator + RLEvaluator)</span>
    <span class="k">if</span> <span class="n">use_custom_evaluator</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Custom evaluators not available, falling back to native evaluation&quot;</span><span class="p">)</span>
            <span class="n">use_custom_evaluator</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">custom_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_with_custom_evaluator</span><span class="p">(</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="n">eval_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">custom_results</span><span class="p">)</span>

    <span class="c1"># Strategy 2: Use native evaluation (fallback or if custom disabled)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">use_custom_evaluator</span><span class="p">:</span>
        <span class="n">native_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_native</span><span class="p">(</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="n">eval_results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">native_results</span><span class="p">)</span>

    <span class="c1"># Apply metric prefix to all keys</span>
    <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="ow">and</span> <span class="n">eval_results</span><span class="p">:</span>
        <span class="n">prefixed_results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">else</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">eval_results</span> <span class="o">=</span> <span class="n">prefixed_results</span>

    <span class="c1"># Log evaluation metrics</span>
    <span class="k">if</span> <span class="n">eval_results</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">eval_results</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;eval/&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_results</span><span class="p">)</span>

        <span class="c1"># Update best metric</span>
        <span class="n">accuracy_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/accuracy&quot;</span> <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="k">else</span> <span class="s2">&quot;accuracy&quot;</span>
        <span class="k">if</span> <span class="n">accuracy_key</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
            <span class="n">improved</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_best_metric</span><span class="p">(</span><span class="n">eval_results</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">improved</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New best metric: </span><span class="si">{</span><span class="n">eval_results</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Log summary</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Evaluation Results Summary&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_value</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eval_results</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">metric_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">metric_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">eval_results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.get_next_batch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_next_batch</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.get_next_batch" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get next batch from data loader.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_next_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get next batch from data loader.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Data loader not initialized. Call setup_data() first.&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">StopIteration</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="c1"># Restart data loader if exhausted or not an iterator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_data_loader</span><span class="p">())</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.get_sample_outputs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_sample_outputs</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.get_sample_outputs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get sample outputs for logging (to be implemented by subclasses).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_sample_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get sample outputs for logging (to be implemented by subclasses).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.load_checkpoint" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.load_checkpoint" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load checkpoint and broadcast to all ranks.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load checkpoint and broadcast to all ranks.&quot;&quot;&quot;</span>
    <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">checkpoint_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint not found: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading checkpoint from </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Load model and tokenizer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span> <span class="o">/</span> <span class="s2">&quot;pytorch_model.bin&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

    <span class="c1"># Load training state</span>
    <span class="n">state_path</span> <span class="o">=</span> <span class="n">checkpoint_path</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
    <span class="k">if</span> <span class="n">state_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">state_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;best_metric&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># Broadcast checkpoint path to all ranks</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">broadcast_checkpoint_path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">))</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint loaded: </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.on_eval" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">on_eval</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.on_eval" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Hook for evaluation operations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">on_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hook for evaluation operations.&quot;&quot;&quot;</span>
    <span class="c1"># Update learning rate scheduler if needed</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;scheduler&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.on_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">on_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.on_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Hook for step-level operations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hook for step-level operations.&quot;&quot;&quot;</span>
    <span class="c1"># Log sample outputs periodically</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_sample_outputs</span><span class="p">(),</span> <span class="n">step</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.predict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.predict" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate predictions from trained model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text(s) to generate from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_new_tokens</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of tokens to generate</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>temperature</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling temperature (higher = more random)</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>top_p</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Nucleus sampling parameter</p>
              </div>
            </td>
            <td>
                  <code>0.9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_sample</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use sampling</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional generation arguments</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generated text(s) - single string if input was string, list if input was list</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="RuntimeError">RuntimeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If model or tokenizer not loaded</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate predictions from trained model.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: Input text(s) to generate from</span>
<span class="sd">        max_new_tokens: Maximum number of tokens to generate</span>
<span class="sd">        temperature: Sampling temperature (higher = more random)</span>
<span class="sd">        top_p: Nucleus sampling parameter</span>
<span class="sd">        do_sample: Whether to use sampling</span>
<span class="sd">        **kwargs: Additional generation arguments</span>

<span class="sd">    Returns:</span>
<span class="sd">        Generated text(s) - single string if input was string, list if input was list</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;predict should only be called on rank 0&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">is_single</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_single</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>

    <span class="c1"># Tokenize</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Move to device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="c1"># Generate</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="o">**</span><span class="n">tokenized</span><span class="p">,</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
            <span class="n">do_sample</span><span class="o">=</span><span class="n">do_sample</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
            <span class="n">eos_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="c1"># Decode</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Remove input prefix from predictions</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">prediction</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If input wasn&#39;t at start, just return the full prediction</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single</span> <span class="k">else</span> <span class="n">predictions</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.push_to_hub" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">push_to_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">private</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">commit_message</span><span class="o">=</span><span class="s1">&#39;Upload fine-tuned model&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.push_to_hub" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Push model to HuggingFace Hub.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>repo_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Repository ID on HuggingFace Hub (e.g., 'username/model-name')</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>private</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether the repository should be private</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>HuggingFace token (if not provided, uses logged-in token)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>commit_message</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Commit message for the upload</p>
              </div>
            </td>
            <td>
                  <code>&#39;Upload fine-tuned model&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments for upload_folder</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>URL of the uploaded repository</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="RuntimeError">RuntimeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If model or tokenizer not loaded</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ImportError">ImportError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If huggingface_hub not installed</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">push_to_hub</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">private</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">commit_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Upload fine-tuned model&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Push model to HuggingFace Hub.</span>

<span class="sd">    Args:</span>
<span class="sd">        repo_id: Repository ID on HuggingFace Hub (e.g., &#39;username/model-name&#39;)</span>
<span class="sd">        private: Whether the repository should be private</span>
<span class="sd">        token: HuggingFace token (if not provided, uses logged-in token)</span>
<span class="sd">        commit_message: Commit message for the upload</span>
<span class="sd">        **kwargs: Additional arguments for upload_folder</span>

<span class="sd">    Returns:</span>
<span class="sd">        URL of the uploaded repository</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">        ImportError: If huggingface_hub not installed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;push_to_hub should only be called on rank 0&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfApi</span><span class="p">,</span> <span class="n">login</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="s2">&quot;huggingface_hub is required for push_to_hub. &quot;</span>
            <span class="s2">&quot;Install with: pip install huggingface_hub&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Login if token provided</span>
    <span class="k">if</span> <span class="n">token</span><span class="p">:</span>
        <span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>

    <span class="c1"># Save model first (if not already saved)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_last_save_path&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;save_model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Fallback: save to temp directory</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span>

    <span class="c1"># Push to hub</span>
    <span class="n">api</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">()</span>
    <span class="n">api</span><span class="o">.</span><span class="n">upload_folder</span><span class="p">(</span>
        <span class="n">folder_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
        <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">private</span><span class="o">=</span><span class="n">private</span><span class="p">,</span>
        <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>

    <span class="n">repo_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://huggingface.co/</span><span class="si">{</span><span class="n">repo_id</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model pushed to </span><span class="si">{</span><span class="n">repo_url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">repo_url</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.save_checkpoint" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_checkpoint</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.save_checkpoint" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save checkpoint (rank-0 only).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save checkpoint (rank-0 only).&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
        <span class="k">return</span>

    <span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;checkpoint-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">checkpoint_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving checkpoint to </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Save model and tokenizer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

    <span class="c1"># Save training state</span>
    <span class="n">state_path</span> <span class="o">=</span> <span class="n">checkpoint_dir</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span>
            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;best_metric&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span><span class="p">,</span>
            <span class="s2">&quot;elapsed_time&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_elapsed_time</span><span class="p">()</span>
        <span class="p">},</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Save resolved configuration</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">.config_loader</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConfigLoader</span>
    <span class="n">ConfigLoader</span><span class="o">.</span><span class="n">save_resolved_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint saved: </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.setup_custom_evaluator" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_custom_evaluator</span><span class="p">(</span><span class="n">evaluator_type</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainerBase.setup_custom_evaluator" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup custom evaluators (BaseEvaluator/RLEvaluator).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>evaluator_type</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"base", "rl", or "auto" (auto-detects based on algorithm)</p>
              </div>
            </td>
            <td>
                  <code>&#39;auto&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metrics</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional list of metrics to use (overrides defaults)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_custom_evaluator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">evaluator_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup custom evaluators (BaseEvaluator/RLEvaluator).</span>

<span class="sd">    Args:</span>
<span class="sd">        evaluator_type: &quot;base&quot;, &quot;rl&quot;, or &quot;auto&quot; (auto-detects based on algorithm)</span>
<span class="sd">        metrics: Optional list of metrics to use (overrides defaults)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> 
            <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> 
            <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">4</span>
        <span class="p">)</span>

        <span class="c1"># Setup BaseEvaluator for text generation metrics</span>
        <span class="k">if</span> <span class="n">evaluator_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;base&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="o">=</span> <span class="n">BaseEvaluator</span><span class="p">(</span>
                <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span> <span class="ow">or</span> <span class="p">[</span><span class="n">RougeMetric</span><span class="p">(),</span> <span class="n">BleuMetric</span><span class="p">(),</span><span class="n">PerplexityMetric</span><span class="p">()],</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">eval_batch_size</span><span class="p">,</span>
                <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BaseEvaluator initialized (batch_size=</span><span class="si">{</span><span class="n">eval_batch_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Setup RLEvaluator for RL-specific metrics</span>
        <span class="k">if</span> <span class="n">evaluator_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;rl&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="o">=</span> <span class="n">RLEvaluator</span><span class="p">(</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">eval_batch_size</span><span class="p">,</span>
                <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RLEvaluator initialized (batch_size=</span><span class="si">{</span><span class="n">eval_batch_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not initialize custom evaluators: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.rl.trainer_base.TrainerBase.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets and data loaders.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets and data loaders.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.rl.trainer_base.TrainerBase.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup model, tokenizer, and optimization.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup model, tokenizer, and optimization.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.rl.trainer_base.TrainerBase.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup reward functions and evaluators.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup reward functions and evaluators.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainerBase.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Main training loop with hooks.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Main training loop with hooks.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>

    <span class="c1"># Setup phase</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>

    <span class="c1"># CRITICAL FIX: Create data loader AFTER setup_data()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_data_loader</span><span class="p">()</span>

    <span class="c1"># Initialize callback handler</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> 
        <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># RL trainers usually wrap optimizer internally</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>  <span class="c1"># Add self as callback for simple hooks</span>

    <span class="c1"># Call on_init_end</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_init_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="c1"># Log initial configuration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
    <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Calculate steps from epochs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either max_steps or epochs must be specified in training config&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training for </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2"> steps&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Get next batch</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_next_batch</span><span class="p">()</span>

        <span class="c1"># Execute training step</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># Update state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_step</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

        <span class="c1"># Hook for step operations</span>
        <span class="c1"># self.on_step(step, metrics) # Handled by callback_handler now</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Evaluation</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
            <span class="c1"># self.on_eval(eval_metrics) # Handled by callback_handler</span>

        <span class="c1"># Checkpointing</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training stopped by callback&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="c1"># Final evaluation and checkpoint</span>
    <span class="n">final_eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
    <span class="c1"># self.on_eval(final_eval_metrics)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training completed&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainerBase.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.rl.trainer_base.TrainerBase.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute single training step.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute single training step.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Example</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.rl.trainer_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainerBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.rl.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnifiedConfig</span>

<span class="c1"># TrainerBase is abstract - use concrete implementations</span>
<span class="c1"># See Backend Trainers below</span>
</code></pre></div>
<h3 id="sfttrainerbase"><code>SFTTrainerBase</code><a class="headerlink" href="#sfttrainerbase" title="Permanent link">&para;</a></h3>
<p>Abstract base trainer for SFT training with lifecycle management.</p>


<div class="doc doc-object doc-class">



<a id="core.sft.trainer_base.SFTTrainerBase"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base trainer with lifecycle management.</p>
<p>All SFT trainers should inherit from this class and implement
the abstract methods for model, data, and training setup.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SFTTrainerBase</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base trainer with lifecycle management.</span>

<span class="sd">    All SFT trainers should inherit from this class and implement</span>
<span class="sd">    the abstract methods for model, data, and training setup.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TrainerCallback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize trainer with configuration.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainingState</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">control</span> <span class="o">=</span> <span class="n">TrainerControl</span><span class="p">()</span>

        <span class="c1"># Initialize logging</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">SFTLogger</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">)</span>

        <span class="c1"># Initialize evaluator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">SFTEvaluator</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Training components (to be set by subclasses)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Setup callbacks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be initialized after model/tokenizer setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># ADD THIS LINE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># ADD THIS LINE</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> task&quot;</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup model, tokenizer, and optimization.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets and data loaders.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute single training step.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Main training loop with hooks.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting SFT training...&quot;</span><span class="p">)</span>

        <span class="c1"># Setup phase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>

        <span class="c1"># Initialize callback handler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> 
            <span class="n">optimizer</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;optimizer&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>  <span class="c1"># Add self as callback for simple hooks</span>

        <span class="c1"># Call on_init_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_init_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Log initial configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Training loop</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
        <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Calculate steps from epochs</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training for </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2"> steps&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

            <span class="c1"># Get next batch</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_next_batch</span><span class="p">()</span>

            <span class="c1"># Execute training step</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># Update state</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_step</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

            <span class="c1"># Log metrics</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

            <span class="c1"># Hook for step operations</span>
            <span class="c1"># self.on_step(step, metrics) # Handled by callback_handler now</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

            <span class="c1"># Evaluation</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
                <span class="c1"># self.on_eval(eval_metrics) # Handled by callback_handler</span>

            <span class="c1"># Checkpointing</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training stopped by callback&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Final evaluation and checkpoint</span>
        <span class="n">final_eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
        <span class="c1"># self.on_eval(final_eval_metrics)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SFT training completed&quot;</span><span class="p">)</span>

    <span class="c1"># def evaluate(</span>
    <span class="c1">#     self,</span>
    <span class="c1">#     eval_dataset=None,</span>
    <span class="c1">#     metric_key_prefix: str = &quot;eval&quot;,</span>
    <span class="c1">#     **kwargs</span>
    <span class="c1"># ) -&gt; Dict[str, float]:</span>
    <span class="c1">#     &quot;&quot;&quot;Run evaluation and return metrics.</span>

    <span class="c1">#     Args:</span>
    <span class="c1">#         eval_dataset: Dataset to evaluate on (defaults to validation set)</span>
    <span class="c1">#         metric_key_prefix: Prefix for metric keys</span>
    <span class="c1">#         **kwargs: Additional evaluation arguments</span>

    <span class="c1">#     Returns:</span>
    <span class="c1">#         Dictionary of evaluation metrics</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     logger.info(&quot;Running evaluation...&quot;)</span>

    <span class="c1">#     # Use provided dataset or fall back to configured dataset</span>
    <span class="c1">#     dataset_to_use = eval_dataset if eval_dataset is not None else self.dataset</span>

    <span class="c1">#     if dataset_to_use is None:</span>
    <span class="c1">#         logger.warning(&quot;No evaluation dataset provided or configured&quot;)</span>
    <span class="c1">#         return {}</span>

    <span class="c1">#     eval_metrics = self.evaluator.evaluate(</span>
    <span class="c1">#         model=self.model,</span>
    <span class="c1">#         tokenizer=self.tokenizer,</span>
    <span class="c1">#         dataset=dataset_to_use,</span>
    <span class="c1">#         config=self.config,</span>
    <span class="c1">#         **kwargs</span>
    <span class="c1">#     )</span>

    <span class="c1">#     # Apply metric key prefix</span>
    <span class="c1">#     if metric_key_prefix:</span>
    <span class="c1">#         prefixed_metrics = {f&quot;{metric_key_prefix}/{k}&quot;: v for k, v in eval_metrics.items()}</span>
    <span class="c1">#         eval_metrics = prefixed_metrics</span>

    <span class="c1">#     # Log evaluation metrics</span>
    <span class="c1">#     self.logger.log_metrics(eval_metrics, self.state.step, prefix=&quot;eval/&quot;)</span>

    <span class="c1">#     self.callback_handler.on_evaluate(self.config, self.state, self.control, metrics=eval_metrics)</span>

    <span class="c1">#     # Update best metric</span>
    <span class="c1">#     accuracy_key = f&quot;{metric_key_prefix}/accuracy&quot; if metric_key_prefix else &quot;accuracy&quot;</span>
    <span class="c1">#     if accuracy_key in eval_metrics:</span>
    <span class="c1">#         improved = self.state.update_best_metric(eval_metrics[accuracy_key])</span>
    <span class="c1">#         if improved:</span>
    <span class="c1">#             logger.info(f&quot;New best metric: {eval_metrics[accuracy_key]:.4f}&quot;)</span>

    <span class="c1">#     return eval_metrics</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span><span class="p">,</span>
        <span class="n">use_custom_evaluator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run evaluation and return metrics.</span>

<span class="sd">        Args:</span>
<span class="sd">            eval_dataset: Dataset to evaluate on (defaults to self.eval_dataset)</span>
<span class="sd">            metric_key_prefix: Prefix for metric keys</span>
<span class="sd">            use_custom_evaluator: If True, use BaseEvaluator. If False, use native SFTEvaluator.</span>
<span class="sd">            metrics: Metrics to compute (only for custom evaluator, overrides setup)</span>
<span class="sd">            **kwargs: Additional evaluation arguments</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of evaluation metrics</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running evaluation...&quot;</span><span class="p">)</span>

        <span class="c1"># Route to appropriate evaluator</span>
        <span class="k">if</span> <span class="n">use_custom_evaluator</span><span class="p">:</span>
            <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_with_custom</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_native</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Apply metric key prefix</span>
        <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="ow">and</span> <span class="n">eval_metrics</span><span class="p">:</span>
            <span class="n">prefixed_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">eval_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="n">eval_metrics</span> <span class="o">=</span> <span class="n">prefixed_metrics</span>

        <span class="c1"># Log evaluation metrics</span>
        <span class="k">if</span> <span class="n">eval_metrics</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;eval/&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">)</span>

            <span class="c1"># Update best metric</span>
            <span class="n">accuracy_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/accuracy&quot;</span> <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="k">else</span> <span class="s2">&quot;accuracy&quot;</span>
            <span class="k">if</span> <span class="n">accuracy_key</span> <span class="ow">in</span> <span class="n">eval_metrics</span><span class="p">:</span>
                <span class="n">improved</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_best_metric</span><span class="p">(</span><span class="n">eval_metrics</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">improved</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New best metric: </span><span class="si">{</span><span class="n">eval_metrics</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">eval_metrics</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_with_custom</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">eval_dataset</span><span class="p">,</span> 
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate using BaseEvaluator (SFT only - no RL metrics).&quot;&quot;&quot;</span>

        <span class="c1"># Auto-setup if not configured</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_custom_evaluator</span><span class="p">(</span><span class="n">evaluator_type</span><span class="o">=</span><span class="s2">&quot;base&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

        <span class="c1"># Use provided dataset or fall back to configured dataset</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span>

        <span class="k">if</span> <span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset provided or configured&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Base Evaluation (SFT)</span>
        <span class="n">task_name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;task_name&#39;</span><span class="p">,</span> <span class="s1">&#39;text_generation&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">task_name</span><span class="o">=</span><span class="n">task_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_native</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Use SFTEvaluator (native evaluation).&quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span>

        <span class="k">if</span> <span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset provided or configured&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save checkpoint.&quot;&quot;&quot;</span>
        <span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;checkpoint-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">checkpoint_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving checkpoint to </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save model and tokenizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

        <span class="c1"># Save training state</span>
        <span class="n">state_path</span> <span class="o">=</span> <span class="n">checkpoint_dir</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span>
                <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span>
                <span class="s2">&quot;best_metric&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span><span class="p">,</span>
                <span class="s2">&quot;start_time&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">start_time</span>
            <span class="p">},</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">last_save_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load checkpoint.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading checkpoint from </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

        <span class="c1"># Load training state</span>
        <span class="n">state_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
        <span class="k">if</span> <span class="n">state_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">state_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;best_metric&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;start_time&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_next_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get next batch from data loader.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Data loader not initialized. Call setup_data() first.&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">StopIteration</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
            <span class="c1"># Restart data loader</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_data_loader</span><span class="p">())</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create data loader - to be implemented by subclasses.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Subclasses must implement create_data_loader&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hook called after each training step.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hook called after each evaluation.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">push_to_hub</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">private</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">commit_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Upload fine-tuned model&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Push model to HuggingFace Hub.</span>

<span class="sd">        Args:</span>
<span class="sd">            repo_id: Repository ID on HuggingFace Hub (e.g., &#39;username/model-name&#39;)</span>
<span class="sd">            private: Whether the repository should be private</span>
<span class="sd">            token: HuggingFace token (if not provided, uses logged-in token)</span>
<span class="sd">            commit_message: Commit message for the upload</span>
<span class="sd">            **kwargs: Additional arguments for upload_folder</span>

<span class="sd">        Returns:</span>
<span class="sd">            URL of the uploaded repository</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">            ImportError: If huggingface_hub not installed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfApi</span><span class="p">,</span> <span class="n">login</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;huggingface_hub is required for push_to_hub. &quot;</span>
                <span class="s2">&quot;Install with: pip install huggingface_hub&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Login if token provided</span>
        <span class="k">if</span> <span class="n">token</span><span class="p">:</span>
            <span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>

        <span class="c1"># Save model first (if not already saved)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_last_save_path&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;save_model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Fallback: save to temp directory</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span>

        <span class="c1"># Push to hub</span>
        <span class="n">api</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">()</span>
        <span class="n">api</span><span class="o">.</span><span class="n">upload_folder</span><span class="p">(</span>
            <span class="n">folder_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
            <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
            <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
            <span class="n">private</span><span class="o">=</span><span class="n">private</span><span class="p">,</span>
            <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

        <span class="n">repo_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://huggingface.co/</span><span class="si">{</span><span class="n">repo_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model pushed to </span><span class="si">{</span><span class="n">repo_url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">repo_url</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate predictions from trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: Input text(s) to generate from</span>
<span class="sd">            max_new_tokens: Maximum number of tokens to generate</span>
<span class="sd">            temperature: Sampling temperature (higher = more random)</span>
<span class="sd">            top_p: Nucleus sampling parameter</span>
<span class="sd">            do_sample: Whether to use sampling</span>
<span class="sd">            **kwargs: Additional generation arguments</span>

<span class="sd">        Returns:</span>
<span class="sd">            Generated text(s) - single string if input was string, list if input was list</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span>
            <span class="p">)</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="n">is_single</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_single</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>

        <span class="c1"># Tokenize</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Move to device</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="c1"># Generate</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="o">**</span><span class="n">tokenized</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
                <span class="n">do_sample</span><span class="o">=</span><span class="n">do_sample</span><span class="p">,</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="n">eos_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="c1"># Decode</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Remove input prefix from predictions</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">prediction</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If input wasn&#39;t at start, just return the full prediction</span>
                <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single</span> <span class="k">else</span> <span class="n">predictions</span>

    <span class="c1"># TrainerCallback methods (can be overridden by subclasses if needed)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_init_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Original hook call</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Original hook call</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cleanup resources.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize trainer with configuration.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TrainerCallback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize trainer with configuration.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainingState</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">control</span> <span class="o">=</span> <span class="n">TrainerControl</span><span class="p">()</span>

    <span class="c1"># Initialize logging</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">SFTLogger</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">)</span>

    <span class="c1"># Initialize evaluator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">SFTEvaluator</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Training components (to be set by subclasses)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Setup callbacks</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be initialized after model/tokenizer setup</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># ADD THIS LINE</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># ADD THIS LINE</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> task&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.cleanup" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">cleanup</span><span class="p">()</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.cleanup" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Cleanup resources.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup resources.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create data loader - to be implemented by subclasses.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create data loader - to be implemented by subclasses.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Subclasses must implement create_data_loader&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="n">use_custom_evaluator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run evaluation and return metrics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>eval_dataset</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dataset to evaluate on (defaults to self.eval_dataset)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric_key_prefix</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prefix for metric keys</p>
              </div>
            </td>
            <td>
                  <code>&#39;eval&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_custom_evaluator</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use BaseEvaluator. If False, use native SFTEvaluator.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metrics</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metrics to compute (only for custom evaluator, overrides setup)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional evaluation arguments</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary of evaluation metrics</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span><span class="p">,</span>
    <span class="n">use_custom_evaluator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run evaluation and return metrics.</span>

<span class="sd">    Args:</span>
<span class="sd">        eval_dataset: Dataset to evaluate on (defaults to self.eval_dataset)</span>
<span class="sd">        metric_key_prefix: Prefix for metric keys</span>
<span class="sd">        use_custom_evaluator: If True, use BaseEvaluator. If False, use native SFTEvaluator.</span>
<span class="sd">        metrics: Metrics to compute (only for custom evaluator, overrides setup)</span>
<span class="sd">        **kwargs: Additional evaluation arguments</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dictionary of evaluation metrics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running evaluation...&quot;</span><span class="p">)</span>

    <span class="c1"># Route to appropriate evaluator</span>
    <span class="k">if</span> <span class="n">use_custom_evaluator</span><span class="p">:</span>
        <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_with_custom</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate_native</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Apply metric key prefix</span>
    <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="ow">and</span> <span class="n">eval_metrics</span><span class="p">:</span>
        <span class="n">prefixed_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">eval_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">eval_metrics</span> <span class="o">=</span> <span class="n">prefixed_metrics</span>

    <span class="c1"># Log evaluation metrics</span>
    <span class="k">if</span> <span class="n">eval_metrics</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">eval_metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;eval/&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">eval_metrics</span><span class="p">)</span>

        <span class="c1"># Update best metric</span>
        <span class="n">accuracy_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_key_prefix</span><span class="si">}</span><span class="s2">/accuracy&quot;</span> <span class="k">if</span> <span class="n">metric_key_prefix</span> <span class="k">else</span> <span class="s2">&quot;accuracy&quot;</span>
        <span class="k">if</span> <span class="n">accuracy_key</span> <span class="ow">in</span> <span class="n">eval_metrics</span><span class="p">:</span>
            <span class="n">improved</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_best_metric</span><span class="p">(</span><span class="n">eval_metrics</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">improved</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New best metric: </span><span class="si">{</span><span class="n">eval_metrics</span><span class="p">[</span><span class="n">accuracy_key</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">eval_metrics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.get_next_batch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_next_batch</span><span class="p">()</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.get_next_batch" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get next batch from data loader.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_next_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get next batch from data loader.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Data loader not initialized. Call setup_data() first.&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">StopIteration</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="c1"># Restart data loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_data_loader</span><span class="p">())</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.load_checkpoint" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.load_checkpoint" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load checkpoint.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load checkpoint.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading checkpoint from </span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Load model and tokenizer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

    <span class="c1"># Load training state</span>
    <span class="n">state_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
    <span class="k">if</span> <span class="n">state_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">state_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;best_metric&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">state_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;start_time&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.on_eval" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">on_eval</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.on_eval" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Hook called after each evaluation.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">on_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hook called after each evaluation.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.on_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">on_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.on_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Hook called after each training step.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hook called after each training step.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.predict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.predict" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate predictions from trained model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text(s) to generate from</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_new_tokens</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of tokens to generate</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>temperature</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling temperature (higher = more random)</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>top_p</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Nucleus sampling parameter</p>
              </div>
            </td>
            <td>
                  <code>0.9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_sample</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use sampling</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional generation arguments</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.List">List</span>[<span title="str">str</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Generated text(s) - single string if input was string, list if input was list</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="RuntimeError">RuntimeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If model or tokenizer not loaded</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate predictions from trained model.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: Input text(s) to generate from</span>
<span class="sd">        max_new_tokens: Maximum number of tokens to generate</span>
<span class="sd">        temperature: Sampling temperature (higher = more random)</span>
<span class="sd">        top_p: Nucleus sampling parameter</span>
<span class="sd">        do_sample: Whether to use sampling</span>
<span class="sd">        **kwargs: Additional generation arguments</span>

<span class="sd">    Returns:</span>
<span class="sd">        Generated text(s) - single string if input was string, list if input was list</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>


    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">is_single</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_single</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>

    <span class="c1"># Tokenize</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Move to device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="c1"># Generate</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="o">**</span><span class="n">tokenized</span><span class="p">,</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
            <span class="n">do_sample</span><span class="o">=</span><span class="n">do_sample</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
            <span class="n">eos_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="c1"># Decode</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Remove input prefix from predictions</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">prediction</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If input wasn&#39;t at start, just return the full prediction</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_prediction_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_single</span> <span class="k">else</span> <span class="n">predictions</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.push_to_hub" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">push_to_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="p">,</span> <span class="n">private</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">commit_message</span><span class="o">=</span><span class="s1">&#39;Upload fine-tuned model&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.push_to_hub" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Push model to HuggingFace Hub.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>repo_id</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Repository ID on HuggingFace Hub (e.g., 'username/model-name')</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>private</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether the repository should be private</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>HuggingFace token (if not provided, uses logged-in token)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>commit_message</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Commit message for the upload</p>
              </div>
            </td>
            <td>
                  <code>&#39;Upload fine-tuned model&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments for upload_folder</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>URL of the uploaded repository</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="RuntimeError">RuntimeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If model or tokenizer not loaded</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ImportError">ImportError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If huggingface_hub not installed</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">push_to_hub</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">repo_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">private</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">commit_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Upload fine-tuned model&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Push model to HuggingFace Hub.</span>

<span class="sd">    Args:</span>
<span class="sd">        repo_id: Repository ID on HuggingFace Hub (e.g., &#39;username/model-name&#39;)</span>
<span class="sd">        private: Whether the repository should be private</span>
<span class="sd">        token: HuggingFace token (if not provided, uses logged-in token)</span>
<span class="sd">        commit_message: Commit message for the upload</span>
<span class="sd">        **kwargs: Additional arguments for upload_folder</span>

<span class="sd">    Returns:</span>
<span class="sd">        URL of the uploaded repository</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If model or tokenizer not loaded</span>
<span class="sd">        ImportError: If huggingface_hub not installed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model not loaded. Call train() first or load a model.&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfApi</span><span class="p">,</span> <span class="n">login</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="s2">&quot;huggingface_hub is required for push_to_hub. &quot;</span>
            <span class="s2">&quot;Install with: pip install huggingface_hub&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Login if token provided</span>
    <span class="k">if</span> <span class="n">token</span><span class="p">:</span>
        <span class="n">login</span><span class="p">(</span><span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>

    <span class="c1"># Save model first (if not already saved)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_last_save_path&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;save_model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">save_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Fallback: save to temp directory</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span>

    <span class="c1"># Push to hub</span>
    <span class="n">api</span> <span class="o">=</span> <span class="n">HfApi</span><span class="p">()</span>
    <span class="n">api</span><span class="o">.</span><span class="n">upload_folder</span><span class="p">(</span>
        <span class="n">folder_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
        <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span>
        <span class="n">repo_type</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">private</span><span class="o">=</span><span class="n">private</span><span class="p">,</span>
        <span class="n">commit_message</span><span class="o">=</span><span class="n">commit_message</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>

    <span class="n">repo_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://huggingface.co/</span><span class="si">{</span><span class="n">repo_id</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model pushed to </span><span class="si">{</span><span class="n">repo_url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">repo_url</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.save_checkpoint" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_checkpoint</span><span class="p">()</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.save_checkpoint" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save checkpoint.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save checkpoint.&quot;&quot;&quot;</span>
    <span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;checkpoint-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">checkpoint_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving checkpoint to </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Save model and tokenizer</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>

    <span class="c1"># Save training state</span>
    <span class="n">state_path</span> <span class="o">=</span> <span class="n">checkpoint_dir</span> <span class="o">/</span> <span class="s2">&quot;training_state.json&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">state_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span>
            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
            <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span>
            <span class="s2">&quot;best_metric&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">best_metric</span><span class="p">,</span>
            <span class="s2">&quot;start_time&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">start_time</span>
        <span class="p">},</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">last_save_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.sft.trainer_base.SFTTrainerBase.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets and data loaders.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets and data loaders.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.sft.trainer_base.SFTTrainerBase.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup model, tokenizer, and optimization.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup model, tokenizer, and optimization.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#core.sft.trainer_base.SFTTrainerBase.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Main training loop with hooks.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Main training loop with hooks.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting SFT training...&quot;</span><span class="p">)</span>

    <span class="c1"># Setup phase</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>

    <span class="c1"># Initialize callback handler</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> 
        <span class="n">optimizer</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;optimizer&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>  <span class="c1"># Add self as callback for simple hooks</span>

    <span class="c1"># Call on_init_end</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_init_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="c1"># Log initial configuration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
    <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Calculate steps from epochs</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training for </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2"> steps&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Get next batch</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_next_batch</span><span class="p">()</span>

        <span class="c1"># Execute training step</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># Update state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">update_step</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

        <span class="c1"># Log metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

        <span class="c1"># Hook for step operations</span>
        <span class="c1"># self.on_step(step, metrics) # Handled by callback_handler now</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

        <span class="c1"># Evaluation</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
            <span class="c1"># self.on_eval(eval_metrics) # Handled by callback_handler</span>

        <span class="c1"># Checkpointing</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="o">.</span><span class="n">should_training_stop</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training stopped by callback&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">callback_handler</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">control</span><span class="p">)</span>

    <span class="c1"># Final evaluation and checkpoint</span>
    <span class="n">final_eval_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
    <span class="c1"># self.on_eval(final_eval_metrics)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SFT training completed&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.sft.trainer_base.SFTTrainerBase.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#core.sft.trainer_base.SFTTrainerBase.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute single training step.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/sft/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute single training step.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Example</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.trainer_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainerBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTConfig</span>

<span class="c1"># SFTTrainerBase is abstract - use concrete implementations</span>
<span class="c1"># See Backend Trainers below</span>
</code></pre></div>
<h3 id="trainingstate"><code>TrainingState</code><a class="headerlink" href="#trainingstate" title="Permanent link">&para;</a></h3>
<p>Training state tracking dataclass.</p>


<div class="doc doc-object doc-class">



<a id="core.rl.trainer_base.TrainingState"></a>
    <div class="doc doc-contents first">



        <p>Training state tracking.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TrainingState</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Training state tracking.&quot;&quot;&quot;</span>
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_metric</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">checkpoint_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">start_time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">)</span>
    <span class="n">last_eval_time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">)</span>
    <span class="n">last_save_time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update current step.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update current epoch.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_best_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update best metric if improved.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">metric</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">metric</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_elapsed_time</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get elapsed training time in seconds.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainingState.get_elapsed_time" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_elapsed_time</span><span class="p">()</span></code>

<a href="#core.rl.trainer_base.TrainingState.get_elapsed_time" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get elapsed training time in seconds.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_elapsed_time</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get elapsed training time in seconds.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainingState.update_best_metric" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_best_metric</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainingState.update_best_metric" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update best metric if improved.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_best_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update best metric if improved.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainingState.update_epoch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainingState.update_epoch" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update current epoch.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update current epoch.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="core.rl.trainer_base.TrainingState.update_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_step</span><span class="p">(</span><span class="n">step</span><span class="p">)</span></code>

<a href="#core.rl.trainer_base.TrainingState.update_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Update current step.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/core/rl/trainer_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update current step.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<hr />
<h2 id="backend-trainers">Backend Trainers<a class="headerlink" href="#backend-trainers" title="Permanent link">&para;</a></h2>
<h3 id="trl-backends">TRL Backends<a class="headerlink" href="#trl-backends" title="Permanent link">&para;</a></h3>
<h4 id="trlsfttrainer"><code>TRLSFTTrainer</code><a class="headerlink" href="#trlsfttrainer" title="Permanent link">&para;</a></h4>
<p>TRL backend for Supervised Fine-Tuning.</p>


<div class="doc doc-object doc-class">



<a id="backends.trl.sft.sft.TRLSFTTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="backends.core.sft.trainer_base.SFTTrainerBase">SFTTrainerBase</span></code></p>



        <p>SFT trainer using pure TRL SFTTrainer with comprehensive task type support.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TRLSFTTrainer</span><span class="p">(</span><span class="n">SFTTrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SFT trainer using pure TRL SFTTrainer with comprehensive task type support.&quot;&quot;&quot;</span>

    <span class="c1"># All supported task types</span>
    <span class="n">SUPPORTED_TASKS</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span>
    <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_task_type</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Already exists - no need to add</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># ADD THIS LINE (for BaseEvaluator)</span>

        <span class="c1"># Validate task type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_task_type</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized TRLSFTTrainer for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_task_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TaskType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract task type from config.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;task_type&#39;</span><span class="p">):</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task_type</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;task_type&#39;</span><span class="p">):</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">task_type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task_type</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="n">TaskType</span><span class="p">(</span><span class="n">task_type</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">task_type</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_task_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate that the task type is supported.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUPPORTED_TASKS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Task type </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> is not supported by TRL backend. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Supported tasks: </span><span class="si">{</span><span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">value</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">SUPPORTED_TASKS</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if TRL is available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">AutoModelForCausalLM</span><span class="p">,</span> 
                <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
                <span class="n">AutoModelForTokenClassification</span><span class="p">,</span>
                <span class="n">AutoTokenizer</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># Replace lines 465-476 in setup_model:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup model using standard Transformers with task type awareness.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL SFT model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL SFT&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">AutoModelForCausalLM</span><span class="p">,</span>
                <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
                <span class="n">AutoModelForTokenClassification</span><span class="p">,</span>
                <span class="n">AutoTokenizer</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Transformers not available.&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># Load tokenizer first</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading tokenizer...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


        <span class="c1"># Set pad token if not set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Set pad token to eos token&quot;</span><span class="p">)</span>

        <span class="c1"># Load model based on task type</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
            <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;num_labels&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading classification model with </span><span class="si">{</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
            <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;num_labels&#39;</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading token classification model with </span><span class="si">{</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Causal LM for generation tasks</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading causal language model&quot;</span><span class="p">)</span>

            <span class="c1"># Handle quantization configuration</span>
            <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">quantization_dict</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="k">if</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>

                    <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                    <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">load_in_4bit</span><span class="p">:</span>
                        <span class="n">compute_dtype_str</span> <span class="o">=</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bnb_4bit_compute_dtype&#39;</span><span class="p">,</span> <span class="s1">&#39;bfloat16&#39;</span><span class="p">)</span>
                        <span class="n">compute_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">compute_dtype_str</span> <span class="o">==</span> <span class="s1">&#39;bfloat16&#39;</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>

                        <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">compute_dtype</span><span class="p">,</span>
                            <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bnb_4bit_quant_type&#39;</span><span class="p">,</span> <span class="s1">&#39;nf4&#39;</span><span class="p">),</span>
                            <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bnb_4bit_use_double_quant&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                        <span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; 4-bit quantization enabled for memory optimization&quot;</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">load_in_8bit</span><span class="p">:</span>
                        <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; 8-bit quantization enabled for memory optimization&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  BitsAndBytes not available. Install with: pip install bitsandbytes&quot;</span><span class="p">)</span>
                    <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Get max_memory from config if specified</span>
            <span class="n">max_memory</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_memory&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;torch_dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
                <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="s1">&#39;device_map&#39;</span><span class="p">:</span> <span class="s1">&#39;auto&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;low_cpu_mem_usage&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Add max_memory if specified</span>
            <span class="k">if</span> <span class="n">max_memory</span><span class="p">:</span>
                <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;max_memory&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_memory</span>

            <span class="k">if</span> <span class="n">quantization_config</span><span class="p">:</span>
                <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;quantization_config&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Quantization config: </span><span class="si">{</span><span class="n">quantization_config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Only set these if not using quantization</span>
                <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No quantization configured - loading full precision model&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>

            <span class="c1"># Move to GPU only if not using device_map=&#39;auto&#39; (which handles it automatically)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">quantization_config</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">model_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;device_map&#39;</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model moved to GPU&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">quantization_config</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded with quantization (device_map=&#39;auto&#39;)&quot;</span><span class="p">)</span>
                <span class="c1"># CRITICAL: When using quantization, PEFT adapters MUST be enabled</span>
                <span class="c1"># TRL SFTTrainer will handle this, but we need to ensure PEFT is enabled in config</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;peft_enabled&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  Quantization requires PEFT adapters. Enabling PEFT automatically.&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">peft_enabled</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Setup tokenizer for specific tasks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_tokenizer_for_task</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL SFT model setup completed successfully&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer vocab size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_tokenizer_for_task</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup tokenizer with task-specific configurations.&quot;&quot;&quot;</span>
        <span class="c1"># If a custom chat template (jinja) is provided in config, set it so</span>
        <span class="c1"># `tokenizer.apply_chat_template(...)` can be used during SFT formatting.</span>
        <span class="n">cfg_template</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cfg_template</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg_template</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;{%&quot;</span> <span class="ow">in</span> <span class="n">cfg_template</span> <span class="ow">or</span> <span class="s2">&quot;{{&quot;</span> <span class="ow">in</span> <span class="n">cfg_template</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="n">cfg_template</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applied custom chat_template from config to tokenizer&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to set tokenizer.chat_template from config: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;chat_template&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;{</span><span class="si">% f</span><span class="s2">or message in messages %}&quot;</span>
                    <span class="s2">&quot;{{ message[&#39;role&#39;] }}: {{ message[&#39;content&#39;] }}</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;{</span><span class="si">% e</span><span class="s2">ndfor %}Assistant:&quot;</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added chat template to tokenizer&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="c1"># If the tokenizer already supports chat templating, prefer using that</span>
            <span class="c1"># instead of introducing ChatML-style tokens.</span>
            <span class="n">has_chat_template</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;apply_chat_template&quot;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_chat_template</span><span class="p">:</span>
                <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;|im_start|&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;|im_end|&gt;&quot;</span><span class="p">]</span>
                <span class="n">num_added</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span>
                    <span class="s1">&#39;additional_special_tokens&#39;</span><span class="p">:</span> <span class="n">special_tokens</span>
                <span class="p">})</span>
                <span class="k">if</span> <span class="n">num_added</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added</span><span class="si">}</span><span class="s2"> special tokens for instruction following&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_chat_template_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="n">add_generation_prompt</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply tokenizer chat template with broad compatibility.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;apply_chat_template&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">messages</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="n">add_generation_prompt</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="c1"># Some tokenizers don&#39;t support add_generation_prompt or other kwargs.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_format_with_chat_template</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">dataset_cfg</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a `text` field using the model&#39;s chat template when available.</span>
<span class="sd">        Falls back to legacy string formatting if templating fails.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset_cfg</span><span class="p">,</span> <span class="s2">&quot;system_prompt&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_prepend_system_if_missing</span><span class="p">(</span><span class="n">msgs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
            <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">msgs</span> <span class="ow">or</span> <span class="n">msgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;role&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;system&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">}]</span> <span class="o">+</span> <span class="n">msgs</span>
            <span class="k">return</span> <span class="n">msgs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">messages_field</span> <span class="o">=</span> <span class="n">dataset_cfg</span><span class="o">.</span><span class="n">messages_column</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_cfg</span><span class="p">,</span> <span class="s2">&quot;messages_column&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;messages&quot;</span>
            <span class="k">for</span> <span class="n">messages</span> <span class="ow">in</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">messages_field</span><span class="p">,</span> <span class="p">[]):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">msgs</span> <span class="o">=</span> <span class="n">_prepend_system_if_missing</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
                    <span class="n">templated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_chat_template_safe</span><span class="p">(</span><span class="n">msgs</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">templated</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">templated</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="c1"># Fallback: plain &quot;role: content&quot; formatting</span>
                    <span class="n">conversation</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;role&#39;</span><span class="p">,</span><span class="s1">&#39;user&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;content&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">msgs</span><span class="p">]</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">conversation</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span> <span class="k">if</span> <span class="n">messages</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span><span class="p">]:</span>
            <span class="c1"># Determine columns (prefer config, fall back to common names)</span>
            <span class="n">instr_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset_cfg</span><span class="p">,</span> <span class="s2">&quot;instruction_column&quot;</span><span class="p">,</span> <span class="s2">&quot;instruction&quot;</span><span class="p">)</span>
            <span class="n">resp_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset_cfg</span><span class="p">,</span> <span class="s2">&quot;response_column&quot;</span><span class="p">,</span> <span class="s2">&quot;response&quot;</span><span class="p">)</span>
            <span class="n">ctx_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset_cfg</span><span class="p">,</span> <span class="s2">&quot;context_column&quot;</span><span class="p">,</span> <span class="s2">&quot;context&quot;</span><span class="p">)</span>
            <span class="n">input_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset_cfg</span><span class="p">,</span> <span class="s2">&quot;input_column&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span><span class="p">)</span>

            <span class="n">instructions</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">instr_col</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;instruction&quot;</span><span class="p">,</span> <span class="p">[]))</span>
            <span class="c1"># response could be in response/output/completion depending on dataset</span>
            <span class="n">responses</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">resp_col</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;response&quot;</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="p">[])))</span>

            <span class="n">n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">instructions</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">responses</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">instruction</span> <span class="o">=</span> <span class="n">instructions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">context</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">ctx_col</span> <span class="ow">in</span> <span class="n">examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ctx_col</span><span class="p">,</span> <span class="p">[])):</span>
                    <span class="n">context</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ctx_col</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">input_col</span> <span class="ow">in</span> <span class="n">examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">input_col</span><span class="p">,</span> <span class="p">[])):</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">input_col</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>

                <span class="n">sys_parts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">system_prompt</span><span class="p">:</span>
                    <span class="n">sys_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">context</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="n">sys_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">sys_parts</span><span class="p">:</span>
                    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sys_parts</span><span class="p">)})</span>

                <span class="n">user_content</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">instruction</span><span class="p">)</span> <span class="k">if</span> <span class="n">instruction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="n">user_content</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="se">\n\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_content</span><span class="p">})</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span> <span class="k">if</span> <span class="n">response</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">})</span>

                <span class="n">templated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_chat_template_safe</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">templated</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">templated</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fallback to legacy formatting (inline; avoid recomputing full batch)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">context</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;system</span><span class="se">\n</span><span class="s2">Context: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;&quot;</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;&quot;</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">user_content</span> <span class="ow">and</span> <span class="n">response</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])[</span><span class="n">i</span><span class="p">])</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]))</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
                <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;[NO_VALID_TEXT]&quot;</span><span class="p">]</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span>

        <span class="c1"># Default fallback (shouldn&#39;t be hit for tasks we call this for)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;[NO_VALID_TEXT]&quot;</span><span class="p">])}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets for SFT training with task-aware formatting.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL SFT datasets: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Initialize dataset cache</span>
        <span class="n">cache_root</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;caching&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;root&quot;</span><span class="p">,</span> <span class="s2">&quot;./cache&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;caching&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;./cache&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="n">DatasetCache</span><span class="p">(</span><span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset cache initialized at: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span><span class="o">.</span><span class="n">cache_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load dataset</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading dataset...&quot;</span><span class="p">)</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

        <span class="c1"># Handle dataset config/subset</span>
        <span class="n">load_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">split</span> <span class="ow">or</span> <span class="s2">&quot;train&quot;</span><span class="p">}</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">name</span>
        <span class="n">dataset_subset</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;subset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
            <span class="n">dataset_subset</span> <span class="o">=</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">subset</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
            <span class="n">dataset_subset</span> <span class="o">=</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">config</span>

        <span class="c1"># Check if dataset has a registered custom loader</span>
        <span class="k">if</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="n">DatasetRegistry</span><span class="o">.</span><span class="n">list_loaders</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using registered dataset loader: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">DatasetRegistry</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">split</span> <span class="ow">or</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
                <span class="n">max_samples</span><span class="o">=</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span>
                <span class="o">**</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset_config</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Load dataset</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dataset_subset</span><span class="p">:</span>
                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_subset</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;Config name is missing&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; requires a config/subset name. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Add &#39;subset&#39; or &#39;config&#39; to your DatasetConfig.&quot;</span>
                    <span class="p">)</span>
                <span class="k">raise</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original dataset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1">#  CRITICAL FIX: Shuffle dataset BEFORE selecting samples</span>
        <span class="c1"># This ensures balanced class distribution for classification tasks</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Shuffling dataset to ensure balanced sampling...&quot;</span><span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

        <span class="c1"># Apply dataset size limits</span>
        <span class="k">if</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span><span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">))</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s2">% of dataset: </span><span class="si">{</span><span class="n">dataset_size</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using max_samples limit: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Apply column mappings if needed</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">:</span>
            <span class="n">valid_mappings</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">column_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">valid_mappings</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">valid_mappings</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns: </span><span class="si">{</span><span class="n">valid_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Task-specific formatting</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_dataset_for_task</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">)</span>

        <span class="c1"># Create evaluation split</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">200</span><span class="p">:</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">50</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>

            <span class="n">split_ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created eval split. Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> | Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not create eval split: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT dataset setup completed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_format_dataset_for_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Format dataset based on task type.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Formatting dataset for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Select appropriate formatter</span>
        <span class="n">can_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;apply_chat_template&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_with_chat_template</span> <span class="k">if</span> <span class="n">can_template</span> <span class="k">else</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_instruction_following</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_with_chat_template</span> <span class="k">if</span> <span class="n">can_template</span> <span class="k">else</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_supervised_fine_tuning</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_text_generation</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_with_chat_template</span> <span class="k">if</span> <span class="n">can_template</span> <span class="k">else</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_chat_completion</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_classification</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_token_classification</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Apply formatting</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># For classification, we need to keep the columns AND rename properly</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
                <span class="c1"># Don&#39;t remove columns, just map them</span>
                <span class="n">formatted_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">formatter</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">),</span>
                    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">]],</span>
                    <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Formatting for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># NOW remove the old &#39;label&#39; column if it exists (keep only &#39;labels&#39;)</span>
                <span class="k">if</span> <span class="s1">&#39;label&#39;</span> <span class="ow">in</span> <span class="n">formatted_dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="ow">and</span> <span class="s1">&#39;labels&#39;</span> <span class="ow">in</span> <span class="n">formatted_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
                    <span class="n">formatted_dataset</span> <span class="o">=</span> <span class="n">formatted_dataset</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Removed duplicate &#39;label&#39; column, keeping &#39;labels&#39;&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
                <span class="n">formatted_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">formatter</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">),</span>
                    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">remove_columns</span><span class="o">=</span><span class="p">[],</span>
                    <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Formatting for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For generation tasks, remove all columns</span>
                <span class="n">formatted_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">formatter</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">),</span>
                    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">remove_columns</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Formatting for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Verify</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">formatted_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;text&#39;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample text (first 200 chars): </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">][:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;labels&#39;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample label: </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: For classification, check label distribution</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
                <span class="n">labels_sample</span> <span class="o">=</span> <span class="p">[</span><span class="n">formatted_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">formatted_dataset</span><span class="p">)))]</span>
                <span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels_sample</span><span class="p">)</span>
                <span class="n">label_counts</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <span class="n">labels_sample</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">unique_labels</span><span class="p">}</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Label distribution (first 100): </span><span class="si">{</span><span class="n">label_counts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Unique labels: </span><span class="si">{</span><span class="n">unique_labels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; ERROR: All labels are </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">! Dataset is corrupted!&quot;</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dataset has only one label class!&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">formatted_dataset</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error formatting dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;SFT doesn&#39;t use reward functions.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SFT training doesn&#39;t use reward functions&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train using TRL SFTTrainer with task-aware setup.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting TRL SFT training for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Setup model and data if not already done</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorWithPadding</span><span class="p">,</span> <span class="n">DataCollatorForTokenClassification</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TRL required for SFT training. Install with: pip install trl&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># Create training arguments</span>
        <span class="c1"># Get optimizer and scheduler configurations</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">....core.optimization</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_optimizer_for_config</span><span class="p">,</span> <span class="n">get_scheduler_for_config</span>
        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Use config-specified optimizer or default to adamw_torch</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
        <span class="n">scheduler_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="s1">&#39;cosine&#39;</span><span class="p">)</span>

        <span class="c1"># Create optimizer configuration</span>
        <span class="n">optimizer_config</span> <span class="o">=</span> <span class="n">get_optimizer_for_config</span><span class="p">(</span>
            <span class="n">optimizer_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span> <span class="ow">or</span> <span class="mf">2e-4</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span> <span class="ow">or</span> <span class="mf">0.01</span>
        <span class="p">)</span>

        <span class="c1"># Calculate max_steps - use config value or calculate from epochs</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
        <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Calculate from epochs if max_steps not specified</span>
            <span class="n">epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">3</span>
            <span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="k">else</span> <span class="mi">1000</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span> <span class="ow">or</span> <span class="mi">2</span>
            <span class="n">grad_accum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">or</span> <span class="mi">4</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset_size</span> <span class="o">*</span> <span class="n">epochs</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">grad_accum</span><span class="p">)</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_steps</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># Minimum 10 steps</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calculated max_steps=</span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2"> from </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> epochs, </span><span class="si">{</span><span class="n">dataset_size</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Calculate warmup steps</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">:</span>
            <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">)</span>

        <span class="c1"># Create scheduler configuration</span>
        <span class="n">scheduler_config</span> <span class="o">=</span> <span class="n">get_scheduler_for_config</span><span class="p">(</span>
            <span class="n">scheduler_name</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="p">,</span>
            <span class="n">warmup_steps</span>
        <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">kwargs_to_str</span><span class="p">(</span><span class="n">kwargs_dict</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Convert optimizer/scheduler kwargs dict to string format.&quot;&quot;&quot;</span>
            <span class="c1"># Exclude lr and weight_decay since TrainingArguments already sets them</span>
            <span class="n">filtered</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">]}</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">filtered</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">v</span><span class="p">))</span><span class="si">}</span><span class="s1">)&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="nb">tuple</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">filtered</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

        <span class="n">optim_args_str</span><span class="o">=</span><span class="n">kwargs_to_str</span><span class="p">(</span><span class="n">optimizer_config</span><span class="p">[</span><span class="s1">&#39;optimizer_kwargs&#39;</span><span class="p">])</span>
        <span class="c1"># print(lr_scheduler_kwargs_str)</span>
        <span class="c1"># print(scheduler_config)</span>
        <span class="n">filtered_scheduler_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">scheduler_config</span><span class="p">[</span><span class="s1">&#39;lr_scheduler_kwargs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> 
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;num_training_steps&#39;</span><span class="p">,</span> <span class="s1">&#39;num_warmup_steps&#39;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="c1"># Build TrainingArguments kwargs, conditionally including optim_args</span>
        <span class="n">training_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;max_steps&quot;</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
            <span class="s2">&quot;per_device_train_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span> <span class="ow">or</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">or</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span> <span class="ow">or</span> <span class="mf">2e-4</span><span class="p">,</span>
            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span> <span class="ow">or</span> <span class="mf">0.01</span><span class="p">,</span>
            <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="n">warmup_steps</span><span class="p">,</span>
            <span class="s2">&quot;logging_steps&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;log_interval&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
            <span class="s2">&quot;save_steps&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
            <span class="s2">&quot;eval_steps&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
            <span class="s2">&quot;eval_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
            <span class="s2">&quot;save_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;load_best_model_at_end&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;report_to&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;run_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="p">,</span>
            <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>
            <span class="s2">&quot;dataloader_num_workers&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;remove_unused_columns&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;optim&quot;</span><span class="p">:</span> <span class="n">optimizer_name</span><span class="p">,</span>
            <span class="s2">&quot;lr_scheduler_type&quot;</span><span class="p">:</span> <span class="n">scheduler_name</span><span class="p">,</span>
            <span class="s2">&quot;lr_scheduler_kwargs&quot;</span><span class="p">:</span> <span class="n">filtered_scheduler_kwargs</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Only include optim_args if it&#39;s not None/empty and valid.</span>
        <span class="c1"># For 8-bit optimizers (adamw_8bit, paged_adamw_8bit, etc.), bitsandbytes handles kwargs internally,</span>
        <span class="c1"># so we skip optim_args to avoid Transformers parsing issues.</span>
        <span class="c1"># Also skip if the string doesn&#39;t contain &quot;=&quot; (would cause parsing errors).</span>
        <span class="n">should_skip_optim_args</span> <span class="o">=</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">optim_args_str</span> <span class="ow">or</span>  <span class="c1"># None or empty string</span>
            <span class="ow">not</span> <span class="n">optim_args_str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="ow">or</span>  <span class="c1"># Whitespace only</span>
            <span class="s2">&quot;=&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">optim_args_str</span> <span class="ow">or</span>  <span class="c1"># Invalid format (no key=value pairs)</span>
            <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="ow">in</span> <span class="n">optimizer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;8bit&quot;</span><span class="p">,</span> <span class="s2">&quot;8_bit&quot;</span><span class="p">,</span> <span class="s2">&quot;bnb&quot;</span><span class="p">,</span> <span class="s2">&quot;paged&quot;</span><span class="p">])</span>  <span class="c1"># 8-bit optimizers</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">should_skip_optim_args</span><span class="p">:</span>
            <span class="n">training_kwargs</span><span class="p">[</span><span class="s2">&quot;optim_args&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optim_args_str</span>

        <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">**</span><span class="n">training_kwargs</span><span class="p">)</span>

        <span class="c1"># Create trainer based on task type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_classification_trainer</span><span class="p">(</span><span class="n">training_args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Generation tasks use SFTTrainer</span>
            <span class="c1"># Setup PEFT config if enabled (required for quantized models)</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;peft_enabled&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span>

                    <span class="c1"># Get LoRA parameters from config</span>
                    <span class="n">lora_r</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_rank&#39;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
                    <span class="n">lora_alpha</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
                    <span class="n">lora_dropout</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
                    <span class="n">target_modules</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                    <span class="c1"># If target_modules not specified, use default for Llama models</span>
                    <span class="k">if</span> <span class="n">target_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">]</span>

                    <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                        <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                        <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                        <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span>
                        <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                        <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; PEFT LoRA config created: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, modules=</span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  PEFT not available. Install with: pip install peft&quot;</span><span class="p">)</span>
                    <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Generation tasks use SFTTrainer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">,</span>  <span class="c1"># Pass PEFT config to SFTTrainer</span>
            <span class="p">)</span>

        <span class="c1"># Record training start</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting TRL SFT Training - Task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Start training</span>
        <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Record training end</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_duration</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

        <span class="c1"># Log training metrics</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>

        <span class="c1"># Save model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

        <span class="c1"># Add to training history</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">(),</span>
            <span class="s1">&#39;duration&#39;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
            <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;model_path&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="p">})</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL SFT training completed successfully!&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Return training results</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;training_time&#39;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
            <span class="s1">&#39;model_path&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">,</span> <span class="p">{}),</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_classification_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup trainer for classification tasks - FIXED VERSION.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">DataCollatorWithPadding</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
            <span class="c1"># CRITICAL: Verify dataset has both text and labels BEFORE tokenization</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns before tokenization: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample before tokenization: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Ensure we have the required columns</span>
            <span class="k">if</span> <span class="s1">&#39;text&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span> <span class="ow">or</span> <span class="s1">&#39;labels&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Dataset must have &#39;text&#39; and &#39;labels&#39; columns. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Found: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Tokenize text and preserve labels - FIXED&quot;&quot;&quot;</span>
                <span class="c1"># Get texts - handle both list and single values</span>
                <span class="n">texts</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">texts</span><span class="p">]</span>

                <span class="c1"># Clean texts</span>
                <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>

                <span class="c1"># Tokenize WITHOUT max_length padding here</span>
                <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                    <span class="n">texts</span><span class="p">,</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># FIX: Don&#39;t pad here, let collator handle it</span>
                    <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                    <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">)</span>

                <span class="c1"># Get labels - handle both list and single values</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">]</span>

                <span class="c1"># FIX: Ensure labels are integers and valid</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label conversion error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Problematic labels: </span><span class="si">{</span><span class="n">labels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">raise</span>

                <span class="k">return</span> <span class="n">tokenized</span>

            <span class="c1"># Store original column names</span>
            <span class="n">original_train_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="c1"># Tokenize train dataset - REMOVE original columns</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Tokenizing train dataset...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="n">tokenize_function</span><span class="p">,</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">remove_columns</span><span class="o">=</span><span class="n">original_train_cols</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Tokenize eval dataset if it exists</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">original_eval_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Tokenizing eval dataset...&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="n">tokenize_function</span><span class="p">,</span>
                    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">remove_columns</span><span class="o">=</span><span class="n">original_eval_cols</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Verify tokenization</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Train dataset columns after tokenization: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Sample keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Sample input_ids length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Sample label: </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Sample label type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># FIX: Verify label distribution and validity</span>
            <span class="n">sample_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
            <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)]</span>
            <span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>
            <span class="n">label_counts</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <span class="n">all_labels</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">unique_labels</span><span class="p">}</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; First </span><span class="si">{</span><span class="n">sample_size</span><span class="si">}</span><span class="s2"> labels distribution: </span><span class="si">{</span><span class="n">label_counts</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Unique labels: </span><span class="si">{</span><span class="n">unique_labels</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Expected labels: </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Validate labels</span>
            <span class="n">expected_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">unique_labels</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">expected_labels</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Found unexpected labels: </span><span class="si">{</span><span class="n">unique_labels</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">expected_labels</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Expected labels in range [0, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; ERROR: All labels are </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dataset has only one label class after tokenization!&quot;</span><span class="p">)</span>

            <span class="c1"># FIX: Use DataCollatorWithPadding that handles padding dynamically</span>
            <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Pad dynamically to longest in batch</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span>  <span class="c1"># Optimize for GPU</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Data collator created with dynamic padding&quot;</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Compute classification metrics&quot;&quot;&quot;</span>
                <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>

                <span class="c1"># Handle logits</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Log predictions distribution</span>
                <span class="n">unique_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
                <span class="n">unique_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictions distribution: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Labels distribution: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>

                <span class="c1"># Accuracy</span>
                <span class="n">accuracy_metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">accuracy_metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
                    <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span>
                    <span class="n">references</span><span class="o">=</span><span class="n">labels</span>
                <span class="p">))</span>

                <span class="c1"># F1 score</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">f1_metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;f1&quot;</span><span class="p">)</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">f1_metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
                        <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span>
                        <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                        <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span>
                    <span class="p">))</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not compute F1: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="k">return</span> <span class="n">metrics</span>

            <span class="c1"># Create trainer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
                <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Classification trainer created successfully&quot;</span><span class="p">)</span>


        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
            <span class="c1"># Tokenize for token classification</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_and_align_labels</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
                <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                    <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">],</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
                <span class="p">)</span>

                <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]):</span>
                    <span class="n">word_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">word_ids</span><span class="p">(</span><span class="n">batch_index</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">label_ids</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="kc">None</span>

                    <span class="k">for</span> <span class="n">word_idx</span> <span class="ow">in</span> <span class="n">word_ids</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">word_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">word_idx</span> <span class="o">!=</span> <span class="n">previous_word_idx</span><span class="p">:</span>
                            <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">word_idx</span><span class="p">])</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
                        <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="n">word_idx</span>

                    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

                <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
                <span class="k">return</span> <span class="n">tokenized</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_and_align_labels</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_and_align_labels</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForTokenClassification</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
                <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

                <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="p">]</span>
                <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="p">]</span>

                <span class="n">flat_preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">true_predictions</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>
                <span class="n">flat_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">true_labels</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>

                <span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">flat_preds</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">flat_labels</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the trained model and tokenizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            output_dir: Directory to save to (defaults to config output_dir)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Path where model was saved</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;sft_model&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="n">output_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;trainer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No trainer available to save model&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;tokenizer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer saved to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No tokenizer available to save&quot;</span><span class="p">)</span>

        <span class="c1"># Save task type info</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">output_dir</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span>
        <span class="p">}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training config saved to </span><span class="si">{</span><span class="n">config_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Store for push_to_hub</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute training step (handled by TRL trainer).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create data loader for training.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Dataset not loaded. Call setup_data() first.&quot;</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>

        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_collate_fn</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_collate_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Collate function for data loader.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">batch</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="c1"># Extract text from batch</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">if</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
                <span class="k">elif</span> <span class="s2">&quot;input_ids&quot;</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">item</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                            <span class="k">break</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No valid text found in batch&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">texts</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_sample_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get sample outputs for logging.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Classification tasks don&#39;t generate samples</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="n">sample_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">))):</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="k">if</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
                <span class="n">text</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="s2">&quot;messages&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
                <span class="n">messages</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>
                <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span>

            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                    <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">temperature</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span>
                    <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="p">)</span>

            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">sample_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="n">text</span><span class="p">,</span>
                <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;trl_sft&quot;</span><span class="p">,</span>
                <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>
            <span class="p">})</span>

        <span class="k">return</span> <span class="n">sample_outputs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cleanup TRL resources.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL SFT trainer cleanup completed&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the model performance with enhanced metrics.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running TRL SFT evaluation for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Training not setup. Call train() first.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span>

        <span class="c1"># Run evaluation</span>
        <span class="n">eval_results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;evaluate&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eval_dataset&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No eval_dataset available; skipping evaluation.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span>

        <span class="c1"># Add task type to results</span>
        <span class="n">eval_results</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>

        <span class="c1"># Calculate perplexity from loss (if available)</span>
        <span class="k">if</span> <span class="s2">&quot;eval_loss&quot;</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_perplexity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not calculate perplexity: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Add comprehensive quality metrics using SFTEvaluator for generation tasks</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">]:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.evaluator</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTEvaluator</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eval_dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">SFTEvaluator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
                    <span class="n">quality_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                    <span class="p">)</span>

                    <span class="c1"># Merge quality metrics (avoid duplicates)</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">quality_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>  <span class="c1"># Don&#39;t override existing metrics</span>
                            <span class="n">eval_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">quality_metrics</span><span class="p">)</span><span class="si">}</span><span class="s2"> quality metrics&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not compute quality metrics: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Generate qualitative samples for generation tasks</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_samples</span><span class="p">()</span>
                <span class="n">eval_results</span><span class="p">[</span><span class="s1">&#39;qualitative_samples&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not generate qualitative samples: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">eval_results</span><span class="p">[</span><span class="s1">&#39;qualitative_samples&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT evaluation completed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span><span class="si">}</span><span class="s2"> metrics computed&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eval_results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate qualitative samples for manual inspection.&quot;&quot;&quot;</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="c1"># Task-specific prompts</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="n">sample_prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">What is artificial intelligence?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Explain machine learning.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Write a Python function.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">sample_prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;Human: Hello!</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: How are you?</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: Explain quantum computing.</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sample_prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;The future of artificial intelligence is&quot;</span><span class="p">,</span>
                <span class="s2">&quot;In a world where technology advances rapidly,&quot;</span><span class="p">,</span>
                <span class="s2">&quot;The most important skill for the 21st century is&quot;</span>
            <span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_prompts</span><span class="p">[:</span><span class="mi">3</span><span class="p">]):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">generated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                        <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">temperature</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span>
                        <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                        <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
                        <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="n">generated_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">generated_text</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s1">&#39;generated_response&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
                    <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>
                <span class="p">})</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated sample </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/3&quot;</span><span class="p">)</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error generating sample </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s1">&#39;generated_response&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>
                <span class="p">})</span>

        <span class="k">return</span> <span class="n">samples</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Public method to generate samples.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Sample generation not supported for classification tasks&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_samples</span><span class="p">()</span>
            <span class="c1"># Return limited number and ensure all have &#39;response&#39; key</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;generated_response&#39;</span> <span class="ow">in</span> <span class="n">s</span> <span class="ow">or</span> <span class="s1">&#39;response&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample generation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_zero_shot_evaluation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run zero-shot evaluation before training with enhanced metrics.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running zero-shot evaluation for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Classification tasks don&#39;t support zero-shot evaluation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Zero-shot evaluation not supported for classification tasks&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">test_prompts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Task-specific default prompts</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
                <span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">What is AI?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Explain ML.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">How does training work?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="p">]</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
                <span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="s2">&quot;Human: Hello!</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;Human: How are you?</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;Human: Tell me about AI.</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="s2">&quot;What is artificial intelligence?&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;Explain machine learning briefly.&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;How does a computer work?&quot;</span>
                <span class="p">]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">test_prompts</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                        <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                        <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span>
                    <span class="p">)</span>

                <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s1">&#39;response&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
                    <span class="s1">&#39;response_length&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">()),</span>
                    <span class="s1">&#39;coherence_score&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_coherence_score</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
                <span class="p">})</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Zero-shot evaluation failed for prompt: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s1">&#39;response&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s1">&#39;response_length&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="s1">&#39;coherence_score&#39;</span><span class="p">:</span> <span class="mf">0.0</span>
                <span class="p">})</span>

        <span class="c1"># Calculate aggregate metrics</span>
        <span class="n">avg_length</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;response_length&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">avg_coherence</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;coherence_score&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">successful_responses</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">)])</span>

        <span class="n">zero_shot_metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;zero_shot_results&#39;</span><span class="p">:</span> <span class="n">results</span><span class="p">,</span>
            <span class="s1">&#39;avg_response_length&#39;</span><span class="p">:</span> <span class="n">avg_length</span><span class="p">,</span>
            <span class="s1">&#39;avg_coherence_score&#39;</span><span class="p">:</span> <span class="n">avg_coherence</span><span class="p">,</span>
            <span class="s1">&#39;successful_responses&#39;</span><span class="p">:</span> <span class="n">successful_responses</span><span class="p">,</span>
            <span class="s1">&#39;success_rate&#39;</span><span class="p">:</span> <span class="n">successful_responses</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">({</span>
                <span class="s1">&#39;zero_shot_avg_length&#39;</span><span class="p">:</span> <span class="n">avg_length</span><span class="p">,</span>
                <span class="s1">&#39;zero_shot_coherence&#39;</span><span class="p">:</span> <span class="n">avg_coherence</span><span class="p">,</span>
                <span class="s1">&#39;zero_shot_success_rate&#39;</span><span class="p">:</span> <span class="n">successful_responses</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="p">})</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Zero-shot evaluation completed. Success rate: </span><span class="si">{</span><span class="n">successful_responses</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">zero_shot_metrics</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_calculate_coherence_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate a simple coherence score for generated text.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>

        <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>

        <span class="c1"># Check for repetition</span>
        <span class="n">unique_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
        <span class="n">repetition_penalty</span> <span class="o">=</span> <span class="n">unique_words</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

        <span class="c1"># Check for reasonable length</span>
        <span class="n">length_score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">/</span> <span class="mf">20.0</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">20</span> <span class="k">else</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">40.0</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>

        <span class="c1"># Simple readability check</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
        <span class="n">avg_sentence_length</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="k">if</span> <span class="n">sentences</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">readability_score</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="mi">5</span> <span class="o">&lt;=</span> <span class="n">avg_sentence_length</span> <span class="o">&lt;=</span> <span class="mi">25</span> <span class="k">else</span> <span class="mf">0.7</span>

        <span class="c1"># Combine scores</span>
        <span class="n">coherence_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">repetition_penalty</span> <span class="o">+</span> <span class="n">length_score</span> <span class="o">+</span> <span class="n">readability_score</span><span class="p">)</span> <span class="o">/</span> <span class="mf">3.0</span>
        <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">coherence_score</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_training_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get enhanced training statistics and information.&quot;&quot;&quot;</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_epochs</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;max_steps&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
                <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_peft</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;dataset_info&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;train_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;val_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eval_dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;loaded&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
                <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;has_peft&#39;</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;peft_config&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">stats</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save enhanced configuration to YAML file.&quot;&quot;&quot;</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_epochs</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;max_steps&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_peft</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT configuration saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a complete experiment with enhanced features.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting TRL SFT experiment: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Setup model and data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>

            <span class="c1"># Run zero-shot evaluation if configured</span>
            <span class="n">zero_shot_results</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;evaluation&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">evaluation</span><span class="p">,</span> <span class="s1">&#39;run_zero_shot&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running pre-training zero-shot evaluation...&quot;</span><span class="p">)</span>
                <span class="n">zero_shot_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_zero_shot_evaluation</span><span class="p">()</span>

            <span class="c1"># Start training</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">train_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

            <span class="c1"># Evaluate after training</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running post-training evaluation...&quot;</span><span class="p">)</span>
            <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

            <span class="c1"># Combine results</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="s1">&#39;train_and_eval&#39;</span><span class="p">,</span>
                <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="s1">&#39;train_results&#39;</span><span class="p">:</span> <span class="n">train_results</span><span class="p">,</span>
                <span class="s1">&#39;eval_results&#39;</span><span class="p">:</span> <span class="n">eval_results</span><span class="p">,</span>
                <span class="s1">&#39;training_stats&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_training_stats</span><span class="p">(),</span>
                <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">),</span>
                    <span class="s1">&#39;dataset&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">),</span>
                <span class="p">}</span>
            <span class="p">}</span>

            <span class="c1"># Add zero-shot results if available</span>
            <span class="k">if</span> <span class="n">zero_shot_results</span><span class="p">:</span>
                <span class="n">results</span><span class="p">[</span><span class="s1">&#39;zero_shot_evaluation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero_shot_results</span>

            <span class="c1"># Save results</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
            <span class="n">output_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">results_path</span> <span class="o">=</span> <span class="n">output_dir</span> <span class="o">/</span> <span class="s2">&quot;experiment_results.yaml&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">results_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT experiment completed. Results saved to </span><span class="si">{</span><span class="n">results_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT experiment failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>
            <span class="k">raise</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.cleanup" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">cleanup</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.cleanup" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Cleanup TRL resources.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup TRL resources.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL SFT trainer cleanup completed&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create data loader for training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create data loader for training.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Dataset not loaded. Call setup_data() first.&quot;</span><span class="p">)</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>

    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_collate_fn</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Evaluate the model performance with enhanced metrics.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate the model performance with enhanced metrics.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running TRL SFT evaluation for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Training not setup. Call train() first.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">eval_dataset</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span>

    <span class="c1"># Run evaluation</span>
    <span class="n">eval_results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;evaluate&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eval_dataset&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No eval_dataset available; skipping evaluation.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span>

    <span class="c1"># Add task type to results</span>
    <span class="n">eval_results</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>

    <span class="c1"># Calculate perplexity from loss (if available)</span>
    <span class="k">if</span> <span class="s2">&quot;eval_loss&quot;</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_perplexity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not calculate perplexity: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Add comprehensive quality metrics using SFTEvaluator for generation tasks</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.evaluator</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTEvaluator</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eval_dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">evaluator</span> <span class="o">=</span> <span class="n">SFTEvaluator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
                <span class="n">quality_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="p">)</span>

                <span class="c1"># Merge quality metrics (avoid duplicates)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">quality_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>  <span class="c1"># Don&#39;t override existing metrics</span>
                        <span class="n">eval_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">quality_metrics</span><span class="p">)</span><span class="si">}</span><span class="s2"> quality metrics&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not compute quality metrics: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Generate qualitative samples for generation tasks</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_samples</span><span class="p">()</span>
            <span class="n">eval_results</span><span class="p">[</span><span class="s1">&#39;qualitative_samples&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not generate qualitative samples: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">eval_results</span><span class="p">[</span><span class="s1">&#39;qualitative_samples&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT evaluation completed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span><span class="si">}</span><span class="s2"> metrics computed&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eval_results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.generate_samples" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_samples</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.generate_samples" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Public method to generate samples.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Public method to generate samples.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Sample generation not supported for classification tasks&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_samples</span><span class="p">()</span>
        <span class="c1"># Return limited number and ensure all have &#39;response&#39; key</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;generated_response&#39;</span> <span class="ow">in</span> <span class="n">s</span> <span class="ow">or</span> <span class="s1">&#39;response&#39;</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample generation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.get_sample_outputs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_sample_outputs</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.get_sample_outputs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get sample outputs for logging.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_sample_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get sample outputs for logging.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="c1"># Classification tasks don&#39;t generate samples</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="n">sample_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">))):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;messages&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>
            <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="p">)</span>

        <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">sample_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="n">text</span><span class="p">,</span>
            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;trl_sft&quot;</span><span class="p">,</span>
            <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>
        <span class="p">})</span>

    <span class="k">return</span> <span class="n">sample_outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.get_training_stats" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_training_stats</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.get_training_stats" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get enhanced training statistics and information.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_training_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get enhanced training statistics and information.&quot;&quot;&quot;</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_epochs</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;max_steps&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_peft</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;dataset_info&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;train_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;val_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eval_dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;loaded&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
            <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;has_peft&#39;</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;peft_config&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">stats</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if TRL is available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if TRL is available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">AutoModelForCausalLM</span><span class="p">,</span> 
            <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
            <span class="n">AutoModelForTokenClassification</span><span class="p">,</span>
            <span class="n">AutoTokenizer</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.run_experiment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">run_experiment</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.run_experiment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run a complete experiment with enhanced features.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">run_experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run a complete experiment with enhanced features.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting TRL SFT experiment: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Setup model and data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>

        <span class="c1"># Run zero-shot evaluation if configured</span>
        <span class="n">zero_shot_results</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;evaluation&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">evaluation</span><span class="p">,</span> <span class="s1">&#39;run_zero_shot&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running pre-training zero-shot evaluation...&quot;</span><span class="p">)</span>
            <span class="n">zero_shot_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_zero_shot_evaluation</span><span class="p">()</span>

        <span class="c1"># Start training</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">train_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="c1"># Evaluate after training</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running post-training evaluation...&quot;</span><span class="p">)</span>
        <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

        <span class="c1"># Combine results</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="s1">&#39;train_and_eval&#39;</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;train_results&#39;</span><span class="p">:</span> <span class="n">train_results</span><span class="p">,</span>
            <span class="s1">&#39;eval_results&#39;</span><span class="p">:</span> <span class="n">eval_results</span><span class="p">,</span>
            <span class="s1">&#39;training_stats&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_training_stats</span><span class="p">(),</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">),</span>
                <span class="s1">&#39;dataset&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="vm">__dict__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <span class="c1"># Add zero-shot results if available</span>
        <span class="k">if</span> <span class="n">zero_shot_results</span><span class="p">:</span>
            <span class="n">results</span><span class="p">[</span><span class="s1">&#39;zero_shot_evaluation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero_shot_results</span>

        <span class="c1"># Save results</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="n">output_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">results_path</span> <span class="o">=</span> <span class="n">output_dir</span> <span class="o">/</span> <span class="s2">&quot;experiment_results.yaml&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">results_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT experiment completed. Results saved to </span><span class="si">{</span><span class="n">results_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT experiment failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>
        <span class="k">raise</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.run_zero_shot_evaluation" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">run_zero_shot_evaluation</span><span class="p">(</span><span class="n">test_prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.run_zero_shot_evaluation" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run zero-shot evaluation before training with enhanced metrics.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">run_zero_shot_evaluation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run zero-shot evaluation before training with enhanced metrics.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running zero-shot evaluation for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Classification tasks don&#39;t support zero-shot evaluation</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Zero-shot evaluation not supported for classification tasks&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">test_prompts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Task-specific default prompts</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">What is AI?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Explain ML.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">How does training work?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;Human: Hello!</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: How are you?</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: Tell me about AI.</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;What is artificial intelligence?&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Explain machine learning briefly.&quot;</span><span class="p">,</span>
                <span class="s2">&quot;How does a computer work?&quot;</span>
            <span class="p">]</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">test_prompts</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                    <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                    <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span>
                <span class="p">)</span>

            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                <span class="s1">&#39;response&#39;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
                <span class="s1">&#39;response_length&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">()),</span>
                <span class="s1">&#39;coherence_score&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_coherence_score</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="p">})</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Zero-shot evaluation failed for prompt: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;prompt&#39;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                <span class="s1">&#39;response&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s1">&#39;response_length&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;coherence_score&#39;</span><span class="p">:</span> <span class="mf">0.0</span>
            <span class="p">})</span>

    <span class="c1"># Calculate aggregate metrics</span>
    <span class="n">avg_length</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;response_length&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">avg_coherence</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;coherence_score&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">successful_responses</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">)])</span>

    <span class="n">zero_shot_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="s1">&#39;zero_shot_results&#39;</span><span class="p">:</span> <span class="n">results</span><span class="p">,</span>
        <span class="s1">&#39;avg_response_length&#39;</span><span class="p">:</span> <span class="n">avg_length</span><span class="p">,</span>
        <span class="s1">&#39;avg_coherence_score&#39;</span><span class="p">:</span> <span class="n">avg_coherence</span><span class="p">,</span>
        <span class="s1">&#39;successful_responses&#39;</span><span class="p">:</span> <span class="n">successful_responses</span><span class="p">,</span>
        <span class="s1">&#39;success_rate&#39;</span><span class="p">:</span> <span class="n">successful_responses</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">({</span>
            <span class="s1">&#39;zero_shot_avg_length&#39;</span><span class="p">:</span> <span class="n">avg_length</span><span class="p">,</span>
            <span class="s1">&#39;zero_shot_coherence&#39;</span><span class="p">:</span> <span class="n">avg_coherence</span><span class="p">,</span>
            <span class="s1">&#39;zero_shot_success_rate&#39;</span><span class="p">:</span> <span class="n">successful_responses</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="p">})</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Zero-shot evaluation completed. Success rate: </span><span class="si">{</span><span class="n">successful_responses</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">zero_shot_metrics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.save_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_config</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.save_config" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save enhanced configuration to YAML file.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save enhanced configuration to YAML file.&quot;&quot;&quot;</span>
    <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_epochs</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;max_steps&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
        <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_peft</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT configuration saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the trained model and tokenizer.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>output_dir</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory to save to (defaults to config output_dir)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path where model was saved</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the trained model and tokenizer.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_dir: Directory to save to (defaults to config output_dir)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Path where model was saved</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;sft_model&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="n">output_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;trainer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No trainer available to save model&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;tokenizer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer saved to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No tokenizer available to save&quot;</span><span class="p">)</span>

    <span class="c1"># Save task type info</span>
    <span class="n">config_path</span> <span class="o">=</span> <span class="n">output_dir</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
    <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span>
    <span class="p">}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training config saved to </span><span class="si">{</span><span class="n">config_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Store for push_to_hub</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets for SFT training with task-aware formatting.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets for SFT training with task-aware formatting.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL SFT datasets: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Initialize dataset cache</span>
    <span class="n">cache_root</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;caching&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;root&quot;</span><span class="p">,</span> <span class="s2">&quot;./cache&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;caching&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;./cache&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="n">DatasetCache</span><span class="p">(</span><span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset cache initialized at: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span><span class="o">.</span><span class="n">cache_root</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Load dataset</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading dataset...&quot;</span><span class="p">)</span>
    <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

    <span class="c1"># Handle dataset config/subset</span>
    <span class="n">load_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">split</span> <span class="ow">or</span> <span class="s2">&quot;train&quot;</span><span class="p">}</span>
    <span class="n">dataset_name</span> <span class="o">=</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">name</span>
    <span class="n">dataset_subset</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;subset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
        <span class="n">dataset_subset</span> <span class="o">=</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">subset</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
        <span class="n">dataset_subset</span> <span class="o">=</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">config</span>

    <span class="c1"># Check if dataset has a registered custom loader</span>
    <span class="k">if</span> <span class="n">dataset_name</span> <span class="ow">in</span> <span class="n">DatasetRegistry</span><span class="o">.</span><span class="n">list_loaders</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using registered dataset loader: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">DatasetRegistry</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">split</span> <span class="ow">or</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="n">max_samples</span><span class="o">=</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span>
            <span class="o">**</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset_config</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Load dataset</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dataset_subset</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_subset</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;Config name is missing&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; requires a config/subset name. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Add &#39;subset&#39; or &#39;config&#39; to your DatasetConfig.&quot;</span>
                <span class="p">)</span>
            <span class="k">raise</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original dataset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

    <span class="c1">#  CRITICAL FIX: Shuffle dataset BEFORE selecting samples</span>
    <span class="c1"># This ensures balanced class distribution for classification tasks</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Shuffling dataset to ensure balanced sampling...&quot;</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Apply dataset size limits</span>
    <span class="k">if</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">percent</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s2">% of dataset: </span><span class="si">{</span><span class="n">dataset_size</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">dataset_config</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using max_samples limit: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

    <span class="c1"># Apply column mappings if needed</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">:</span>
        <span class="n">valid_mappings</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset_config</span><span class="o">.</span><span class="n">column_mapping</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">valid_mappings</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">valid_mappings</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns: </span><span class="si">{</span><span class="n">valid_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Task-specific formatting</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_dataset_for_task</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">)</span>

    <span class="c1"># Create evaluation split</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">200</span><span class="p">:</span>
            <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">test_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">50</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>

        <span class="n">split_ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created eval split. Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> | Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not create eval split: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFT dataset setup completed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup model using standard Transformers with task type awareness.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup model using standard Transformers with task type awareness.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL SFT model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task Type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
    <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL SFT&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">AutoModelForCausalLM</span><span class="p">,</span>
            <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
            <span class="n">AutoModelForTokenClassification</span><span class="p">,</span>
            <span class="n">AutoTokenizer</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Transformers not available.&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="c1"># Load tokenizer first</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading tokenizer...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>


    <span class="c1"># Set pad token if not set</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Set pad token to eos token&quot;</span><span class="p">)</span>

    <span class="c1"># Load model based on task type</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
        <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;num_labels&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading classification model with </span><span class="si">{</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
        <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;num_labels&#39;</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading token classification model with </span><span class="si">{</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Causal LM for generation tasks</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading causal language model&quot;</span><span class="p">)</span>

        <span class="c1"># Handle quantization configuration</span>
        <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">quantization_dict</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="k">if</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>

                <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">load_in_4bit</span><span class="p">:</span>
                    <span class="n">compute_dtype_str</span> <span class="o">=</span> <span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bnb_4bit_compute_dtype&#39;</span><span class="p">,</span> <span class="s1">&#39;bfloat16&#39;</span><span class="p">)</span>
                    <span class="n">compute_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">compute_dtype_str</span> <span class="o">==</span> <span class="s1">&#39;bfloat16&#39;</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>

                    <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                        <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">compute_dtype</span><span class="p">,</span>
                        <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bnb_4bit_quant_type&#39;</span><span class="p">,</span> <span class="s1">&#39;nf4&#39;</span><span class="p">),</span>
                        <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="n">quantization_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bnb_4bit_use_double_quant&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; 4-bit quantization enabled for memory optimization&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">load_in_8bit</span><span class="p">:</span>
                    <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; 8-bit quantization enabled for memory optimization&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  BitsAndBytes not available. Install with: pip install bitsandbytes&quot;</span><span class="p">)</span>
                <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Get max_memory from config if specified</span>
        <span class="n">max_memory</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_memory&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;torch_dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
            <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s1">&#39;device_map&#39;</span><span class="p">:</span> <span class="s1">&#39;auto&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;low_cpu_mem_usage&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Add max_memory if specified</span>
        <span class="k">if</span> <span class="n">max_memory</span><span class="p">:</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;max_memory&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_memory</span>

        <span class="k">if</span> <span class="n">quantization_config</span><span class="p">:</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;quantization_config&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Quantization config: </span><span class="si">{</span><span class="n">quantization_config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Only set these if not using quantization</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No quantization configured - loading full precision model&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>

        <span class="c1"># Move to GPU only if not using device_map=&#39;auto&#39; (which handles it automatically)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">quantization_config</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">model_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;device_map&#39;</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model moved to GPU&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">quantization_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded with quantization (device_map=&#39;auto&#39;)&quot;</span><span class="p">)</span>
            <span class="c1"># CRITICAL: When using quantization, PEFT adapters MUST be enabled</span>
            <span class="c1"># TRL SFTTrainer will handle this, but we need to ensure PEFT is enabled in config</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;peft_enabled&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  Quantization requires PEFT adapters. Enabling PEFT automatically.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">peft_enabled</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Setup tokenizer for specific tasks</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_setup_tokenizer_for_task</span><span class="p">()</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL SFT model setup completed successfully&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer vocab size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>SFT doesn't use reward functions.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SFT doesn&#39;t use reward functions.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SFT training doesn&#39;t use reward functions&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Train using TRL SFTTrainer with task-aware setup.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train using TRL SFTTrainer with task-aware setup.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting TRL SFT training for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Setup model and data if not already done</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorWithPadding</span><span class="p">,</span> <span class="n">DataCollatorForTokenClassification</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;TRL required for SFT training. Install with: pip install trl&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="c1"># Create training arguments</span>
    <span class="c1"># Get optimizer and scheduler configurations</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">....core.optimization</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_optimizer_for_config</span><span class="p">,</span> <span class="n">get_scheduler_for_config</span>
    <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
    <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

    <span class="c1"># Use config-specified optimizer or default to adamw_torch</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
    <span class="n">scheduler_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="s1">&#39;cosine&#39;</span><span class="p">)</span>

    <span class="c1"># Create optimizer configuration</span>
    <span class="n">optimizer_config</span> <span class="o">=</span> <span class="n">get_optimizer_for_config</span><span class="p">(</span>
        <span class="n">optimizer_name</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span> <span class="ow">or</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span> <span class="ow">or</span> <span class="mf">0.01</span>
    <span class="p">)</span>

    <span class="c1"># Calculate max_steps - use config value or calculate from epochs</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
    <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Calculate from epochs if max_steps not specified</span>
        <span class="n">epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">3</span>
        <span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="k">else</span> <span class="mi">1000</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span> <span class="ow">or</span> <span class="mi">2</span>
        <span class="n">grad_accum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">or</span> <span class="mi">4</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset_size</span> <span class="o">*</span> <span class="n">epochs</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">grad_accum</span><span class="p">)</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_steps</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># Minimum 10 steps</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calculated max_steps=</span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2"> from </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> epochs, </span><span class="si">{</span><span class="n">dataset_size</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

    <span class="c1"># Calculate warmup steps</span>
    <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">:</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">)</span>

    <span class="c1"># Create scheduler configuration</span>
    <span class="n">scheduler_config</span> <span class="o">=</span> <span class="n">get_scheduler_for_config</span><span class="p">(</span>
        <span class="n">scheduler_name</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">,</span>
        <span class="n">warmup_steps</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">kwargs_to_str</span><span class="p">(</span><span class="n">kwargs_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert optimizer/scheduler kwargs dict to string format.&quot;&quot;&quot;</span>
        <span class="c1"># Exclude lr and weight_decay since TrainingArguments already sets them</span>
        <span class="n">filtered</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">]}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">filtered</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">v</span><span class="p">))</span><span class="si">}</span><span class="s1">)&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="nb">tuple</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">filtered</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="n">optim_args_str</span><span class="o">=</span><span class="n">kwargs_to_str</span><span class="p">(</span><span class="n">optimizer_config</span><span class="p">[</span><span class="s1">&#39;optimizer_kwargs&#39;</span><span class="p">])</span>
    <span class="c1"># print(lr_scheduler_kwargs_str)</span>
    <span class="c1"># print(scheduler_config)</span>
    <span class="n">filtered_scheduler_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">scheduler_config</span><span class="p">[</span><span class="s1">&#39;lr_scheduler_kwargs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> 
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;num_training_steps&#39;</span><span class="p">,</span> <span class="s1">&#39;num_warmup_steps&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="c1"># Build TrainingArguments kwargs, conditionally including optim_args</span>
    <span class="n">training_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="s2">&quot;max_steps&quot;</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
        <span class="s2">&quot;per_device_train_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span> <span class="ow">or</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">or</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span> <span class="ow">or</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span> <span class="ow">or</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="n">warmup_steps</span><span class="p">,</span>
        <span class="s2">&quot;logging_steps&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;log_interval&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="s2">&quot;save_steps&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
        <span class="s2">&quot;eval_steps&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
        <span class="s2">&quot;eval_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
        <span class="s2">&quot;save_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="s2">&quot;load_best_model_at_end&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;report_to&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;run_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="p">,</span>
        <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
        <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>
        <span class="s2">&quot;dataloader_num_workers&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;remove_unused_columns&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;optim&quot;</span><span class="p">:</span> <span class="n">optimizer_name</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler_type&quot;</span><span class="p">:</span> <span class="n">scheduler_name</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler_kwargs&quot;</span><span class="p">:</span> <span class="n">filtered_scheduler_kwargs</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Only include optim_args if it&#39;s not None/empty and valid.</span>
    <span class="c1"># For 8-bit optimizers (adamw_8bit, paged_adamw_8bit, etc.), bitsandbytes handles kwargs internally,</span>
    <span class="c1"># so we skip optim_args to avoid Transformers parsing issues.</span>
    <span class="c1"># Also skip if the string doesn&#39;t contain &quot;=&quot; (would cause parsing errors).</span>
    <span class="n">should_skip_optim_args</span> <span class="o">=</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">optim_args_str</span> <span class="ow">or</span>  <span class="c1"># None or empty string</span>
        <span class="ow">not</span> <span class="n">optim_args_str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="ow">or</span>  <span class="c1"># Whitespace only</span>
        <span class="s2">&quot;=&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">optim_args_str</span> <span class="ow">or</span>  <span class="c1"># Invalid format (no key=value pairs)</span>
        <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="ow">in</span> <span class="n">optimizer_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;8bit&quot;</span><span class="p">,</span> <span class="s2">&quot;8_bit&quot;</span><span class="p">,</span> <span class="s2">&quot;bnb&quot;</span><span class="p">,</span> <span class="s2">&quot;paged&quot;</span><span class="p">])</span>  <span class="c1"># 8-bit optimizers</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">should_skip_optim_args</span><span class="p">:</span>
        <span class="n">training_kwargs</span><span class="p">[</span><span class="s2">&quot;optim_args&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optim_args_str</span>

    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">**</span><span class="n">training_kwargs</span><span class="p">)</span>

    <span class="c1"># Create trainer based on task type</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">]:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_classification_trainer</span><span class="p">(</span><span class="n">training_args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Generation tasks use SFTTrainer</span>
        <span class="c1"># Setup PEFT config if enabled (required for quantized models)</span>
        <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;peft_enabled&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span>

                <span class="c1"># Get LoRA parameters from config</span>
                <span class="n">lora_r</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_rank&#39;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
                <span class="n">lora_alpha</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
                <span class="n">lora_dropout</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                <span class="c1"># If target_modules not specified, use default for Llama models</span>
                <span class="k">if</span> <span class="n">target_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">]</span>

                <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                    <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                    <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                    <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span>
                    <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; PEFT LoRA config created: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, modules=</span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  PEFT not available. Install with: pip install peft&quot;</span><span class="p">)</span>
                <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Generation tasks use SFTTrainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">,</span>  <span class="c1"># Pass PEFT config to SFTTrainer</span>
        <span class="p">)</span>

    <span class="c1"># Record training start</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting TRL SFT Training - Task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Start training</span>
    <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Record training end</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_duration</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

    <span class="c1"># Log training metrics</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>

    <span class="c1"># Save model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

    <span class="c1"># Add to training history</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">(),</span>
        <span class="s1">&#39;duration&#39;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
        <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="s1">&#39;model_path&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
    <span class="p">})</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL SFT training completed successfully!&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Return training results</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;training_time&#39;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
        <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="s1">&#39;model_path&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">,</span> <span class="p">{}),</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.sft.TRLSFTTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.trl.sft.sft.TRLSFTTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute training step (handled by TRL trainer).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute training step (handled by TRL trainer).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Example</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.backends.trl.sft.sft</span><span class="w"> </span><span class="kn">import</span> <span class="n">TRLSFTTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">SFTConfig</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TRLSFTTrainer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<h4 id="trldpotrainer"><code>TRLDPOTrainer</code><a class="headerlink" href="#trldpotrainer" title="Permanent link">&para;</a></h4>
<p>TRL backend for Direct Preference Optimization.</p>


<div class="doc doc-object doc-class">



<a id="backends.trl.rl.dpo.dpo.TRLDPOTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.rl.trainer_base.TrainerBase">TrainerBase</span></code></p>



        <p>TRL-based DPO trainer using TRL's DPOTrainer.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TRLDPOTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;TRL-based DPO trainer using TRL&#39;s DPOTrainer.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize TRL DPO trainer.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if TRL DPO trainer is available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_obj</span><span class="p">,</span> <span class="o">*</span><span class="n">attr_names</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely get config value from multiple possible attribute names.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">config_obj</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">config_obj</span><span class="p">[</span><span class="n">attr_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">default</span>


    <span class="c1"># Required abstract methods</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup data - delegates to setup_dataset.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup rewards - not used in DPO (uses preferences).&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;DPO uses preference pairs instead of explicit rewards&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Single training step - handled internally by TRL DPOTrainer.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Trainer not initialized. Call train() first.&quot;</span><span class="p">)</span>
        <span class="c1"># The actual training loop is handled by self.trainer.train()</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup model and tokenizer for DPO.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL DPO model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


            <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
            <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL DPO&quot;</span><span class="p">)</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

            <span class="c1"># Determine dtype</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;bf16&quot;</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;fp16&quot;</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;fp32&quot;</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>

            <span class="c1"># Load tokenizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="c1"># Set pad token if not set</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

            <span class="c1"># Setup quantization config</span>
            <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">use_quantization</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                    <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                        <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
                        <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
                        <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">use_quantization</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using 4-bit quantization with BitsAndBytesConfig&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                    <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                        <span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">use_quantization</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using 8-bit quantization with BitsAndBytesConfig&quot;</span><span class="p">)</span>

            <span class="c1"># Load main model</span>
            <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
                <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="n">quantization_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;quantization_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>
            <span class="c1"># ---- Extract LoRA config safely ----</span>
            <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span>
            <span class="p">)</span>
            <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span>
            <span class="p">)</span>
            <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
                <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;LoRA config: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, dropout=</span><span class="si">{</span><span class="n">lora_dropout</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target modules: </span><span class="si">{</span><span class="n">lora_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># ---- Apply LoRA ----</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

            <span class="k">if</span> <span class="n">use_quantization</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">prepare_model_for_kbit_training</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

                <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                    <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                    <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                    <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                    <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applied LoRA adapters to quantized model&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;use_peft&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                    <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                    <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                    <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                    <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applied LoRA adapters to model&quot;</span><span class="p">)</span>


            <span class="c1"># Create reference model (frozen copy)</span>
            <span class="c1"># For quantized models, reference model uses same quantization but no LoRA</span>
            <span class="n">ref_model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
                <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="n">quantization_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ref_model_kwargs</span><span class="p">[</span><span class="s2">&quot;quantization_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">ref_model_kwargs</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPO model setup completed successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup TRL DPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup and prepare preference dataset for DPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Setup datasets for GRPO training using unified DataManager.&quot;&quot;&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up GRPO datasets with DataManager...&quot;</span><span class="p">)</span>

            <span class="c1"># Extract dataset configuration</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
                <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

            <span class="c1"># Extract parameters</span>
            <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
            <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Advanced DataManager features</span>
            <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">max_eval_samples</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_eval_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Initialize DataManager for GRPO task</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

            <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;dpo&quot;</span><span class="p">,</span>
                <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>           <span class="c1"># System prompt</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
                <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>       <span class="c1">#  ADD THIS - Enable thinking mode</span>
                <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
                <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
                <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
                <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Load dataset - DataManager handles everything including chat template</span>
            <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
                <span class="n">dataset_name</span><span class="p">,</span>
                <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Extract train and validation splits</span>


            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>

            <span class="c1"># === ROBUST COLUMN DETECTION ===</span>
            <span class="c1"># Check what columns actually exist</span>

            <span class="n">available_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
            <span class="c1"># Detect the column structure</span>
            <span class="n">has_prompt</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
            <span class="n">has_chosen</span> <span class="o">=</span> <span class="s2">&quot;chosen&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
            <span class="n">has_rejected</span> <span class="o">=</span> <span class="s2">&quot;rejected&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>

            <span class="c1"># Log first sample to understand the structure</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Define a robust filtering function that handles different column structures</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">filter_valid_examples</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Filter out invalid examples with flexible column detection.&quot;&quot;&quot;</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># If we have the standard DPO format</span>
                    <span class="k">if</span> <span class="n">has_prompt</span> <span class="ow">and</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> 
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> 
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span><span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="p">)</span>

                    <span class="c1"># Alternative: dataset might have &#39;chosen&#39; and &#39;rejected&#39; only</span>
                    <span class="c1"># (TRL can handle this format too)</span>
                    <span class="k">elif</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_prompt</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> 
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="p">)</span>

                    <span class="c1"># If columns don&#39;t match expected format, log and skip</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected dataset format. Available columns: </span><span class="si">{</span><span class="n">available_columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">return</span> <span class="kc">False</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error filtering example: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>

            <span class="c1"># Filter empty examples</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">initial_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">filter_valid_examples</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid examples&quot;</span>
                <span class="p">)</span>
                <span class="n">filtered_count</span> <span class="o">=</span> <span class="n">initial_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">filtered_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtered out </span><span class="si">{</span><span class="n">filtered_count</span><span class="si">}</span><span class="s2"> invalid examples&quot;</span><span class="p">)</span>

            <span class="c1"># Filter by approximate token count</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">is_valid_length</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Check if example fits within max sequence length.&quot;&quot;&quot;</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Rough approximation: 1 token  4 characters</span>

                    <span class="c1"># Handle different column structures</span>
                    <span class="k">if</span> <span class="n">has_prompt</span><span class="p">:</span>
                        <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># If no prompt, we&#39;ll check chosen/rejected only</span>
                        <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="mi">0</span>

                    <span class="n">chosen_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                    <span class="n">rejected_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>

                    <span class="c1"># Each response is concatenated with prompt, so check both</span>
                    <span class="k">return</span> <span class="p">(</span>
                        <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">chosen_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span> <span class="ow">and</span> 
                        <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">rejected_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error checking length: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>

            <span class="n">original_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">is_valid_length</span><span class="p">,</span> 
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long sequences&quot;</span>
            <span class="p">)</span>
            <span class="n">filtered_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">original_size</span> <span class="o">-</span> <span class="n">filtered_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtered </span><span class="si">{</span><span class="n">original_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filtered_size</span><span class="si">}</span><span class="s2"> samples that were too long&quot;</span><span class="p">)</span>

            <span class="c1"># Apply same filtering to eval dataset if it exists</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">filter_valid_examples</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid eval examples&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">is_valid_length</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long eval sequences&quot;</span>
                <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DPO dataset prepared: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train samples&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

            <span class="c1"># Log final sample for debugging</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Final dataset structure:&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">preview</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="n">value</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup TRL DPOTrainer.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL DPOTrainer&quot;</span><span class="p">)</span>

            <span class="c1"># Create DPO configuration</span>
            <span class="c1"># Get optimizer and scheduler configurations</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.optimization</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_optimizer_for_config</span><span class="p">,</span> <span class="n">get_scheduler_for_config</span>

            <span class="c1"># Use config-specified optimizer or default to adamw_torch</span>
            <span class="n">optimizer_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
            <span class="n">scheduler_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="s1">&#39;cosine&#39;</span><span class="p">)</span>

            <span class="c1"># Create optimizer configuration</span>
            <span class="n">optimizer_config</span> <span class="o">=</span> <span class="n">get_optimizer_for_config</span><span class="p">(</span>
                <span class="n">optimizer_name</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span> <span class="ow">or</span> <span class="mf">0.01</span>
            <span class="p">)</span>

            <span class="c1"># Calculate warmup steps</span>
            <span class="n">num_train_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="ow">or</span> <span class="mi">1</span>
            <span class="c1"># Estimate max_steps for scheduler if not provided</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="s1">&#39;__len__&#39;</span><span class="p">):</span>
                <span class="c1"># Rough estimation: steps = epochs * (dataset_size / batch_size / accumulation)</span>
                <span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span> <span class="ow">or</span> <span class="mi">1</span>
                <span class="n">accumulation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">or</span> <span class="mi">1</span>
                <span class="n">effective_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">accumulation</span>
                <span class="n">max_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_train_epochs</span> <span class="o">*</span> <span class="n">dataset_size</span> <span class="o">/</span> <span class="n">effective_batch_size</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># fallback</span>

            <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">:</span>
                <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">)</span>

            <span class="c1"># Create scheduler configuration</span>
            <span class="n">scheduler_config</span> <span class="o">=</span> <span class="n">get_scheduler_for_config</span><span class="p">(</span>
                <span class="n">scheduler_name</span><span class="p">,</span>
                <span class="n">max_steps</span><span class="p">,</span>
                <span class="n">warmup_steps</span>
            <span class="p">)</span>
            <span class="c1"># print( scheduler_config)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">kwargs_to_str</span><span class="p">(</span><span class="n">kwargs_dict</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Convert optimizer/scheduler kwargs dict to string format.&quot;&quot;&quot;</span>
                <span class="k">return</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">v</span><span class="p">))</span><span class="si">}</span><span class="s1">)&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="nb">tuple</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="k">if</span> <span class="n">kwargs_dict</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="n">optim_args_str</span><span class="o">=</span><span class="n">kwargs_to_str</span><span class="p">(</span><span class="n">optimizer_config</span><span class="p">[</span><span class="s1">&#39;optimizer_kwargs&#39;</span><span class="p">])</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

            <span class="c1"># Evaluation parameters</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
            <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
            <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
            <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eval_loss&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Logging parameters</span>
            <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;report_to&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Use eval_dataset-aware defaults</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
                <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>


            <span class="c1"># Get max_steps from config (if set, it overrides num_train_epochs)</span>
            <span class="n">config_max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">dpo_config</span> <span class="o">=</span> <span class="n">DPOConfig</span><span class="p">(</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
                <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_train_epochs</span><span class="p">,</span>
                <span class="n">max_steps</span><span class="o">=</span><span class="n">config_max_steps</span> <span class="k">if</span> <span class="n">config_max_steps</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># -1 means use num_train_epochs</span>
                <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
                <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>  <span class="c1"># ADD THIS</span>
                <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>

                <span class="c1"># Evaluation parameters</span>
                <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
                <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>

                <span class="c1"># Logging parameters</span>
                <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
                <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>

                <span class="c1"># Save parameters</span>
                <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
                <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
                <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>
                <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>
                <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
                <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>

                <span class="c1"># Optimizer and scheduler</span>
                <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="n">scheduler_name</span><span class="p">,</span>
                <span class="n">optim</span><span class="o">=</span><span class="n">optimizer_name</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">[</span><span class="s1">&#39;optimizer_kwargs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
                <span class="n">optim_args</span><span class="o">=</span><span class="n">optim_args_str</span><span class="p">,</span>

                <span class="c1"># Precision</span>
                <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

                <span class="c1"># Data handling</span>
                <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

                <span class="c1"># DPO-specific parameters</span>
                <span class="n">beta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span>
                <span class="n">loss_type</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">),</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">max_prompt_length</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span>
                <span class="n">truncation_mode</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;truncation_mode&#39;</span><span class="p">,</span> <span class="s1">&#39;keep_end&#39;</span><span class="p">),</span>
                <span class="n">precompute_ref_log_probs</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;precompute_ref_log_probs&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>

                <span class="c1"># Logging configuration</span>
                <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span> <span class="k">if</span> <span class="n">report_to</span> <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]),</span>
            <span class="p">)</span>


            <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
                <span class="n">backend_config</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;dpo&#39;</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">dpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>



            <span class="c1"># Create trainer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">DPOTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPOTrainer setup completed&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup DPO trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run DPO training.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting TRL DPO training&quot;</span><span class="p">)</span>

            <span class="c1"># Setup components</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

            <span class="c1"># Run training</span>
            <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Save model</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPO training completed successfully&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_runtime&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">model_path</span><span class="p">,</span>
                <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_steps&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DPO training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="c1"># def evaluate(self) -&gt; Dict[str, Any]:</span>
    <span class="c1">#     &quot;&quot;&quot;Evaluate the trained model.&quot;&quot;&quot;</span>
    <span class="c1">#     try:</span>
    <span class="c1">#         if not self.trainer or not self.eval_dataset:</span>
    <span class="c1">#             logger.warning(&quot;No trainer or evaluation dataset available&quot;)</span>
    <span class="c1">#             return {}</span>

    <span class="c1">#         logger.info(&quot;Running DPO evaluation&quot;)</span>

    <span class="c1">#         # Run evaluation</span>
    <span class="c1">#         eval_result = self.trainer.evaluate()</span>

    <span class="c1">#         logger.info(&quot;DPO evaluation completed&quot;)</span>

    <span class="c1">#         return {</span>
    <span class="c1">#             &quot;eval_loss&quot;: eval_result.get(&quot;eval_loss&quot;, 0),</span>
    <span class="c1">#             &quot;eval_metrics&quot;: eval_result</span>
    <span class="c1">#         }</span>

    <span class="c1">#     except Exception as e:</span>
    <span class="c1">#         logger.error(f&quot;DPO evaluation failed: {e}&quot;)</span>
    <span class="c1">#         return {}</span>
    <span class="c1"># def evaluate(self, eval_dataset=None, metric_key_prefix: str = &quot;eval&quot;,use_custom_evaluator=False, **kwargs) -&gt; Dict[str, float]:</span>
    <span class="c1">#     # Setup evaluators on first call</span>
    <span class="c1">#     if self.base_evaluator is None and self.rl_evaluator is None:</span>
    <span class="c1">#         self.setup_custom_evaluator(evaluator_type=&quot;auto&quot;)</span>

    <span class="c1">#     # Call parent&#39;s evaluate method</span>
    <span class="c1">#     return super().evaluate(</span>
    <span class="c1">#         eval_dataset=eval_dataset,</span>
    <span class="c1">#         metric_key_prefix=metric_key_prefix,</span>
    <span class="c1">#         use_custom_evaluator=use_custom_evaluator, </span>
    <span class="c1">#         **kwargs</span>
    <span class="c1">#     )</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/dpo&#39;</span><span class="p">)</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saved successfully&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">save_path</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Save failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Load model and tokenizer</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize TRL DPO trainer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize TRL DPO trainer.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if TRL DPO trainer is available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if TRL DPO trainer is available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a trained model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a trained model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/dpo&#39;</span><span class="p">)</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saved successfully&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">save_path</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Save failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup data - delegates to setup_dataset.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup data - delegates to setup_dataset.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_dataset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_dataset</span><span class="p">()</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_dataset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup and prepare preference dataset for DPO training using unified DataManager.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup and prepare preference dataset for DPO training using unified DataManager.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets for GRPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up GRPO datasets with DataManager...&quot;</span><span class="p">)</span>

        <span class="c1"># Extract dataset configuration</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

        <span class="c1"># Extract parameters</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Advanced DataManager features</span>
        <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">max_eval_samples</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_eval_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize DataManager for GRPO task</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

        <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;dpo&quot;</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>           <span class="c1"># System prompt</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
            <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>       <span class="c1">#  ADD THIS - Enable thinking mode</span>
            <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
            <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
            <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Load dataset - DataManager handles everything including chat template</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Extract train and validation splits</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>

        <span class="c1"># === ROBUST COLUMN DETECTION ===</span>
        <span class="c1"># Check what columns actually exist</span>

        <span class="n">available_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="c1"># Detect the column structure</span>
        <span class="n">has_prompt</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
        <span class="n">has_chosen</span> <span class="o">=</span> <span class="s2">&quot;chosen&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
        <span class="n">has_rejected</span> <span class="o">=</span> <span class="s2">&quot;rejected&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>

        <span class="c1"># Log first sample to understand the structure</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Define a robust filtering function that handles different column structures</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">filter_valid_examples</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Filter out invalid examples with flexible column detection.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># If we have the standard DPO format</span>
                <span class="k">if</span> <span class="n">has_prompt</span> <span class="ow">and</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> 
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> 
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span><span class="o">&gt;</span> <span class="mi">0</span>
                    <span class="p">)</span>

                <span class="c1"># Alternative: dataset might have &#39;chosen&#39; and &#39;rejected&#39; only</span>
                <span class="c1"># (TRL can handle this format too)</span>
                <span class="k">elif</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_prompt</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> 
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
                    <span class="p">)</span>

                <span class="c1"># If columns don&#39;t match expected format, log and skip</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected dataset format. Available columns: </span><span class="si">{</span><span class="n">available_columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error filtering example: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Filter empty examples</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">initial_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">filter_valid_examples</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid examples&quot;</span>
            <span class="p">)</span>
            <span class="n">filtered_count</span> <span class="o">=</span> <span class="n">initial_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">filtered_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtered out </span><span class="si">{</span><span class="n">filtered_count</span><span class="si">}</span><span class="s2"> invalid examples&quot;</span><span class="p">)</span>

        <span class="c1"># Filter by approximate token count</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">is_valid_length</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Check if example fits within max sequence length.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Rough approximation: 1 token  4 characters</span>

                <span class="c1"># Handle different column structures</span>
                <span class="k">if</span> <span class="n">has_prompt</span><span class="p">:</span>
                    <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If no prompt, we&#39;ll check chosen/rejected only</span>
                    <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">chosen_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                <span class="n">rejected_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>

                <span class="c1"># Each response is concatenated with prompt, so check both</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">chosen_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span> <span class="ow">and</span> 
                    <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">rejected_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error checking length: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="n">original_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
            <span class="n">is_valid_length</span><span class="p">,</span> 
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long sequences&quot;</span>
        <span class="p">)</span>
        <span class="n">filtered_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">original_size</span> <span class="o">-</span> <span class="n">filtered_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtered </span><span class="si">{</span><span class="n">original_size</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filtered_size</span><span class="si">}</span><span class="s2"> samples that were too long&quot;</span><span class="p">)</span>

        <span class="c1"># Apply same filtering to eval dataset if it exists</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">filter_valid_examples</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid eval examples&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">is_valid_length</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long eval sequences&quot;</span>
            <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DPO dataset prepared: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train samples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Log final sample for debugging</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Final dataset structure:&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">preview</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="n">value</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup model and tokenizer for DPO.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup model and tokenizer for DPO.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL DPO model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL DPO&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Determine dtype</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;bf16&quot;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;fp16&quot;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;fp32&quot;</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>

        <span class="c1"># Load tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Set pad token if not set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

        <span class="c1"># Setup quantization config</span>
        <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">use_quantization</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
                    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
                    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">use_quantization</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using 4-bit quantization with BitsAndBytesConfig&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                    <span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">use_quantization</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using 8-bit quantization with BitsAndBytesConfig&quot;</span><span class="p">)</span>

        <span class="c1"># Load main model</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">quantization_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;quantization_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>
        <span class="c1"># ---- Extract LoRA config safely ----</span>
        <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span>
        <span class="p">)</span>
        <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span>
        <span class="p">)</span>
        <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
            <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;LoRA config: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, dropout=</span><span class="si">{</span><span class="n">lora_dropout</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target modules: </span><span class="si">{</span><span class="n">lora_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># ---- Apply LoRA ----</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

        <span class="k">if</span> <span class="n">use_quantization</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">prepare_model_for_kbit_training</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applied LoRA adapters to quantized model&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;use_peft&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applied LoRA adapters to model&quot;</span><span class="p">)</span>


        <span class="c1"># Create reference model (frozen copy)</span>
        <span class="c1"># For quantized models, reference model uses same quantization but no LoRA</span>
        <span class="n">ref_model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">quantization_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ref_model_kwargs</span><span class="p">[</span><span class="s2">&quot;quantization_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ref_model_kwargs</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPO model setup completed successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup TRL DPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup rewards - not used in DPO (uses preferences).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup rewards - not used in DPO (uses preferences).&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;DPO uses preference pairs instead of explicit rewards&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup TRL DPOTrainer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup TRL DPOTrainer.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL DPOTrainer&quot;</span><span class="p">)</span>

        <span class="c1"># Create DPO configuration</span>
        <span class="c1"># Get optimizer and scheduler configurations</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.optimization</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_optimizer_for_config</span><span class="p">,</span> <span class="n">get_scheduler_for_config</span>

        <span class="c1"># Use config-specified optimizer or default to adamw_torch</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
        <span class="n">scheduler_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="s1">&#39;cosine&#39;</span><span class="p">)</span>

        <span class="c1"># Create optimizer configuration</span>
        <span class="n">optimizer_config</span> <span class="o">=</span> <span class="n">get_optimizer_for_config</span><span class="p">(</span>
            <span class="n">optimizer_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span> <span class="ow">or</span> <span class="mf">0.01</span>
        <span class="p">)</span>

        <span class="c1"># Calculate warmup steps</span>
        <span class="n">num_train_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span> <span class="ow">or</span> <span class="mi">1</span>
        <span class="c1"># Estimate max_steps for scheduler if not provided</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="s1">&#39;__len__&#39;</span><span class="p">):</span>
            <span class="c1"># Rough estimation: steps = epochs * (dataset_size / batch_size / accumulation)</span>
            <span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span> <span class="ow">or</span> <span class="mi">1</span>
            <span class="n">accumulation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">or</span> <span class="mi">1</span>
            <span class="n">effective_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">accumulation</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_train_epochs</span> <span class="o">*</span> <span class="n">dataset_size</span> <span class="o">/</span> <span class="n">effective_batch_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># fallback</span>

        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">:</span>
            <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">)</span>

        <span class="c1"># Create scheduler configuration</span>
        <span class="n">scheduler_config</span> <span class="o">=</span> <span class="n">get_scheduler_for_config</span><span class="p">(</span>
            <span class="n">scheduler_name</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="p">,</span>
            <span class="n">warmup_steps</span>
        <span class="p">)</span>
        <span class="c1"># print( scheduler_config)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">kwargs_to_str</span><span class="p">(</span><span class="n">kwargs_dict</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Convert optimizer/scheduler kwargs dict to string format.&quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">v</span><span class="p">))</span><span class="si">}</span><span class="s1">)&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="nb">tuple</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="k">if</span> <span class="n">kwargs_dict</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">optim_args_str</span><span class="o">=</span><span class="n">kwargs_to_str</span><span class="p">(</span><span class="n">optimizer_config</span><span class="p">[</span><span class="s1">&#39;optimizer_kwargs&#39;</span><span class="p">])</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Evaluation parameters</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eval_loss&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Logging parameters</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;report_to&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Use eval_dataset-aware defaults</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>


        <span class="c1"># Get max_steps from config (if set, it overrides num_train_epochs)</span>
        <span class="n">config_max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">dpo_config</span> <span class="o">=</span> <span class="n">DPOConfig</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_train_epochs</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="n">config_max_steps</span> <span class="k">if</span> <span class="n">config_max_steps</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># -1 means use num_train_epochs</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>  <span class="c1"># ADD THIS</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>

            <span class="c1"># Evaluation parameters</span>
            <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>

            <span class="c1"># Logging parameters</span>
            <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>

            <span class="c1"># Save parameters</span>
            <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>
            <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>
            <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
            <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>

            <span class="c1"># Optimizer and scheduler</span>
            <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="n">scheduler_name</span><span class="p">,</span>
            <span class="n">optim</span><span class="o">=</span><span class="n">optimizer_name</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">optimizer_config</span><span class="p">[</span><span class="s1">&#39;optimizer_kwargs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
            <span class="n">optim_args</span><span class="o">=</span><span class="n">optim_args_str</span><span class="p">,</span>

            <span class="c1"># Precision</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

            <span class="c1"># Data handling</span>
            <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

            <span class="c1"># DPO-specific parameters</span>
            <span class="n">beta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span>
            <span class="n">loss_type</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">),</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">max_prompt_length</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">truncation_mode</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;truncation_mode&#39;</span><span class="p">,</span> <span class="s1">&#39;keep_end&#39;</span><span class="p">),</span>
            <span class="n">precompute_ref_log_probs</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;precompute_ref_log_probs&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>

            <span class="c1"># Logging configuration</span>
            <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span> <span class="k">if</span> <span class="n">report_to</span> <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]),</span>
        <span class="p">)</span>


        <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
            <span class="n">backend_config</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;dpo&#39;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">dpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>



        <span class="c1"># Create trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">DPOTrainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span><span class="p">,</span>
            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPOTrainer setup completed&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup DPO trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run DPO training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run DPO training.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting TRL DPO training&quot;</span><span class="p">)</span>

        <span class="c1"># Setup components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Run training</span>
        <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Save model</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPO training completed successfully&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_runtime&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">model_path</span><span class="p">,</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_steps&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DPO training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.dpo.dpo.TRLDPOTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.trl.rl.dpo.dpo.TRLDPOTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Single training step - handled internally by TRL DPOTrainer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single training step - handled internally by TRL DPOTrainer.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Trainer not initialized. Call train() first.&quot;</span><span class="p">)</span>
    <span class="c1"># The actual training loop is handled by self.trainer.train()</span>
    <span class="k">return</span> <span class="p">{}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Example</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.backends.trl.rl.dpo.dpo</span><span class="w"> </span><span class="kn">import</span> <span class="n">TRLDPOTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.rl.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnifiedConfig</span><span class="p">,</span> <span class="n">AlgorithmType</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">UnifiedConfig</span><span class="p">(</span><span class="n">algo</span><span class="o">=</span><span class="n">AlgorithmType</span><span class="o">.</span><span class="n">DPO</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TRLDPOTrainer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<h4 id="trlppotrainer"><code>TRLPPOTrainer</code><a class="headerlink" href="#trlppotrainer" title="Permanent link">&para;</a></h4>
<p>TRL backend for Proximal Policy Optimization.</p>


<div class="doc doc-object doc-class">



<a id="backends.trl.rl.ppo.ppo.TRLPPOTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.rl.trainer_base.TrainerBase">TrainerBase</span></code></p>



        <p>PPO trainer using pure TRL PPOTrainer with math, code, and enhanced rewards.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TRLPPOTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;PPO trainer using pure TRL PPOTrainer with math, code, and enhanced rewards.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if TRL is available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup models (policy, reference, reward, value) using standard Transformers.&quot;&quot;&quot;</span>
        <span class="c1"># Extract model config values safely</span>
        <span class="n">policy_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;name_or_path&#39;</span><span class="p">,</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>


       <span class="c1"># Check if integrated reward training is configured</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;reward_training&#39;</span><span class="p">)</span> <span class="ow">and</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Training custom reward model before PPO...&quot;</span><span class="p">)</span>
            <span class="n">reward_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_custom_reward_model</span><span class="p">()</span>

            <span class="c1"># Override reward_model_name with trained model path</span>
            <span class="n">reward_model_name</span> <span class="o">=</span> <span class="n">reward_model_path</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Custom reward model trained and saved to: </span><span class="si">{</span><span class="n">reward_model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Extract from config as normal</span>
            <span class="n">reward_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;reward_model_name&#39;</span><span class="p">,</span>
                <span class="s1">&#39;reward_path&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">value_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;reward_value_model&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">sft_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;sft_path&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">trust_remote_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;device_map&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>

        <span class="n">is_ddp</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">device_map</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;DDP&quot;</span><span class="p">,</span> <span class="s2">&quot;ddp&quot;</span><span class="p">]</span> <span class="ow">or</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ACCELERATE_USE_DDP&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;true&#39;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_ddp</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">PartialState</span>
            <span class="n">device_string</span> <span class="o">=</span> <span class="n">PartialState</span><span class="p">()</span><span class="o">.</span><span class="n">process_index</span>
            <span class="n">device_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="n">device_string</span><span class="p">}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;DDP mode detected: device_map=</span><span class="se">{{</span><span class="s2">&#39;&#39;: </span><span class="si">{</span><span class="n">device_string</span><span class="si">}</span><span class="se">}}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL PPO&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Quantization settings</span>
        <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Auto-detect quantization from model name</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">load_in_4bit</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">load_in_8bit</span><span class="p">:</span>
            <span class="n">model_name_lower</span> <span class="o">=</span> <span class="n">policy_model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="s1">&#39;bnb-4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;awq&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Auto-detected 4-bit quantization from model name: </span><span class="si">{</span><span class="n">policy_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="s1">&#39;bnb-8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Auto-detected 8-bit quantization from model name: </span><span class="si">{</span><span class="n">policy_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Auto-enable PEFT if using quantization</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_peft</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Quantization detected - auto-enabling PEFT/LoRA adapters (required for training)&quot;</span><span class="p">)</span>
            <span class="n">use_peft</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL PPO models&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Policy model: </span><span class="si">{</span><span class="n">policy_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SFT path: </span><span class="si">{</span><span class="n">sft_model_path</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="s1">&#39;Same as policy&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model: </span><span class="si">{</span><span class="n">reward_model_name</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="s1">&#39;Same as value model&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value model: </span><span class="si">{</span><span class="n">value_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Transformers not available. Install with: pip install transformers&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># Load tokenizer</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading tokenizer...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">policy_model_name</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="n">trust_remote_code</span><span class="p">,</span>
        <span class="p">)</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">!=</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;left&quot;</span>

        <span class="c1"># Set pad token if not set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Set pad token to eos token&quot;</span><span class="p">)</span>

        <span class="c1"># Common model kwargs</span>
        <span class="n">base_model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>
            <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="n">trust_remote_code</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Add quantization if specified for policy model</span>
        <span class="n">policy_model_kwargs</span> <span class="o">=</span> <span class="n">base_model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">load_in_4bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading policy model with 4-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
            <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">load_in_8bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading policy model with 8-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Load policy model (from SFT path if provided, else base model)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading policy model...&quot;</span><span class="p">)</span>
        <span class="n">policy_path</span> <span class="o">=</span> <span class="n">sft_model_path</span> <span class="ow">or</span> <span class="n">policy_model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">policy_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">policy_model_kwargs</span>
        <span class="p">)</span>

        <span class="c1"># Apply PEFT if specified</span>
        <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying PEFT (LoRA) configuration to policy model...&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">prepare_model_for_kbit_training</span>

            <span class="c1"># Prepare model for k-bit training if using quantization</span>
            <span class="k">if</span> <span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Preparing policy model for k-bit training...&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">)</span>

            <span class="c1"># Extract PEFT config values</span>
            <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
            <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
            <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
                <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;LoRA config: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, dropout=</span><span class="si">{</span><span class="n">lora_dropout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target modules: </span><span class="si">{</span><span class="n">lora_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PEFT adapters applied to policy model successfully&quot;</span><span class="p">)</span>

            <span class="c1"># Reference model is None when using PEFT (TRL handles this)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Reference model: None (PEFT mode - TRL will handle reference)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Load reference model (frozen copy of SFT model)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reference model (frozen copy)...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">policy_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">base_model_kwargs</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Reference model loaded and frozen&quot;</span><span class="p">)</span>

        <span class="c1"># Load reward and value models</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reward and value models...&quot;</span><span class="p">)</span>

        <span class="c1"># Reward model quantization settings</span>
        <span class="n">reward_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_quantization&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">{})</span>
        <span class="n">reward_load_4bit</span> <span class="o">=</span> <span class="n">reward_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">reward_load_8bit</span> <span class="o">=</span> <span class="n">reward_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">reward_model_kwargs</span> <span class="o">=</span> <span class="n">base_model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">reward_load_4bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reward model with 4-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
            <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">reward_load_8bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reward model with 8-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Value model quantization settings</span>
        <span class="n">value_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;value_model_quantization&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">{})</span>
        <span class="n">value_load_4bit</span> <span class="o">=</span> <span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">value_load_8bit</span> <span class="o">=</span> <span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">value_model_kwargs</span> <span class="o">=</span> <span class="n">base_model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">value_load_4bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading value model with 4-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
            <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">value_load_8bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading value model with 8-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Load reward model (or use value model if not specified)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">reward_path</span> <span class="o">=</span> <span class="n">reward_model_name</span> <span class="ow">or</span> <span class="n">value_model_name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">reward_path</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="o">**</span><span class="n">reward_model_kwargs</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model loaded from: </span><span class="si">{</span><span class="n">reward_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">policy_model_name</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="o">**</span><span class="n">reward_model_kwargs</span>
            <span class="p">)</span>

        <span class="c1"># Load value model</span>
        <span class="k">try</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">value_model_name</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="o">**</span><span class="n">value_model_kwargs</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value model loaded from: </span><span class="si">{</span><span class="n">value_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">policy_model_name</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="o">**</span><span class="n">value_model_kwargs</span>
            <span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_train_custom_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train a custom reward model using the reward_training config.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardModelTrainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.factory</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_reward_functions</span>

        <span class="n">reward_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span>

        <span class="c1"># Validate required fields</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;base_model_name&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">base_model_name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;reward_training.base_model_name is required&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">output_dir</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;reward_training.output_dir is required&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;reward_functions&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;reward_training.reward_functions is required&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;training_texts&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">training_texts</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;reward_training.training_texts is required (minimum 10 samples)&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training reward model with base: </span><span class="si">{</span><span class="n">reward_config</span><span class="o">.</span><span class="n">base_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output directory: </span><span class="si">{</span><span class="n">reward_config</span><span class="o">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_config</span><span class="o">.</span><span class="n">training_texts</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_config</span><span class="o">.</span><span class="n">reward_functions</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Create reward functions from config</span>
        <span class="c1"># reward_functions is a List[str] according to config</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span>
        <span class="n">reward_func_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">rf_name</span> <span class="ow">in</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">rf</span> <span class="o">=</span> <span class="n">RewardRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span><span class="n">rf_name</span><span class="p">)</span>
                <span class="n">reward_func_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rf</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not load reward function &#39;</span><span class="si">{</span><span class="n">rf_name</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">reward_func_list</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No valid reward functions could be loaded&quot;</span><span class="p">)</span>

        <span class="c1"># Get composite weights if provided</span>
        <span class="n">composite_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;reward_weights&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">reward_weights</span><span class="p">:</span>
            <span class="n">composite_weights</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">reward_weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">composite_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">reward_func_list</span><span class="p">)</span>

        <span class="c1"># Create reward model trainer</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">RewardModelTrainer</span><span class="p">(</span>
            <span class="n">base_model_name</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">base_model_name</span><span class="p">,</span>
            <span class="n">reward_functions</span><span class="o">=</span><span class="n">reward_func_list</span><span class="p">,</span>
            <span class="n">composite_weights</span><span class="o">=</span><span class="n">composite_weights</span>
        <span class="p">)</span>

        <span class="c1"># Generate training dataset from training_texts</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Generating training data from reward functions...&quot;</span><span class="p">)</span>
        <span class="n">training_data</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">generate_training_data</span><span class="p">(</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">training_texts</span><span class="p">,</span>
            <span class="n">references</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">reference_texts</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;reference_texts&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span><span class="si">}</span><span class="s2"> training examples&quot;</span><span class="p">)</span>

        <span class="c1"># Train the reward model</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting reward model training...&quot;</span><span class="p">)</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_reward_model</span><span class="p">(</span>
            <span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_epochs</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Custom reward model training completed: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_path</span>



    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets for PPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up PPO datasets with DataManager...&quot;</span><span class="p">)</span>

        <span class="c1"># Extract dataset configuration</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multiple datasets provided, using first one&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

        <span class="c1"># Extract parameters</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
        <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Advanced DataManager features</span>
        <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">percent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize DataManager for PPO task (prompt-only format)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

        <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;sft&quot;</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>
            <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
            <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
            <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span>
        <span class="p">)</span>

        <span class="c1"># Load dataset - DataManager handles everything including chat template</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Extract train and validation splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>

        <span class="c1"># Apply sampling if specified</span>
        <span class="k">if</span> <span class="n">max_samples</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Limiting train dataset to </span><span class="si">{</span><span class="n">max_samples</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">))))</span>
        <span class="k">elif</span> <span class="n">percent</span> <span class="ow">and</span> <span class="n">percent</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">percent</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">percent</span><span class="si">}</span><span class="s2">% of dataset (</span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">and</span> <span class="n">max_samples</span><span class="p">:</span>
            <span class="n">eval_max</span> <span class="o">=</span> <span class="n">max_samples</span> <span class="o">//</span> <span class="mi">10</span>  <span class="c1"># Use 10% for eval</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">eval_max</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">))))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

        <span class="c1"># Tokenize dataset for PPO</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tokenizing dataset...&quot;</span><span class="p">)</span>
        <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Tokenize prompts for PPO training.&quot;&quot;&quot;</span>
            <span class="c1"># Get prompt column (DataManager ensures consistent naming)</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="p">[]))</span>

            <span class="c1"># Tokenize</span>
            <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">prompts</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Keep False like TRL example</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>

            <span class="c1"># Calculate lengths for each sequence in the batch</span>
            <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>

            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span> <span class="s2">&quot;lengths&quot;</span><span class="p">:</span> <span class="n">lengths</span><span class="p">}</span>


        <span class="c1"># Tokenize datasets</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="n">tokenize_function</span><span class="p">,</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="n">tokenize_function</span><span class="p">,</span>
                    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># Filter by length (like TRL example)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtering sequences longer than </span><span class="si">{</span><span class="n">max_prompt_length</span><span class="si">}</span><span class="s2"> tokens...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering train dataset&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering eval dataset&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final dataset sizes - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Verify dataset structure (like TRL example checks)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span> \
            <span class="s2">&quot;The last token should not be an EOS token&quot;</span>

        <span class="c1"># Log sample</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample tokenized prompt (first 100 chars): </span><span class="si">{</span><span class="n">decoded</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup reward functions using the centralized registry system.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up reward functions for PPO...&quot;</span><span class="p">)</span>

        <span class="c1"># Get reward configurations</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;rewards&#39;</span><span class="p">):</span>
            <span class="n">rewards_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">rewards_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;No reward configurations found, using default rewards&quot;</span><span class="p">)</span>
            <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;length&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentiment&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;positive_weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;safety&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}},</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;diversity&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span>
            <span class="p">]</span>

        <span class="c1"># Load reward functions from the registry</span>
        <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="n">rewards_config</span><span class="p">:</span>
            <span class="c1"># Handle both dict and RewardConfig object</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">params</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># RewardConfig object</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Special case: custom reward function passed directly</span>
                <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="s1">&#39;reward_function&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;reward_function&#39;</span><span class="p">]</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loaded custom reward function (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Use the rewards registry to get reward functions</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span> <span class="k">as</span> <span class="n">RewardsRegistry</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardConfig</span><span class="p">,</span> <span class="n">RewardType</span>

                    <span class="c1"># Map common variations to standard names</span>
                    <span class="n">reward_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s1">&#39;math&#39;</span><span class="p">:</span> <span class="s1">&#39;math_reasoning&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;code_quality&#39;</span><span class="p">,</span>
                    <span class="p">}</span>
                    <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_type</span><span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="c1"># Convert reward type string to enum</span>
                        <span class="n">reward_type_enum</span> <span class="o">=</span> <span class="n">RewardType</span><span class="p">[</span><span class="n">reward_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>

                        <span class="c1"># Create RewardConfig with weight and params</span>
                        <span class="n">reward_cfg</span> <span class="o">=</span> <span class="n">RewardConfig</span><span class="p">(</span>
                            <span class="n">reward_type</span><span class="o">=</span><span class="n">reward_type_enum</span><span class="p">,</span>
                            <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Weight will be applied separately</span>
                            <span class="n">params</span><span class="o">=</span><span class="n">params</span>
                        <span class="p">)</span>

                        <span class="c1"># Get reward function from registry</span>
                        <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                            <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_cfg</span><span class="p">)</span>
                        <span class="c1"># Extract the callable compute method</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                            <span class="k">continue</span>

                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward from registry (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                        <span class="c1"># Reward type not in enum, try registry by name</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward type &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; not in RewardType enum, trying registry by name&quot;</span><span class="p">)</span>
                        <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                            <span class="n">reward_type</span><span class="p">)</span>

                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                            <span class="k">continue</span>

                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward by name (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="c1"># Store reward function with metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                    <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">reward_type</span>
                <span class="p">})</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to load reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">continue</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;No reward functions were loaded! Adding a simple default length reward.&quot;</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">default_length_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">length</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="mf">0.5</span>
                <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mf">200.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="mf">1.0</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">default_length_reward</span><span class="p">,</span>
                <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;default_length&quot;</span>
            <span class="p">})</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added default length reward as fallback&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot; Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions successfully&quot;</span><span class="p">)</span>

        <span class="c1"># Log summary of loaded rewards</span>
        <span class="n">reward_summary</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_summary</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_combined_reward_function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">completions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Combined reward function that applies all registered rewards.</span>

<span class="sd">        Args:</span>
<span class="sd">            completions: List of generated completions</span>
<span class="sd">            **kwargs: Additional arguments including prompts, references, etc.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">completions</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="n">batch_rewards</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Extract batch data from kwargs</span>
        <span class="n">test_lists</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;test_list&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">))</span>

        <span class="c1"># Check multiple possible reference column names</span>
        <span class="n">references</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">ref_key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">,</span> <span class="s1">&#39;solution&#39;</span><span class="p">,</span> <span class="s1">&#39;reference&#39;</span><span class="p">,</span> <span class="s1">&#39;ground_truth&#39;</span><span class="p">,</span> <span class="s1">&#39;response&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">ref_key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">references</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">ref_key</span><span class="p">]</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="n">references</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>

        <span class="c1"># Ensure lists match completion length</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_lists</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">test_lists</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_lists</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">completion</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">completions</span><span class="p">):</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c1"># Get per-sample data</span>
            <span class="n">test_cases</span> <span class="o">=</span> <span class="n">test_lists</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_lists</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">reference</span> <span class="o">=</span> <span class="n">references</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">references</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>

                    <span class="c1"># Handle different reward function signatures</span>
                    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func</span><span class="p">):</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span><span class="n">completion</span><span class="p">,</span> <span class="n">test_cases</span><span class="o">=</span><span class="n">test_cases</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
                            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                <span class="k">try</span><span class="p">:</span>
                                    <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span><span class="n">completion</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">reference</span><span class="p">)</span>
                                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                    <span class="k">try</span><span class="p">:</span>
                                        <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                            <span class="n">completion</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="p">{})</span>
                                    <span class="k">except</span> <span class="ne">BaseException</span><span class="p">:</span>
                                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                                            <span class="sa">f</span><span class="s2">&quot;Could not call reward function </span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, returning 0&quot;</span><span class="p">)</span>
                                        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward function </span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> is not callable&quot;</span><span class="p">)</span>
                        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>

                    <span class="c1"># Apply weight</span>
                    <span class="n">weighted_reward</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">*</span> <span class="n">weight</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">weighted_reward</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward </span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">reward</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (weighted: </span><span class="si">{</span><span class="n">weighted_reward</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error computing reward </span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">batch_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>

        <span class="c1"># Log batch statistics</span>
        <span class="k">if</span> <span class="n">batch_rewards</span><span class="p">:</span>
            <span class="n">successful</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">partial</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">failed</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;BATCH REWARDS: </span><span class="si">{</span><span class="n">successful</span><span class="si">}</span><span class="s2"> passed | </span><span class="si">{</span><span class="n">partial</span><span class="si">}</span><span class="s2"> partial | </span><span class="si">{</span><span class="n">failed</span><span class="si">}</span><span class="s2"> failed | total=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Reward stats: min=</span><span class="si">{</span><span class="nb">min</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><span class="nb">max</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, mean=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">batch_rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_obj</span><span class="p">,</span> <span class="o">*</span><span class="n">attr_names</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely get config value from multiple possible attribute names.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">config_obj</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">config_obj</span><span class="p">[</span><span class="n">attr_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">default</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set up the PPO trainer with all configurations.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL PPO trainer...&quot;</span><span class="p">)</span>

        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Get training parameters</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
            <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/ppo_trl&#39;</span><span class="p">)</span>

        <span class="c1"># PPO-specific parameters</span>
        <span class="n">kl_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">cliprange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">cliprange_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange_value&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">vf_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;vf_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lam&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

        <span class="c1"># Generation parameters</span>
        <span class="n">response_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;response_length&#39;</span><span class="p">,</span> <span class="s1">&#39;max_completion_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">stop_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;stop_token&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eos&#39;</span><span class="p">)</span>
        <span class="n">missing_eos_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;missing_eos_penalty&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># Evaluation and checkpointing</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>

        <span class="c1"># Logging</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL PPO Training Configuration&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epochs: </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max steps: </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning rate: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch size: </span><span class="si">{</span><span class="n">per_device_batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient accumulation: </span><span class="si">{</span><span class="n">gradient_accumulation_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KL coefficient: </span><span class="si">{</span><span class="n">kl_coef</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Clip range: </span><span class="si">{</span><span class="n">cliprange</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value function coef: </span><span class="si">{</span><span class="n">vf_coef</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Response length: </span><span class="si">{</span><span class="n">response_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Temperature: </span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output directory: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Create output directory</span>
        <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Setup PPO trainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>

        <span class="n">ppo_config</span> <span class="o">=</span> <span class="n">PPOConfig</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>

            <span class="c1"># PPO-specific</span>
            <span class="n">kl_coef</span><span class="o">=</span><span class="n">kl_coef</span><span class="p">,</span>
            <span class="n">cliprange</span><span class="o">=</span><span class="n">cliprange</span><span class="p">,</span>
            <span class="n">cliprange_value</span><span class="o">=</span><span class="n">cliprange_value</span><span class="p">,</span>
            <span class="n">vf_coef</span><span class="o">=</span><span class="n">vf_coef</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>

            <span class="c1"># Generation</span>
            <span class="n">response_length</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">stop_token</span><span class="o">=</span><span class="n">stop_token</span><span class="p">,</span>
            <span class="n">missing_eos_penalty</span><span class="o">=</span><span class="n">missing_eos_penalty</span><span class="p">,</span>

            <span class="c1"># Evaluation</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>

            <span class="c1"># Checkpointing</span>
            <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>

            <span class="c1"># Logging</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span> <span class="k">if</span> <span class="n">report_to</span> <span class="k">else</span> <span class="p">[],</span>

            <span class="c1"># Precision</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

            <span class="c1"># Other</span>
            <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>


        <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
            <span class="n">backend_config</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ppo&#39;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">ppo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># Get PEFT config if using PEFT</span>
        <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span>
            <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
            <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
            <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
                <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
            <span class="p">)</span>




        <span class="c1"># Create PPO trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">PPOTrainer</span><span class="p">(</span>
            <span class="n">args</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
            <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span>
            <span class="n">reward_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span>
            <span class="n">value_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PPO trainer setup completed successfully!&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute PPO training.&quot;&quot;&quot;</span>
        <span class="c1"># Setup components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Get output directory</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
            <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/ppo_trl&#39;</span><span class="p">)</span>

        <span class="c1"># Record training start</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting TRL PPO Training&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num reward functions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>




        <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Log samples after training</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">raw_reward_funcs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_functions&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">raw_reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">reward_callables</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="n">raw_reward_funcs</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;function&quot;</span><span class="p">))</span>
                    <span class="p">]</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">generate_and_log_samples</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">sample_logging</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">reward_callables</span><span class="p">,</span>
                <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;post-train&quot;</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">sample_error</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to log qualitative samples: </span><span class="si">{</span><span class="n">sample_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Record training end</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_duration</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

        <span class="c1"># Extract metrics</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">train_result</span><span class="o">.</span><span class="n">metrics</span>

        <span class="c1"># Save model</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="c1"># Compile results</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
            <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL PPO Training Completed Successfully!&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final loss: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total steps: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;model_path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute a single training step - handled by TRL internally.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;train_step() called but TRL PPO uses TRL&#39;s internal training loop&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create data loader - handled by TRL internally.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;create_data_loader() called but TRL PPO uses TRL&#39;s internal data loading&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># def evaluate(self) -&gt; Dict[str, float]:</span>
    <span class="c1">#     try:</span>
    <span class="c1">#         logger.info(&quot;Running evaluation...&quot;)</span>
    <span class="c1">#         return self.trainer.evaluate()</span>
    <span class="c1">#     except Exception as e:</span>
    <span class="c1">#         logger.error(f&quot;Evaluation failed: {e}&quot;)</span>
    <span class="c1">#         return {}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_training_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get training statistics.&quot;&quot;&quot;</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;proximal_policy_optimization&#39;</span><span class="p">,</span>
                <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
                <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">),</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
                <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="s1">&#39;dataset_info&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;train_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;val_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;loaded&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
                <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;has_peft&#39;</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s1">&#39;peft_config&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">stats</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save configuration to YAML file.&quot;&quot;&quot;</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;proximal_policy_optimization&#39;</span><span class="p">,</span>
            <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">),</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">),</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
            <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL PPO configuration saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the trained PPO model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">default_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>

            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving PPO model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Save using trainer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="c1"># Save training configuration</span>
            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;ppo_training_config.yaml&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_config</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">config_path</span><span class="p">))</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PPO model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">save_path</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save PPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained PPO model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading PPO model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

            <span class="c1"># Load tokenizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

            <span class="c1"># Load model</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">path</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PPO model loaded successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load PPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create data loader - handled by TRL internally.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create data loader - handled by TRL internally.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;create_data_loader() called but TRL PPO uses TRL&#39;s internal data loading&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.get_training_stats" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_training_stats</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.get_training_stats" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get training statistics.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_training_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get training statistics.&quot;&quot;&quot;</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;proximal_policy_optimization&#39;</span><span class="p">,</span>
            <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">),</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
            <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="s1">&#39;dataset_info&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;train_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;val_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;loaded&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
            <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;has_peft&#39;</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s1">&#39;peft_config&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">stats</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if TRL is available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if TRL is available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a trained PPO model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a trained PPO model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading PPO model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

        <span class="c1"># Load tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

        <span class="c1"># Load model</span>
        <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PPO model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load PPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.save_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_config</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.save_config" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save configuration to YAML file.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save configuration to YAML file.&quot;&quot;&quot;</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;proximal_policy_optimization&#39;</span><span class="p">,</span>
        <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">),</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">),</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
        <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
        <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL PPO configuration saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the trained PPO model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the trained PPO model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>

        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving PPO model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save using trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="c1"># Save training configuration</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;ppo_training_config.yaml&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_config</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">config_path</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PPO model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">save_path</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save PPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets for PPO training using unified DataManager.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets for PPO training using unified DataManager.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up PPO datasets with DataManager...&quot;</span><span class="p">)</span>

    <span class="c1"># Extract dataset configuration</span>
    <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multiple datasets provided, using first one&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

    <span class="c1"># Extract parameters</span>
    <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
    <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Advanced DataManager features</span>
    <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">percent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize DataManager for PPO task (prompt-only format)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

    <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;sft&quot;</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>
        <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
        <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
        <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span>
    <span class="p">)</span>

    <span class="c1"># Load dataset - DataManager handles everything including chat template</span>
    <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
        <span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
        <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Extract train and validation splits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>

    <span class="c1"># Apply sampling if specified</span>
    <span class="k">if</span> <span class="n">max_samples</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Limiting train dataset to </span><span class="si">{</span><span class="n">max_samples</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">))))</span>
    <span class="k">elif</span> <span class="n">percent</span> <span class="ow">and</span> <span class="n">percent</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">percent</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">percent</span><span class="si">}</span><span class="s2">% of dataset (</span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">and</span> <span class="n">max_samples</span><span class="p">:</span>
        <span class="n">eval_max</span> <span class="o">=</span> <span class="n">max_samples</span> <span class="o">//</span> <span class="mi">10</span>  <span class="c1"># Use 10% for eval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">eval_max</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">))))</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

    <span class="c1"># Tokenize dataset for PPO</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tokenizing dataset...&quot;</span><span class="p">)</span>
    <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenize prompts for PPO training.&quot;&quot;&quot;</span>
        <span class="c1"># Get prompt column (DataManager ensures consistent naming)</span>
        <span class="n">prompts</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="p">[]))</span>

        <span class="c1"># Tokenize</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompts</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Keep False like TRL example</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>

        <span class="c1"># Calculate lengths for each sequence in the batch</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span> <span class="s2">&quot;lengths&quot;</span><span class="p">:</span> <span class="n">lengths</span><span class="p">}</span>


    <span class="c1"># Tokenize datasets</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">tokenize_function</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="n">tokenize_function</span><span class="p">,</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Filter by length (like TRL example)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtering sequences longer than </span><span class="si">{</span><span class="n">max_prompt_length</span><span class="si">}</span><span class="s2"> tokens...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering train dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering eval dataset&quot;</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final dataset sizes - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Verify dataset structure (like TRL example checks)</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span> \
        <span class="s2">&quot;The last token should not be an EOS token&quot;</span>

    <span class="c1"># Log sample</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample tokenized prompt (first 100 chars): </span><span class="si">{</span><span class="n">decoded</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup models (policy, reference, reward, value) using standard Transformers.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup models (policy, reference, reward, value) using standard Transformers.&quot;&quot;&quot;</span>
    <span class="c1"># Extract model config values safely</span>
    <span class="n">policy_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="s1">&#39;name_or_path&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>


   <span class="c1"># Check if integrated reward training is configured</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;reward_training&#39;</span><span class="p">)</span> <span class="ow">and</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Training custom reward model before PPO...&quot;</span><span class="p">)</span>
        <span class="n">reward_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_custom_reward_model</span><span class="p">()</span>

        <span class="c1"># Override reward_model_name with trained model path</span>
        <span class="n">reward_model_name</span> <span class="o">=</span> <span class="n">reward_model_path</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Custom reward model trained and saved to: </span><span class="si">{</span><span class="n">reward_model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Extract from config as normal</span>
        <span class="n">reward_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;reward_model_name&#39;</span><span class="p">,</span>
            <span class="s1">&#39;reward_path&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">value_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="s1">&#39;reward_value_model&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">sft_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="s1">&#39;sft_path&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">trust_remote_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;device_map&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>

    <span class="n">is_ddp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">device_map</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;DDP&quot;</span><span class="p">,</span> <span class="s2">&quot;ddp&quot;</span><span class="p">]</span> <span class="ow">or</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ACCELERATE_USE_DDP&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;true&#39;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">is_ddp</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">PartialState</span>
        <span class="n">device_string</span> <span class="o">=</span> <span class="n">PartialState</span><span class="p">()</span><span class="o">.</span><span class="n">process_index</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="n">device_string</span><span class="p">}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;DDP mode detected: device_map=</span><span class="se">{{</span><span class="s2">&#39;&#39;: </span><span class="si">{</span><span class="n">device_string</span><span class="si">}</span><span class="se">}}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
    <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL PPO&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

    <span class="c1"># Quantization settings</span>
    <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Auto-detect quantization from model name</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">load_in_4bit</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">load_in_8bit</span><span class="p">:</span>
        <span class="n">model_name_lower</span> <span class="o">=</span> <span class="n">policy_model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="s1">&#39;bnb-4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;awq&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Auto-detected 4-bit quantization from model name: </span><span class="si">{</span><span class="n">policy_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="s1">&#39;bnb-8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Auto-detected 8-bit quantization from model name: </span><span class="si">{</span><span class="n">policy_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Auto-enable PEFT if using quantization</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_peft</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Quantization detected - auto-enabling PEFT/LoRA adapters (required for training)&quot;</span><span class="p">)</span>
        <span class="n">use_peft</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL PPO models&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Policy model: </span><span class="si">{</span><span class="n">policy_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SFT path: </span><span class="si">{</span><span class="n">sft_model_path</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="s1">&#39;Same as policy&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model: </span><span class="si">{</span><span class="n">reward_model_name</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="s1">&#39;Same as value model&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value model: </span><span class="si">{</span><span class="n">value_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="s2">&quot;Transformers not available. Install with: pip install transformers&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="c1"># Load tokenizer</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading tokenizer...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">policy_model_name</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="n">trust_remote_code</span><span class="p">,</span>
    <span class="p">)</span>


    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">!=</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;left&quot;</span>

    <span class="c1"># Set pad token if not set</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Set pad token to eos token&quot;</span><span class="p">)</span>

    <span class="c1"># Common model kwargs</span>
    <span class="n">base_model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
        <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>
        <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="n">trust_remote_code</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Add quantization if specified for policy model</span>
    <span class="n">policy_model_kwargs</span> <span class="o">=</span> <span class="n">base_model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">load_in_4bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading policy model with 4-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
        <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">load_in_8bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading policy model with 8-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">policy_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Load policy model (from SFT path if provided, else base model)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading policy model...&quot;</span><span class="p">)</span>
    <span class="n">policy_path</span> <span class="o">=</span> <span class="n">sft_model_path</span> <span class="ow">or</span> <span class="n">policy_model_name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">policy_path</span><span class="p">,</span>
        <span class="o">**</span><span class="n">policy_model_kwargs</span>
    <span class="p">)</span>

    <span class="c1"># Apply PEFT if specified</span>
    <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying PEFT (LoRA) configuration to policy model...&quot;</span><span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">prepare_model_for_kbit_training</span>

        <span class="c1"># Prepare model for k-bit training if using quantization</span>
        <span class="k">if</span> <span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Preparing policy model for k-bit training...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">)</span>

        <span class="c1"># Extract PEFT config values</span>
        <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
        <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
            <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;LoRA config: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, dropout=</span><span class="si">{</span><span class="n">lora_dropout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target modules: </span><span class="si">{</span><span class="n">lora_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
            <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PEFT adapters applied to policy model successfully&quot;</span><span class="p">)</span>

        <span class="c1"># Reference model is None when using PEFT (TRL handles this)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Reference model: None (PEFT mode - TRL will handle reference)&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Load reference model (frozen copy of SFT model)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reference model (frozen copy)...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">policy_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">base_model_kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Reference model loaded and frozen&quot;</span><span class="p">)</span>

    <span class="c1"># Load reward and value models</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reward and value models...&quot;</span><span class="p">)</span>

    <span class="c1"># Reward model quantization settings</span>
    <span class="n">reward_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_quantization&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">{})</span>
    <span class="n">reward_load_4bit</span> <span class="o">=</span> <span class="n">reward_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">reward_load_8bit</span> <span class="o">=</span> <span class="n">reward_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="n">reward_model_kwargs</span> <span class="o">=</span> <span class="n">base_model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">reward_load_4bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reward model with 4-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
        <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">reward_load_8bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reward model with 8-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">reward_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Value model quantization settings</span>
    <span class="n">value_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;value_model_quantization&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">{})</span>
    <span class="n">value_load_4bit</span> <span class="o">=</span> <span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">value_load_8bit</span> <span class="o">=</span> <span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="n">value_model_kwargs</span> <span class="o">=</span> <span class="n">base_model_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">value_load_4bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading value model with 4-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
        <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">value_load_8bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading value model with 8-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">value_model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Load reward model (or use value model if not specified)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">reward_path</span> <span class="o">=</span> <span class="n">reward_model_name</span> <span class="ow">or</span> <span class="n">value_model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">reward_path</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">reward_model_kwargs</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model loaded from: </span><span class="si">{</span><span class="n">reward_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">policy_model_name</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">reward_model_kwargs</span>
        <span class="p">)</span>

    <span class="c1"># Load value model</span>
    <span class="k">try</span><span class="p">:</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">value_model_name</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">value_model_kwargs</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value model loaded from: </span><span class="si">{</span><span class="n">value_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">policy_model_name</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="o">**</span><span class="n">value_model_kwargs</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup reward functions using the centralized registry system.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup reward functions using the centralized registry system.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up reward functions for PPO...&quot;</span><span class="p">)</span>

    <span class="c1"># Get reward configurations</span>
    <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;rewards&#39;</span><span class="p">):</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">rewards_config</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;No reward configurations found, using default rewards&quot;</span><span class="p">)</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;length&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentiment&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;positive_weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;safety&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}},</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;diversity&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span>
        <span class="p">]</span>

    <span class="c1"># Load reward functions from the registry</span>
    <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="n">rewards_config</span><span class="p">:</span>
        <span class="c1"># Handle both dict and RewardConfig object</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># RewardConfig object</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Special case: custom reward function passed directly</span>
            <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="s1">&#39;reward_function&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="n">reward_func</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;reward_function&#39;</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Loaded custom reward function (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use the rewards registry to get reward functions</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span> <span class="k">as</span> <span class="n">RewardsRegistry</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardConfig</span><span class="p">,</span> <span class="n">RewardType</span>

                <span class="c1"># Map common variations to standard names</span>
                <span class="n">reward_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;math&#39;</span><span class="p">:</span> <span class="s1">&#39;math_reasoning&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;code_quality&#39;</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_type</span><span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Convert reward type string to enum</span>
                    <span class="n">reward_type_enum</span> <span class="o">=</span> <span class="n">RewardType</span><span class="p">[</span><span class="n">reward_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>

                    <span class="c1"># Create RewardConfig with weight and params</span>
                    <span class="n">reward_cfg</span> <span class="o">=</span> <span class="n">RewardConfig</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="o">=</span><span class="n">reward_type_enum</span><span class="p">,</span>
                        <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Weight will be applied separately</span>
                        <span class="n">params</span><span class="o">=</span><span class="n">params</span>
                    <span class="p">)</span>

                    <span class="c1"># Get reward function from registry</span>
                    <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_cfg</span><span class="p">)</span>
                    <span class="c1"># Extract the callable compute method</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward from registry (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="c1"># Reward type not in enum, try registry by name</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward type &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; not in RewardType enum, trying registry by name&quot;</span><span class="p">)</span>
                    <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward by name (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Store reward function with metadata</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">reward_type</span>
            <span class="p">})</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Failed to load reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">continue</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
            <span class="s2">&quot;No reward functions were loaded! Adding a simple default length reward.&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">default_length_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">length</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="mf">0.5</span>
            <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mf">200.0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">1.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">default_length_reward</span><span class="p">,</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;default_length&quot;</span>
        <span class="p">})</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added default length reward as fallback&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot; Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions successfully&quot;</span><span class="p">)</span>

    <span class="c1"># Log summary of loaded rewards</span>
    <span class="n">reward_summary</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">])</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_summary</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Set up the PPO trainer with all configurations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set up the PPO trainer with all configurations.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL PPO trainer...&quot;</span><span class="p">)</span>

    <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
    <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

    <span class="c1"># Get training parameters</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
        <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/ppo_trl&#39;</span><span class="p">)</span>

    <span class="c1"># PPO-specific parameters</span>
    <span class="n">kl_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">cliprange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">cliprange_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange_value&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">vf_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;vf_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lam&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

    <span class="c1"># Generation parameters</span>
    <span class="n">response_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;response_length&#39;</span><span class="p">,</span> <span class="s1">&#39;max_completion_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">stop_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;stop_token&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eos&#39;</span><span class="p">)</span>
    <span class="n">missing_eos_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;missing_eos_penalty&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># Evaluation and checkpointing</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
    <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>

    <span class="c1"># Logging</span>
    <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL PPO Training Configuration&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epochs: </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max steps: </span><span class="si">{</span><span class="n">max_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning rate: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch size: </span><span class="si">{</span><span class="n">per_device_batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient accumulation: </span><span class="si">{</span><span class="n">gradient_accumulation_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KL coefficient: </span><span class="si">{</span><span class="n">kl_coef</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Clip range: </span><span class="si">{</span><span class="n">cliprange</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value function coef: </span><span class="si">{</span><span class="n">vf_coef</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Response length: </span><span class="si">{</span><span class="n">response_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Temperature: </span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output directory: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Create output directory</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Setup PPO trainer</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>

    <span class="n">ppo_config</span> <span class="o">=</span> <span class="n">PPOConfig</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
        <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>

        <span class="c1"># PPO-specific</span>
        <span class="n">kl_coef</span><span class="o">=</span><span class="n">kl_coef</span><span class="p">,</span>
        <span class="n">cliprange</span><span class="o">=</span><span class="n">cliprange</span><span class="p">,</span>
        <span class="n">cliprange_value</span><span class="o">=</span><span class="n">cliprange_value</span><span class="p">,</span>
        <span class="n">vf_coef</span><span class="o">=</span><span class="n">vf_coef</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
        <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>

        <span class="c1"># Generation</span>
        <span class="n">response_length</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
        <span class="n">stop_token</span><span class="o">=</span><span class="n">stop_token</span><span class="p">,</span>
        <span class="n">missing_eos_penalty</span><span class="o">=</span><span class="n">missing_eos_penalty</span><span class="p">,</span>

        <span class="c1"># Evaluation</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
        <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>

        <span class="c1"># Checkpointing</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
        <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>

        <span class="c1"># Logging</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
        <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span> <span class="k">if</span> <span class="n">report_to</span> <span class="k">else</span> <span class="p">[],</span>

        <span class="c1"># Precision</span>
        <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

        <span class="c1"># Other</span>
        <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>


    <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
        <span class="n">backend_config</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
        <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ppo&#39;</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">ppo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="c1"># Get PEFT config if using PEFT</span>
    <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span>
        <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
        <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
            <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

        <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
            <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
        <span class="p">)</span>




    <span class="c1"># Create PPO trainer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">PPOTrainer</span><span class="p">(</span>
        <span class="n">args</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
        <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
        <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span>
        <span class="n">reward_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span>
        <span class="n">value_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
        <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PPO trainer setup completed successfully!&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute PPO training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute PPO training.&quot;&quot;&quot;</span>
    <span class="c1"># Setup components</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

    <span class="c1"># Get output directory</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
        <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/ppo_trl&#39;</span><span class="p">)</span>

    <span class="c1"># Record training start</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting TRL PPO Training&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num reward functions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>




    <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Log samples after training</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">raw_reward_funcs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_functions&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">raw_reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">reward_callables</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="n">raw_reward_funcs</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;function&quot;</span><span class="p">))</span>
                <span class="p">]</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">generate_and_log_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">sample_logging</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">reward_callables</span><span class="p">,</span>
            <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;post-train&quot;</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">sample_error</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to log qualitative samples: </span><span class="si">{</span><span class="n">sample_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Record training end</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_duration</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

    <span class="c1"># Extract metrics</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">train_result</span><span class="o">.</span><span class="n">metrics</span>

    <span class="c1"># Save model</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="c1"># Compile results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
        <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
        <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
        <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL PPO Training Completed Successfully!&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final loss: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total steps: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;model_path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.ppo.ppo.TRLPPOTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.trl.rl.ppo.ppo.TRLPPOTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute a single training step - handled by TRL internally.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute a single training step - handled by TRL internally.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;train_step() called but TRL PPO uses TRL&#39;s internal training loop&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Example</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.backends.trl.rl.ppo.ppo</span><span class="w"> </span><span class="kn">import</span> <span class="n">TRLPPOTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.rl.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnifiedConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">UnifiedConfig</span><span class="p">(</span><span class="n">algo</span><span class="o">=</span><span class="n">AlgorithmType</span><span class="o">.</span><span class="n">PPO</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TRLPPOTrainer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<h4 id="trlgrpotrainer"><code>TRLGRPOTrainer</code><a class="headerlink" href="#trlgrpotrainer" title="Permanent link">&para;</a></h4>
<p>TRL backend for Group Relative Policy Optimization.</p>


<div class="doc doc-object doc-class">



<a id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.rl.trainer_base.TrainerBase">TrainerBase</span></code></p>



        <p>GRPO trainer using pure TRL GRPOTrainer with math, code, and enhanced rewards.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  38</span>
<span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TRLGRPOTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GRPO trainer using pure TRL GRPOTrainer with math, code, and enhanced rewards.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Add eval dataset support</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># self.evaluator = None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># For BaseEvaluator/RLEvaluator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if TRL is available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup model using standard Transformers.&quot;&quot;&quot;</span>
        <span class="c1"># Extract model config values safely</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;name_or_path&#39;</span><span class="p">,</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
        <span class="n">trust_remote_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">)</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;device_map&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
        <span class="n">is_ddp</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">device_map</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;DDP&quot;</span><span class="p">,</span> <span class="s2">&quot;ddp&quot;</span><span class="p">]</span> <span class="ow">or</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ACCELERATE_USE_DDP&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;true&#39;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_ddp</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">PartialState</span>
            <span class="n">device_string</span> <span class="o">=</span> <span class="n">PartialState</span><span class="p">()</span><span class="o">.</span><span class="n">process_index</span>
            <span class="n">device_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="n">device_string</span><span class="p">}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;DDP mode detected: device_map=</span><span class="se">{{</span><span class="s2">&#39;&#39;: </span><span class="si">{</span><span class="n">device_string</span><span class="si">}</span><span class="se">}}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL GRPO&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Auto-detect quantization from model name if not explicitly set</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">load_in_4bit</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">load_in_8bit</span><span class="p">:</span>
            <span class="n">model_name_lower</span> <span class="o">=</span> <span class="n">model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="s1">&#39;bnb-4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;awq&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Auto-detected 4-bit quantization from model name: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="s1">&#39;bnb-8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Auto-detected 8-bit quantization from model name: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Auto-enable PEFT if using quantization (required for training</span>
        <span class="c1"># quantized models)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_peft</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Quantization detected - auto-enabling PEFT/LoRA adapters (required for training)&quot;</span><span class="p">)</span>
            <span class="n">use_peft</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL GRPO model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Transformers not available. Install with: pip install transformers&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># Load tokenizer first</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading tokenizer...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="n">trust_remote_code</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Set pad token if not set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Set pad token to eos token&quot;</span><span class="p">)</span>

        <span class="c1"># Load model</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading model...&quot;</span><span class="p">)</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>
            <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="n">trust_remote_code</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Add quantization if specified</span>
        <span class="k">if</span> <span class="n">load_in_4bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading model with 4-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">load_in_8bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading model with 8-bit quantization...&quot;</span><span class="p">)</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>

        <span class="c1"># Apply PEFT if specified or if quantization is used</span>
        <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying PEFT (LoRA) configuration...&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">prepare_model_for_kbit_training</span>

            <span class="c1"># Prepare model for k-bit training if using quantization</span>
            <span class="k">if</span> <span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Preparing model for k-bit training...&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

            <span class="c1"># Extract PEFT config values safely</span>
            <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
            <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
            <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
                <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;LoRA config: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, dropout=</span><span class="si">{</span><span class="n">lora_dropout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target modules: </span><span class="si">{</span><span class="n">lora_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PEFT adapters applied successfully&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPO model setup completed successfully&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer vocab size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets for GRPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up GRPO datasets with DataManager...&quot;</span><span class="p">)</span>

        <span class="c1"># Extract dataset configuration</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

        <span class="c1"># Extract parameters</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Advanced DataManager features</span>
        <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize DataManager for GRPO task</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

        <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;grpo&quot;</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>           <span class="c1"># System prompt</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
            <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>       <span class="c1">#  ADD THIS - Enable thinking mode</span>
            <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
            <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
            <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
        <span class="p">)</span>

        <span class="c1"># Load dataset - DataManager handles everything including chat template</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>



        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

        <span class="c1"># Log sample</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">prompt_col</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="k">if</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">else</span> <span class="s2">&quot;query&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample prompt (first 100 chars): </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="n">prompt_col</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>            


    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup reward functions using the centralized registry system.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up reward functions for GRPO...&quot;</span><span class="p">)</span>

        <span class="c1"># Get reward configurations</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;rewards&#39;</span><span class="p">):</span>
            <span class="n">rewards_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">rewards_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;No reward configurations found, using default rewards&quot;</span><span class="p">)</span>
            <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;length&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentiment&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;positive_weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;safety&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                            <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}},</span> <span class="p">{</span>
                                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;diversity&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span>
                                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">]</span>

        <span class="c1"># Load reward functions from the registry</span>
        <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="n">rewards_config</span><span class="p">:</span>
            <span class="c1"># Handle both dict and RewardConfig object</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">params</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># RewardConfig object</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Special case: custom reward function passed directly</span>
                <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="s1">&#39;reward_function&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;reward_function&#39;</span><span class="p">]</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loaded custom reward function (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Use the rewards registry to get reward functions</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span> <span class="k">as</span> <span class="n">RewardsRegistry</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardConfig</span><span class="p">,</span> <span class="n">RewardType</span>

                    <span class="c1"># Map common variations to standard names</span>
                    <span class="n">reward_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s1">&#39;math&#39;</span><span class="p">:</span> <span class="s1">&#39;math_reasoning&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;code_quality&#39;</span><span class="p">,</span>
                    <span class="p">}</span>
                    <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_type</span><span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="c1"># Convert reward type string to enum</span>
                        <span class="n">reward_type_enum</span> <span class="o">=</span> <span class="n">RewardType</span><span class="p">[</span><span class="n">reward_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>

                        <span class="c1"># Create RewardConfig with weight and params</span>
                        <span class="n">reward_cfg</span> <span class="o">=</span> <span class="n">RewardConfig</span><span class="p">(</span>
                            <span class="n">reward_type</span><span class="o">=</span><span class="n">reward_type_enum</span><span class="p">,</span>
                            <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Weight will be applied separately</span>
                            <span class="n">params</span><span class="o">=</span><span class="n">params</span>
                        <span class="p">)</span>

                        <span class="c1"># Get reward function from registry</span>
                        <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                            <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_cfg</span><span class="p">)</span>
                        <span class="c1"># Extract the callable compute method</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                            <span class="k">continue</span>

                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward from registry (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                        <span class="c1"># Reward type not in enum, try registry by name</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward type &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; not in RewardType enum, trying registry by name&quot;</span><span class="p">)</span>
                        <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                            <span class="n">reward_type</span><span class="p">)</span>

                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                            <span class="k">continue</span>

                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward by name (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="c1"># Store reward function with metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                    <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">reward_type</span>
                <span class="p">})</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to load reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="c1"># Fallback: try to continue with other rewards rather than</span>
                <span class="c1"># failing</span>
                <span class="k">continue</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;No reward functions were loaded! Adding a simple default length reward.&quot;</span><span class="p">)</span>
            <span class="c1"># Add a simple fallback reward so training doesn&#39;t fail</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">default_length_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">length</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="mf">0.5</span>
                <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mf">200.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="mf">1.0</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">default_length_reward</span><span class="p">,</span>
                <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;default_length&quot;</span>
            <span class="p">})</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added default length reward as fallback&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot; Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions successfully&quot;</span><span class="p">)</span>

        <span class="c1"># Log summary of loaded rewards</span>
        <span class="n">reward_summary</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_summary</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_combined_reward_function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">completions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Combined reward function that applies all registered rewards.</span>

<span class="sd">        Args:</span>
<span class="sd">            completions: List of generated completions</span>
<span class="sd">            **kwargs: Additional arguments from TRL including:</span>
<span class="sd">                - prompts: List of prompts</span>
<span class="sd">                - test_list: List of test cases (for code datasets like MBPP)</span>
<span class="sd">                - answer/solution/reference: Reference answers (for math datasets)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">completions</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Debug: log what TRL is passing (once)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_logged_kwargs&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[DEBUG] _combined_reward_function kwargs keys: </span><span class="si">{</span>
<span class="w">                    </span><span class="nb">list</span><span class="p">(</span>
<span class="w">                        </span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;test_list&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;test_list&#39;</span><span class="p">][:</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;test_list&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;empty&#39;</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[DEBUG] test_list found, sample: </span><span class="si">{</span><span class="n">sample</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;[DEBUG] test_list NOT in kwargs!&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logged_kwargs</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">batch_rewards</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Extract batch data from kwargs (TRL passes these as lists)</span>
        <span class="n">test_lists</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;test_list&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">))</span>
        <span class="c1"># CHECK MULTIPLE POSSIBLE REFERENCE COLUMN NAMES</span>
        <span class="c1"># Try different column names in order of preference</span>
        <span class="n">references</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">ref_key</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s1">&#39;answer&#39;</span><span class="p">,</span>
            <span class="s1">&#39;solution&#39;</span><span class="p">,</span>
            <span class="s1">&#39;reference&#39;</span><span class="p">,</span>
            <span class="s1">&#39;ground_truth&#39;</span><span class="p">,</span>
            <span class="s1">&#39;response&#39;</span><span class="p">,</span>
                <span class="s1">&#39;target&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">ref_key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">references</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">ref_key</span><span class="p">]</span>
                <span class="c1"># print(f&quot;[INFO] Found reference data in column: &#39;{ref_key}&#39;&quot;)</span>
                <span class="k">break</span>

        <span class="c1"># If no reference column found, use None for all completions</span>
        <span class="k">if</span> <span class="n">references</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[WARNING] No reference column found. Checked: answer, solution, reference, ground_truth, target&quot;</span><span class="p">)</span>

        <span class="c1"># Ensure lists match completion length</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_lists</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">test_lists</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_lists</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">completion</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">completions</span><span class="p">):</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c1"># Get per-sample data</span>
            <span class="n">test_cases</span> <span class="o">=</span> <span class="n">test_lists</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_lists</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">reference</span> <span class="o">=</span> <span class="n">references</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">references</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>

                    <span class="c1"># Handle different reward function signatures</span>
                    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func</span><span class="p">):</span>
                        <span class="c1"># Try different calling patterns</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="c1"># Pattern 1: text + test_cases (for code execution)</span>
                            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                <span class="n">completion</span><span class="p">,</span> <span class="n">test_cases</span><span class="o">=</span><span class="n">test_cases</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="c1"># Pattern 2: Just text</span>
                                <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
                            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                <span class="k">try</span><span class="p">:</span>
                                    <span class="c1"># Pattern 3: text + reference</span>
                                    <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                        <span class="n">completion</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">reference</span><span class="p">)</span>
                                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                    <span class="k">try</span><span class="p">:</span>
                                        <span class="c1"># Pattern 4: text + reference + context</span>
                                        <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                            <span class="n">completion</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="p">{})</span>
                                    <span class="k">except</span> <span class="ne">BaseException</span><span class="p">:</span>
                                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                                            <span class="sa">f</span><span class="s2">&quot;Could not call reward function </span><span class="si">{</span>
<span class="w">                                                </span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, returning 0&quot;</span><span class="p">)</span>
                                        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function </span><span class="si">{</span>
<span class="w">                                </span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> is not callable&quot;</span><span class="p">)</span>
                        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>

                    <span class="c1"># Apply weight</span>
                    <span class="n">weighted_reward</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">*</span> <span class="n">weight</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">weighted_reward</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward </span><span class="si">{</span>
<span class="w">                            </span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span>
<span class="w">                            </span><span class="n">reward</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (weighted: </span><span class="si">{</span>
<span class="w">                            </span><span class="n">weighted_reward</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error computing reward </span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">batch_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>

        <span class="c1"># Log batch statistics with completions summary</span>
        <span class="k">if</span> <span class="n">batch_rewards</span><span class="p">:</span>
            <span class="n">successful</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">partial</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">failed</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;BATCH REWARDS: </span><span class="si">{</span><span class="n">successful</span><span class="si">}</span><span class="s2"> passed | </span><span class="si">{</span><span class="n">partial</span><span class="si">}</span><span class="s2"> partial | </span><span class="si">{</span><span class="n">failed</span><span class="si">}</span><span class="s2"> failed | total=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">len</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Reward stats: min=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">min</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">max</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, mean=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">sum</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="w"> </span><span class="o">/</span>
<span class="w">                    </span><span class="nb">len</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">batch_rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute a single training step.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;train_step() called but TRL GRPO uses TRL&#39;s internal training loop&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create data loader for training.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;create_data_loader() called but TRL GRPO uses TRL&#39;s internal data loading&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_obj</span><span class="p">,</span> <span class="o">*</span><span class="n">attr_names</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely get config value from multiple possible attribute names.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">config_obj</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">config_obj</span><span class="p">[</span><span class="n">attr_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">default</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set up the GRPO trainer with all configurations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL GRPO trainer...&quot;</span><span class="p">)</span>

        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span>
            <span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Get training parameters</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">)</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
            <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/grpo_trl&#39;</span><span class="p">)</span>

        <span class="c1"># GRPO-specific parameters (beta = KL coefficient, epsilon = clip</span>
        <span class="c1"># range)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

        <span class="c1"># Generation parameters</span>
        <span class="n">num_generations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_generations&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">max_completion_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_completion_length&#39;</span><span class="p">,</span> <span class="s1">&#39;max_new_tokens&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
        <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">top_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;top_p&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s2">&quot;max_steps&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>


        <span class="c1"># Evaluation parameters</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>

        <span class="c1"># Save parameters</span>
        <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eval_loss&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Logging parameters</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="c1"># Use eval_dataset-aware defaults</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPO Training Configuration&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epochs: </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning rate: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch size: </span><span class="si">{</span><span class="n">per_device_batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient accumulation: </span><span class="si">{</span><span class="n">gradient_accumulation_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beta (KL coefficient): </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epsilon (clip range): </span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num generations per prompt: </span><span class="si">{</span><span class="n">num_generations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max completion length: </span><span class="si">{</span><span class="n">max_completion_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Temperature: </span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output directory: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Create output directory</span>
        <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Setup GRPO trainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>

        <span class="n">grpo_config</span> <span class="o">=</span> <span class="n">GRPOConfig</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>

            <span class="c1"># Evaluation parameters</span>
            <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>

            <span class="c1"># Logging parameters</span>
            <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span> <span class="k">if</span> <span class="n">report_to</span> <span class="k">else</span> <span class="p">[],</span>

            <span class="c1"># Save parameters</span>
            <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>
            <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>
            <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
            <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>

            <span class="c1"># Training parameters</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

            <span class="c1"># Generation parameters</span>
            <span class="n">num_generations</span><span class="o">=</span><span class="n">num_generations</span><span class="p">,</span>
            <span class="n">max_completion_length</span><span class="o">=</span><span class="n">max_completion_length</span><span class="p">,</span>
            <span class="n">max_prompt_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>

            <span class="c1"># GRPO-specific</span>
            <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>

            <span class="c1"># Precision</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>
        <span class="p">)</span>


        <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
            <span class="n">backend_config</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;grpo&#39;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">grpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>


        <span class="c1"># Create GRPO trainer</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
        <span class="n">should_use_pure_trl</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PURE_TRL_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span>

        <span class="k">if</span> <span class="n">should_use_pure_trl</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PURE_TRL_MODE enabled - using pure TRL API&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">reward_funcs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="s2">&quot;Detected Unsloth environment, using reward_funcs parameter&quot;</span><span class="p">)</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">unsloth_reward_wrapper</span><span class="p">(</span>
                        <span class="n">prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">completions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">completions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span> <span class="k">if</span> <span class="n">prompts</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span><span class="p">(</span>
                        <span class="n">completions</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                    <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">reward_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">unsloth_reward_wrapper</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using pure TRL, using reward_function parameter&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                    <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">reward_funcs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO trainer setup completed successfully!&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute GRPO training.&quot;&quot;&quot;</span>
        <span class="c1"># Setup components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Get output directory for saving</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
            <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/grpo_trl&#39;</span><span class="p">)</span>

        <span class="c1"># Record training start</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting TRL GRPO Training&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num reward functions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Start training</span>
        <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Log samples after training</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># For qualitative samples we only need callable reward functions,</span>
            <span class="c1"># not the full metadata dicts stored in self.reward_functions.</span>
            <span class="n">raw_reward_funcs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_functions&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">raw_reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">reward_callables</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="n">raw_reward_funcs</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;function&quot;</span><span class="p">))</span>
                    <span class="p">]</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="c1"># Fallback: disable reward logging rather than failing</span>
                    <span class="c1"># samples</span>
                    <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">generate_and_log_samples</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">sample_logging</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">reward_callables</span><span class="p">,</span>
                <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;post-train&quot;</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">sample_error</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unable to log qualitative samples: </span><span class="si">{</span><span class="n">sample_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Record training end</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_duration</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

        <span class="c1"># Extract metrics</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">train_result</span><span class="o">.</span><span class="n">metrics</span>

        <span class="c1"># Save model</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="c1"># Compile results</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">train_result</span><span class="p">,</span>
                <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;train_loss&#39;</span><span class="p">,</span>
                <span class="mf">0.0</span><span class="p">),</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">train_result</span><span class="p">,</span>
                <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
            <span class="s2">&quot;num_datasets&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPO Training Completed Successfully!&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final loss: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total steps: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;model_path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="c1"># def evaluate(</span>
    <span class="c1">#     self,</span>
    <span class="c1">#     eval_dataset=None,</span>
    <span class="c1">#     metric_key_prefix: str = &quot;eval&quot;,</span>
    <span class="c1">#     use_custom_evaluator: bool = True,</span>
    <span class="c1">#     **kwargs</span>
    <span class="c1"># ) -&gt; Dict[str, float]:</span>
    <span class="c1">#     &quot;&quot;&quot;GRPO-specific evaluation - auto-setup evaluators and delegate to parent.&quot;&quot;&quot;</span>

    <span class="c1">#     # Auto-setup evaluators on first call</span>
    <span class="c1">#     if self.base_evaluator is None and self.rl_evaluator is None:</span>
    <span class="c1">#         logger.info(&quot;Auto-initializing evaluators for first evaluation...&quot;)</span>
    <span class="c1">#         self.setup_custom_evaluator(evaluator_type=&quot;auto&quot;)</span>

    <span class="c1">#     # Call parent&#39;s unified evaluate method</span>
    <span class="c1">#     return super().evaluate(</span>
    <span class="c1">#         eval_dataset=eval_dataset,</span>
    <span class="c1">#         metric_key_prefix=metric_key_prefix,</span>
    <span class="c1">#         use_custom_evaluator=use_custom_evaluator,</span>
    <span class="c1">#         **kwargs</span>
    <span class="c1">#     )</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_training_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get training statistics.&quot;&quot;&quot;</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;group_relative_policy_optimization&#39;</span><span class="p">,</span>
                <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                    <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">),</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                    <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
                <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="s1">&#39;precision&#39;</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
                <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="s1">&#39;dataset_info&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;train_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span>
                    <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;val_size&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;loaded&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span>
                    <span class="nb">next</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
                <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;has_peft&#39;</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="s1">&#39;peft_config&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">stats</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save configuration to YAML file.&quot;&quot;&quot;</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
            <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;group_relative_policy_optimization&#39;</span><span class="p">,</span>
            <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">),</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span>
                <span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">),</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;precision&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
            <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL GRPO configuration saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the trained GRPO model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">default_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                       <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                       <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                                   <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving Unsloth GRPO model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Save using Unsloth&#39;s optimized saving</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="c1"># Save training configuration</span>
            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;grpo_training_config.yaml&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GRPO model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">save_path</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained GRPO model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Unsloth GRPO model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Handle both dict and object config</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

            <span class="c1"># Load model and tokenizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO model loaded successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create data loader for training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create data loader for training.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
        <span class="s2">&quot;create_data_loader() called but TRL GRPO uses TRL&#39;s internal data loading&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.get_training_stats" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_training_stats</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.get_training_stats" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get training statistics.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span>
<span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span>
<span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span>
<span class="normal">988</span>
<span class="normal">989</span>
<span class="normal">990</span>
<span class="normal">991</span>
<span class="normal">992</span>
<span class="normal">993</span>
<span class="normal">994</span>
<span class="normal">995</span>
<span class="normal">996</span>
<span class="normal">997</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_training_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get training statistics.&quot;&quot;&quot;</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;group_relative_policy_optimization&#39;</span><span class="p">,</span>
            <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span>
                <span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">),</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;precision&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
            <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="s1">&#39;dataset_info&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;train_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span>
                <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;val_size&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;model_info&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;loaded&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span>
                <span class="nb">next</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span><span class="p">,</span>
            <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;has_peft&#39;</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;peft_config&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">stats</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if TRL is available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if TRL is available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a trained GRPO model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a trained GRPO model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Unsloth GRPO model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

        <span class="c1"># Handle both dict and object config</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.save_config" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_config</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.save_config" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save configuration to YAML file.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save configuration to YAML file.&quot;&quot;&quot;</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
        <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="s1">&#39;group_relative_policy_optimization&#39;</span><span class="p">,</span>
        <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">),</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span>
            <span class="s1">&#39;lr&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">),</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
        <span class="s1">&#39;dataset_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="s1">&#39;use_peft&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">),</span>
        <span class="s1">&#39;num_reward_functions&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL GRPO configuration saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the trained GRPO model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the trained GRPO model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                   <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                   <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                               <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving Unsloth GRPO model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save using Unsloth&#39;s optimized saving</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="c1"># Save training configuration</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;grpo_training_config.yaml&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GRPO model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">save_path</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets for GRPO training using unified DataManager.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets for GRPO training using unified DataManager.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up GRPO datasets with DataManager...&quot;</span><span class="p">)</span>

    <span class="c1"># Extract dataset configuration</span>
    <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

    <span class="c1"># Extract parameters</span>
    <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
    <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Advanced DataManager features</span>
    <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize DataManager for GRPO task</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

    <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;grpo&quot;</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>           <span class="c1"># System prompt</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
        <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>       <span class="c1">#  ADD THIS - Enable thinking mode</span>
        <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
        <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
        <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
    <span class="p">)</span>

    <span class="c1"># Load dataset - DataManager handles everything including chat template</span>
    <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
        <span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
        <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>



    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

    <span class="c1"># Log sample</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">prompt_col</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="k">if</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">else</span> <span class="s2">&quot;query&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample prompt (first 100 chars): </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="n">prompt_col</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>            
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup model using standard Transformers.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup model using standard Transformers.&quot;&quot;&quot;</span>
    <span class="c1"># Extract model config values safely</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="s1">&#39;name_or_path&#39;</span><span class="p">,</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
    <span class="n">trust_remote_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">)</span>
    <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;device_map&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
    <span class="n">is_ddp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">device_map</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;DDP&quot;</span><span class="p">,</span> <span class="s2">&quot;ddp&quot;</span><span class="p">]</span> <span class="ow">or</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ACCELERATE_USE_DDP&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;true&#39;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">is_ddp</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">PartialState</span>
        <span class="n">device_string</span> <span class="o">=</span> <span class="n">PartialState</span><span class="p">()</span><span class="o">.</span><span class="n">process_index</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="n">device_string</span><span class="p">}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;DDP mode detected: device_map=</span><span class="se">{{</span><span class="s2">&#39;&#39;: </span><span class="si">{</span><span class="n">device_string</span><span class="si">}</span><span class="se">}}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;load_in_8bit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;use_peft&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
    <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;TRL GRPO&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

    <span class="c1"># Auto-detect quantization from model name if not explicitly set</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">load_in_4bit</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">load_in_8bit</span><span class="p">:</span>
        <span class="n">model_name_lower</span> <span class="o">=</span> <span class="n">model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="s1">&#39;bnb-4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;4bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;awq&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Auto-detected 4-bit quantization from model name: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="s1">&#39;bnb-8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span> <span class="ow">or</span> <span class="s1">&#39;8bit&#39;</span> <span class="ow">in</span> <span class="n">model_name_lower</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Auto-detected 8-bit quantization from model name: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">load_in_8bit</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Auto-enable PEFT if using quantization (required for training</span>
    <span class="c1"># quantized models)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_peft</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Quantization detected - auto-enabling PEFT/LoRA adapters (required for training)&quot;</span><span class="p">)</span>
        <span class="n">use_peft</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL GRPO model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="s2">&quot;Transformers not available. Install with: pip install transformers&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="c1"># Load tokenizer first</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading tokenizer...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="n">trust_remote_code</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Set pad token if not set</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Set pad token to eos token&quot;</span><span class="p">)</span>

    <span class="c1"># Load model</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading model...&quot;</span><span class="p">)</span>
    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>
        <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>
        <span class="s2">&quot;trust_remote_code&quot;</span><span class="p">:</span> <span class="n">trust_remote_code</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># Add quantization if specified</span>
    <span class="k">if</span> <span class="n">load_in_4bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading model with 4-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_compute_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_quant_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nf4&quot;</span>
        <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;bnb_4bit_use_double_quant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">load_in_8bit</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading model with 8-bit quantization...&quot;</span><span class="p">)</span>
        <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;load_in_8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="o">**</span><span class="n">model_kwargs</span>
    <span class="p">)</span>

    <span class="c1"># Apply PEFT if specified or if quantization is used</span>
    <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying PEFT (LoRA) configuration...&quot;</span><span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">prepare_model_for_kbit_training</span>

        <span class="c1"># Prepare model for k-bit training if using quantization</span>
        <span class="k">if</span> <span class="n">load_in_4bit</span> <span class="ow">or</span> <span class="n">load_in_8bit</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Preparing model for k-bit training...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># Extract PEFT config values safely</span>
        <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_r&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
        <span class="n">lora_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;lora_target_modules&#39;</span><span class="p">,</span>
            <span class="s1">&#39;target_modules&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;lora_dropout&#39;</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;LoRA config: r=</span><span class="si">{</span><span class="n">lora_r</span><span class="si">}</span><span class="s2">, alpha=</span><span class="si">{</span><span class="n">lora_alpha</span><span class="si">}</span><span class="s2">, dropout=</span><span class="si">{</span><span class="n">lora_dropout</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target modules: </span><span class="si">{</span><span class="n">lora_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
            <span class="n">r</span><span class="o">=</span><span class="n">lora_r</span><span class="p">,</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="n">lora_target_modules</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PEFT adapters applied successfully&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPO model setup completed successfully&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer vocab size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup reward functions using the centralized registry system.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup reward functions using the centralized registry system.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up reward functions for GRPO...&quot;</span><span class="p">)</span>

    <span class="c1"># Get reward configurations</span>
    <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;rewards&#39;</span><span class="p">):</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">rewards_config</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;No reward configurations found, using default rewards&quot;</span><span class="p">)</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;length&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentiment&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;positive_weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;safety&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}},</span> <span class="p">{</span>
                            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;diversity&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span>
                                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">]</span>

    <span class="c1"># Load reward functions from the registry</span>
    <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="n">rewards_config</span><span class="p">:</span>
        <span class="c1"># Handle both dict and RewardConfig object</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># RewardConfig object</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Special case: custom reward function passed directly</span>
            <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="s1">&#39;reward_function&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="n">reward_func</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;reward_function&#39;</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Loaded custom reward function (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use the rewards registry to get reward functions</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span> <span class="k">as</span> <span class="n">RewardsRegistry</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardConfig</span><span class="p">,</span> <span class="n">RewardType</span>

                <span class="c1"># Map common variations to standard names</span>
                <span class="n">reward_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;math&#39;</span><span class="p">:</span> <span class="s1">&#39;math_reasoning&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;code_quality&#39;</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_type</span><span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Convert reward type string to enum</span>
                    <span class="n">reward_type_enum</span> <span class="o">=</span> <span class="n">RewardType</span><span class="p">[</span><span class="n">reward_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>

                    <span class="c1"># Create RewardConfig with weight and params</span>
                    <span class="n">reward_cfg</span> <span class="o">=</span> <span class="n">RewardConfig</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="o">=</span><span class="n">reward_type_enum</span><span class="p">,</span>
                        <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Weight will be applied separately</span>
                        <span class="n">params</span><span class="o">=</span><span class="n">params</span>
                    <span class="p">)</span>

                    <span class="c1"># Get reward function from registry</span>
                    <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_cfg</span><span class="p">)</span>
                    <span class="c1"># Extract the callable compute method</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward from registry (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="c1"># Reward type not in enum, try registry by name</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward type &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; not in RewardType enum, trying registry by name&quot;</span><span class="p">)</span>
                    <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward by name (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Store reward function with metadata</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">reward_type</span>
            <span class="p">})</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Failed to load reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Fallback: try to continue with other rewards rather than</span>
            <span class="c1"># failing</span>
            <span class="k">continue</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
            <span class="s2">&quot;No reward functions were loaded! Adding a simple default length reward.&quot;</span><span class="p">)</span>
        <span class="c1"># Add a simple fallback reward so training doesn&#39;t fail</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">default_length_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">length</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="mf">0.5</span>
            <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mf">200.0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">1.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">default_length_reward</span><span class="p">,</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;default_length&quot;</span>
        <span class="p">})</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added default length reward as fallback&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot; Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions successfully&quot;</span><span class="p">)</span>

    <span class="c1"># Log summary of loaded rewards</span>
    <span class="n">reward_summary</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">])</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_summary</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Set up the GRPO trainer with all configurations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set up the GRPO trainer with all configurations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL GRPO trainer...&quot;</span><span class="p">)</span>

    <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
    <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span>
        <span class="n">precision</span><span class="p">)</span>

    <span class="c1"># Get training parameters</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">)</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
        <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/grpo_trl&#39;</span><span class="p">)</span>

    <span class="c1"># GRPO-specific parameters (beta = KL coefficient, epsilon = clip</span>
    <span class="c1"># range)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="c1"># Generation parameters</span>
    <span class="n">num_generations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_generations&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">max_completion_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_completion_length&#39;</span><span class="p">,</span> <span class="s1">&#39;max_new_tokens&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
    <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">top_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;top_p&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

    <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s2">&quot;max_steps&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>


    <span class="c1"># Evaluation parameters</span>
    <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
    <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>

    <span class="c1"># Save parameters</span>
    <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
    <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eval_loss&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Logging parameters</span>
    <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
    <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="c1"># Use eval_dataset-aware defaults</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPO Training Configuration&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epochs: </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning rate: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch size: </span><span class="si">{</span><span class="n">per_device_batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient accumulation: </span><span class="si">{</span><span class="n">gradient_accumulation_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beta (KL coefficient): </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epsilon (clip range): </span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num generations per prompt: </span><span class="si">{</span><span class="n">num_generations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Max completion length: </span><span class="si">{</span><span class="n">max_completion_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Temperature: </span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output directory: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Create output directory</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Setup GRPO trainer</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>

    <span class="n">grpo_config</span> <span class="o">=</span> <span class="n">GRPOConfig</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
        <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>

        <span class="c1"># Evaluation parameters</span>
        <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>

        <span class="c1"># Logging parameters</span>
        <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
        <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span> <span class="k">if</span> <span class="n">report_to</span> <span class="k">else</span> <span class="p">[],</span>

        <span class="c1"># Save parameters</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
        <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
        <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>
        <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>
        <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
        <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>

        <span class="c1"># Training parameters</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
        <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

        <span class="c1"># Generation parameters</span>
        <span class="n">num_generations</span><span class="o">=</span><span class="n">num_generations</span><span class="p">,</span>
        <span class="n">max_completion_length</span><span class="o">=</span><span class="n">max_completion_length</span><span class="p">,</span>
        <span class="n">max_prompt_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
        <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>

        <span class="c1"># GRPO-specific</span>
        <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>

        <span class="c1"># Precision</span>
        <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>
    <span class="p">)</span>


    <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
        <span class="n">backend_config</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
        <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;grpo&#39;</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">grpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>


    <span class="c1"># Create GRPO trainer</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
    <span class="n">should_use_pure_trl</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PURE_TRL_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span>

    <span class="k">if</span> <span class="n">should_use_pure_trl</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PURE_TRL_MODE enabled - using pure TRL API&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">reward_funcs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Detected Unsloth environment, using reward_funcs parameter&quot;</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">unsloth_reward_wrapper</span><span class="p">(</span>
                    <span class="n">prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">completions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">completions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span> <span class="k">if</span> <span class="n">prompts</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span><span class="p">(</span>
                    <span class="n">completions</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">reward_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">unsloth_reward_wrapper</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using pure TRL, using reward_function parameter&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">reward_funcs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO trainer setup completed successfully!&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute GRPO training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute GRPO training.&quot;&quot;&quot;</span>
    <span class="c1"># Setup components</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

    <span class="c1"># Get output directory for saving</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
        <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/grpo_trl&#39;</span><span class="p">)</span>

    <span class="c1"># Record training start</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting TRL GRPO Training&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num reward functions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Start training</span>
    <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Log samples after training</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># For qualitative samples we only need callable reward functions,</span>
        <span class="c1"># not the full metadata dicts stored in self.reward_functions.</span>
        <span class="n">raw_reward_funcs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_functions&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">raw_reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">reward_callables</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="n">raw_reward_funcs</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;function&quot;</span><span class="p">))</span>
                <span class="p">]</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="c1"># Fallback: disable reward logging rather than failing</span>
                <span class="c1"># samples</span>
                <span class="n">reward_callables</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">generate_and_log_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">sample_logging</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">reward_callables</span><span class="p">,</span>
            <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;post-train&quot;</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">sample_error</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unable to log qualitative samples: </span><span class="si">{</span><span class="n">sample_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Record training end</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">training_duration</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_duration</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

    <span class="c1"># Extract metrics</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_result</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">train_result</span><span class="o">.</span><span class="n">metrics</span>

    <span class="c1"># Save model</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="c1"># Compile results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_duration</span><span class="p">,</span>
        <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">train_result</span><span class="p">,</span>
            <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">,</span>
            <span class="mf">0.0</span><span class="p">),</span>
        <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">train_result</span><span class="p">,</span>
            <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
        <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
        <span class="s2">&quot;num_datasets&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPO Training Completed Successfully!&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final loss: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total steps: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;model_path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.rl.grpo.grpo.TRLGRPOTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.trl.rl.grpo.grpo.TRLGRPOTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute a single training step.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute a single training step.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
        <span class="s2">&quot;train_step() called but TRL GRPO uses TRL&#39;s internal training loop&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<h3 id="unsloth-backends">Unsloth Backends<a class="headerlink" href="#unsloth-backends" title="Permanent link">&para;</a></h3>
<h4 id="unslothsfttrainer"><code>UnslothSFTTrainer</code><a class="headerlink" href="#unslothsfttrainer" title="Permanent link">&para;</a></h4>
<p>Unsloth backend for Supervised Fine-Tuning (faster).</p>


<div class="doc doc-object doc-class">



<a id="backends.unsloth.sft.sft.UnslothSFTTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.sft.trainer_base.SFTTrainerBase">SFTTrainerBase</span></code></p>



        <p>Enhanced SFT trainer using Unsloth with task type support.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">UnslothSFTTrainer</span><span class="p">(</span><span class="n">SFTTrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Enhanced SFT trainer using Unsloth with task type support.&quot;&quot;&quot;</span>

    <span class="c1"># Supported task types for Unsloth</span>
    <span class="n">SUPPORTED_TASKS</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">,</span>
        <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span>
    <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_task_type</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Already exists - no need to add</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># ADD THIS LINE (for BaseEvaluator)</span>

        <span class="c1"># Validate task type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_task_type</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized UnslothSFTTrainer for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_task_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TaskType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract task type from config.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;task_type&#39;</span><span class="p">):</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task_type</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;task_type&#39;</span><span class="p">):</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">task_type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Default to supervised fine-tuning</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span>

        <span class="c1"># Convert string to enum if needed</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task_type</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">task_type</span> <span class="o">=</span> <span class="n">TaskType</span><span class="p">(</span><span class="n">task_type</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">task_type</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_task_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate that the task type is supported by Unsloth.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">SUPPORTED_TASKS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Task type </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2"> is not supported by Unsloth backend. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Supported tasks: </span><span class="si">{</span><span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">value</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">SUPPORTED_TASKS</span><span class="p">]</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Use TRL backend for classification tasks.&quot;</span>
            <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if Unsloth is available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model with task-aware configuration.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up Unsloth model for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Configure Unsloth model parameters</span>
            <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
            <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;Unsloth SFT&quot;</span><span class="p">)</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

            <span class="c1"># Configure Unsloth model parameters</span>
            <span class="c1"># Unsloth only accepts load_in_4bit as boolean, not BitsAndBytesConfig parameters</span>
            <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>  <span class="c1"># Use dtype from PrecisionHandler instead of None</span>
                <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Unsloth handles quantization internally - don&#39;t pass BitsAndBytesConfig parameters</span>
            <span class="c1"># Parameters like bnb_4bit_compute_dtype, bnb_4bit_quant_type, etc. are not supported</span>

            <span class="c1"># Load model with Unsloth optimizations</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">model_kwargs</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">SyntaxError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># Handle Unsloth compiled module syntax errors (may be wrapped in RuntimeError)</span>
                <span class="n">error_msg</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="k">if</span> <span class="s2">&quot;unsloth_compiled_module&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;unexpected indent&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth compilation error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;This is a known Unsloth issue with compiled modules.&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Suggested fixes:&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  1. Clear Unsloth cache: rm -rf ~/.cache/unsloth/&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  2. Retry training after clearing cache&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  3. Use TRL backend instead: backend=&#39;trl&#39;&quot;</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Unsloth compiled module syntax error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;This is a known Unsloth library issue. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Please clear the Unsloth cache and retry, or use TRL backend instead.&quot;</span>
                    <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Re-raise if it&#39;s a different error</span>
                    <span class="k">raise</span>

            <span class="c1"># Detect model architecture for appropriate target modules</span>
            <span class="n">model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_target_modules_for_architecture</span><span class="p">(</span><span class="n">model_type</span><span class="p">)</span>

            <span class="c1"># Validate target modules exist in the model</span>
            <span class="n">available_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()]</span>
            <span class="n">valid_target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">tm</span> <span class="k">for</span> <span class="n">tm</span> <span class="ow">in</span> <span class="n">target_modules</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">tm</span> <span class="ow">in</span> <span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">available_modules</span><span class="p">)]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_target_modules</span><span class="p">:</span>
                <span class="c1"># Try to auto-detect target modules</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;None of the target modules </span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2"> found in model. Attempting auto-detection...&quot;</span><span class="p">)</span>
                <span class="n">valid_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_auto_detect_target_modules</span><span class="p">(</span><span class="n">available_modules</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_target_modules</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Target modules </span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2"> not found in the base model (type: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Available modules include: </span><span class="si">{</span><span class="n">available_modules</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">... &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Please check the target modules and try again, or use a different model architecture.&quot;</span>
                <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using target modules for </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">valid_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Configure model for training with LoRA</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
                <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># LoRA rank</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">valid_target_modules</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="s2">&quot;unsloth&quot;</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
                <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">loftq_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Setup tokenizer based on task type</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_tokenizer_for_task</span><span class="p">()</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth model setup completed successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup Unsloth model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_target_modules_for_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get appropriate target modules based on model architecture.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;qwen&quot;</span> <span class="ow">in</span> <span class="n">model_type</span> <span class="ow">or</span> <span class="s2">&quot;qwen2&quot;</span> <span class="ow">in</span> <span class="n">model_type</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;llama&quot;</span> <span class="ow">in</span> <span class="n">model_type</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;mistral&quot;</span> <span class="ow">in</span> <span class="n">model_type</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;phi&quot;</span> <span class="ow">in</span> <span class="n">model_type</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;gemma&quot;</span> <span class="ow">in</span> <span class="n">model_type</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;gpt2&quot;</span> <span class="ow">in</span> <span class="n">model_type</span> <span class="ow">or</span> <span class="s2">&quot;gpt&quot;</span> <span class="ow">in</span> <span class="n">model_type</span> <span class="ow">or</span> <span class="s2">&quot;dialogpt&quot;</span> <span class="ow">in</span> <span class="n">model_type</span><span class="p">:</span>
            <span class="c1"># GPT-2 and DialoGPT use different module names</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;c_attn&quot;</span><span class="p">,</span> <span class="s2">&quot;c_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;c_fc&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Try to auto-detect by checking model structure</span>
            <span class="c1"># Default to common attention modules, but will be validated</span>
            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_auto_detect_target_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">available_modules</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Auto-detect target modules from available modules.&quot;&quot;&quot;</span>
        <span class="c1"># Common patterns for attention modules</span>
        <span class="n">patterns</span> <span class="o">=</span> <span class="p">[</span>
            <span class="c1"># GPT-2 style</span>
            <span class="p">(</span><span class="s2">&quot;c_attn&quot;</span><span class="p">,</span> <span class="s2">&quot;c_proj&quot;</span><span class="p">),</span>
            <span class="c1"># LLaMA/Qwen style</span>
            <span class="p">(</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">),</span>
            <span class="c1"># BERT style</span>
            <span class="p">(</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">),</span>
            <span class="c1"># Generic attention</span>
            <span class="p">(</span><span class="s2">&quot;attn&quot;</span><span class="p">,</span> <span class="s2">&quot;attention&quot;</span><span class="p">),</span>
        <span class="p">]</span>

        <span class="n">detected</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pattern_group</span> <span class="ow">in</span> <span class="n">patterns</span><span class="p">:</span>
            <span class="n">matches</span> <span class="o">=</span> <span class="p">[</span><span class="n">mod</span> <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">available_modules</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="ow">in</span> <span class="n">mod</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pattern_group</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">matches</span><span class="p">:</span>
                <span class="c1"># Get unique module names (remove duplicates)</span>
                <span class="n">unique_matches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">matches</span> <span class="k">if</span> <span class="s1">&#39;.&#39;</span> <span class="ow">in</span> <span class="n">m</span><span class="p">]))</span>
                <span class="k">if</span> <span class="n">unique_matches</span><span class="p">:</span>
                    <span class="n">detected</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">unique_matches</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>  <span class="c1"># Limit to 4 modules</span>
                    <span class="k">break</span>

        <span class="k">return</span> <span class="n">detected</span> <span class="k">if</span> <span class="n">detected</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_tokenizer_for_task</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup tokenizer with task-specific configurations.&quot;&quot;&quot;</span>
        <span class="c1"># Ensure pad token is set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

        <span class="c1"># If a chat template is explicitly provided in config, try to apply it</span>
        <span class="c1"># so `tokenizer.apply_chat_template(...)` works across SFT task types.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
            <span class="n">cfg_template</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">has_template</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">_normalize_template_name</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">None</span>
                <span class="n">v</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;none&quot;</span><span class="p">}:</span>
                    <span class="k">return</span> <span class="kc">None</span>
                <span class="c1"># common aliases used in configs</span>
                <span class="k">if</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;llama3&quot;</span><span class="p">,</span> <span class="s2">&quot;llama_3&quot;</span><span class="p">,</span> <span class="s2">&quot;llama-3&quot;</span><span class="p">}:</span>
                    <span class="k">return</span> <span class="s2">&quot;llama-3&quot;</span>
                <span class="k">if</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;llama2&quot;</span><span class="p">,</span> <span class="s2">&quot;llama_2&quot;</span><span class="p">,</span> <span class="s2">&quot;llama-2&quot;</span><span class="p">}:</span>
                    <span class="k">return</span> <span class="s2">&quot;llama-2&quot;</span>
                <span class="k">return</span> <span class="n">name</span>

            <span class="n">normalized</span> <span class="o">=</span> <span class="n">_normalize_template_name</span><span class="p">(</span><span class="n">cfg_template</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">normalized</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_template</span><span class="p">:</span>
                <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;role&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;user&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;assistant&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_chat_template</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">chat_template</span><span class="o">=</span><span class="n">normalized</span><span class="p">,</span>
                    <span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied configured chat template for SFT: </span><span class="si">{</span><span class="n">normalized</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skipping configured chat template application: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Add chat template for chat completion tasks</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying Unsloth chat template...&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Get chat template from config if available</span>
            <span class="n">chat_template</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;chat_template&#39;</span><span class="p">):</span>
                <span class="n">chat_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">chat_template</span>

            <span class="c1"># Default mapping</span>
            <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;role&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;user&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;assistant&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">}</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_chat_template</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span> <span class="k">if</span> <span class="n">chat_template</span> <span class="k">else</span> <span class="s2">&quot;llama-3&quot;</span><span class="p">,</span> <span class="c1"># Default to llama-3 if not specified</span>
                    <span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied chat template: </span><span class="si">{</span><span class="n">chat_template</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">chat_template</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;llama-3 (default)&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to apply Unsloth chat template: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Falling back to manual template.&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;chat_template&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="s2">&quot;{</span><span class="si">% f</span><span class="s2">or message in messages %}&quot;</span>
                        <span class="s2">&quot;{{ message[&#39;role&#39;] }}: {{ message[&#39;content&#39;] }}</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;{</span><span class="si">% e</span><span class="s2">ndfor %}Assistant:&quot;</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added manual chat template to tokenizer&quot;</span><span class="p">)</span>

        <span class="c1"># Add special tokens for instruction following if needed</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="n">has_chat_template</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;apply_chat_template&quot;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;chat_template&quot;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_chat_template</span><span class="p">:</span>
                <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;|im_start|&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;|im_end|&gt;&quot;</span><span class="p">]</span>
                <span class="n">num_added</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span>
                    <span class="s1">&#39;additional_special_tokens&#39;</span><span class="p">:</span> <span class="n">special_tokens</span>
                <span class="p">})</span>
                <span class="k">if</span> <span class="n">num_added</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="n">num_added</span><span class="si">}</span><span class="s2"> special tokens for instruction following&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_chat_template_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="n">add_generation_prompt</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply tokenizer chat template with broad compatibility.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;apply_chat_template&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">messages</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="n">add_generation_prompt</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_format_with_chat_template</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">ds_cfg</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a `text` field using the model&#39;s chat template when available.</span>
<span class="sd">        Falls back to legacy string formatting if templating fails.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s2">&quot;system_prompt&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_prepend_system_if_missing</span><span class="p">(</span><span class="n">msgs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
            <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">msgs</span> <span class="ow">or</span> <span class="n">msgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;role&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;system&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">}]</span> <span class="o">+</span> <span class="n">msgs</span>
            <span class="k">return</span> <span class="n">msgs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">messages_field</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">messages_column</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s2">&quot;messages_column&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;messages&quot;</span>
            <span class="k">for</span> <span class="n">messages</span> <span class="ow">in</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">messages_field</span><span class="p">,</span> <span class="p">[]):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">msgs</span> <span class="o">=</span> <span class="n">_prepend_system_if_missing</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
                    <span class="n">templated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_chat_template_safe</span><span class="p">(</span><span class="n">msgs</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">templated</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">templated</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="n">conversation</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;role&#39;</span><span class="p">,</span><span class="s1">&#39;user&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;content&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">msgs</span><span class="p">]</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">conversation</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span> <span class="k">if</span> <span class="n">messages</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">,</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span><span class="p">]:</span>
            <span class="n">instr_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s2">&quot;instruction_column&quot;</span><span class="p">,</span> <span class="s2">&quot;instruction&quot;</span><span class="p">)</span>
            <span class="n">resp_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s2">&quot;response_column&quot;</span><span class="p">,</span> <span class="s2">&quot;response&quot;</span><span class="p">)</span>
            <span class="n">ctx_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s2">&quot;context_column&quot;</span><span class="p">,</span> <span class="s2">&quot;context&quot;</span><span class="p">)</span>
            <span class="n">input_col</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s2">&quot;input_column&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span><span class="p">)</span>

            <span class="n">instructions</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">instr_col</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;instruction&quot;</span><span class="p">,</span> <span class="p">[]))</span>
            <span class="n">responses</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">resp_col</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;response&quot;</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="p">[])))</span>

            <span class="n">n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">instructions</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">responses</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">instruction</span> <span class="o">=</span> <span class="n">instructions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                <span class="n">context</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">ctx_col</span> <span class="ow">in</span> <span class="n">examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ctx_col</span><span class="p">,</span> <span class="p">[])):</span>
                    <span class="n">context</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ctx_col</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>
                <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">input_col</span> <span class="ow">in</span> <span class="n">examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">input_col</span><span class="p">,</span> <span class="p">[])):</span>
                    <span class="n">input_text</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">input_col</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])[</span><span class="n">i</span><span class="p">]</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>

                <span class="n">sys_parts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">system_prompt</span><span class="p">:</span>
                    <span class="n">sys_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">context</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="n">sys_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">sys_parts</span><span class="p">:</span>
                    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sys_parts</span><span class="p">)})</span>

                <span class="n">user_content</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">instruction</span><span class="p">)</span> <span class="k">if</span> <span class="n">instruction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">input_text</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="n">user_content</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="se">\n\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_content</span><span class="p">})</span>
                <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span> <span class="k">if</span> <span class="n">response</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">})</span>

                <span class="n">templated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_chat_template_safe</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">templated</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">templated</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fallback to legacy formatting (inline)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">context</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;system</span><span class="se">\n</span><span class="s2">Context: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;&quot;</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&lt;|im_end|&gt;&quot;</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="si">{</span><span class="n">user_content</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
                <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;[NO_VALID_TEXT]&quot;</span><span class="p">]</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;[NO_VALID_TEXT]&quot;</span><span class="p">])}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup and prepare dataset for training (required by abstract base class).&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute a single training step (required by abstract base class).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Trainer not initialized. Call setup_model() first.&quot;</span><span class="p">)</span>

        <span class="c1"># The actual training step is handled by TRL&#39;s SFTTrainer</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup and prepare dataset with task-aware formatting.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

            <span class="n">ds_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">ds_cfg</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Prepare load_dataset arguments</span>
            <span class="n">load_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># Add split parameter</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">split</span><span class="p">:</span>
                <span class="n">load_kwargs</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">split</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">load_kwargs</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span>

            <span class="c1"># Handle dataset config/subset (for datasets like wikitext that require it)</span>
            <span class="n">dataset_name</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">name</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;subset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
                <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">subset</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using dataset config/subset: </span><span class="si">{</span><span class="n">dataset_config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
                <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">config</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using dataset config: </span><span class="si">{</span><span class="n">dataset_config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Load dataset with or without config</span>
            <span class="c1"># Special handling for SQuAD (both v1.1 and v2.0) which use deprecated &#39;List&#39; feature type</span>
            <span class="k">if</span> <span class="s2">&quot;squad&quot;</span> <span class="ow">in</span> <span class="n">dataset_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected SQuAD dataset. Using workaround for deprecated &#39;List&#39; feature type...&quot;</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Method 1: Try loading with builder to bypass feature validation</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset_builder</span>
                    <span class="n">builder</span> <span class="o">=</span> <span class="n">load_dataset_builder</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span> <span class="k">if</span> <span class="n">dataset_config</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

                    <span class="c1"># Download and prepare</span>
                    <span class="n">builder</span><span class="o">.</span><span class="n">download_and_prepare</span><span class="p">()</span>

                    <span class="c1"># Load from cache, bypassing feature type validation</span>
                    <span class="n">split_name</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">as_dataset</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="n">split_name</span><span class="p">)</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> using builder workaround&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e_builder</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Builder method failed: </span><span class="si">{</span><span class="n">e_builder</span><span class="si">}</span><span class="s2">. Trying alternative approach...&quot;</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="c1"># Method 2: Try loading with ignore_verifications (if supported)</span>
                        <span class="n">load_kwargs_alt</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                        <span class="n">load_kwargs_alt</span><span class="p">[</span><span class="s1">&#39;download_mode&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;force_redownload&#39;</span>
                        <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_alt</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_alt</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> with force_redownload&quot;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e2</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Force redownload failed: </span><span class="si">{</span><span class="n">e2</span><span class="si">}</span><span class="s2">. Trying feature patching...&quot;</span><span class="p">)</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="c1"># Method 3: Patch Features.from_dict to handle List -&gt; Sequence conversion</span>
                            <span class="kn">import</span><span class="w"> </span><span class="nn">datasets</span>
                            <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
                            <span class="n">original_from_dict</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Features</span><span class="o">.</span><span class="n">from_dict</span>

                            <span class="k">def</span><span class="w"> </span><span class="nf">patched_from_dict</span><span class="p">(</span><span class="n">features_dict</span><span class="p">):</span>
<span class="w">                                </span><span class="sd">&quot;&quot;&quot;Patch to convert &#39;List&#39; to &#39;Sequence&#39; in feature dict.&quot;&quot;&quot;</span>
                                <span class="c1"># Convert to string, replace, convert back</span>
                                <span class="n">features_str</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">features_dict</span><span class="p">)</span>
                                <span class="n">features_str</span> <span class="o">=</span> <span class="n">features_str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;&quot;List&quot;&#39;</span><span class="p">,</span> <span class="s1">&#39;&quot;Sequence&quot;&#39;</span><span class="p">)</span>
                                <span class="n">features_str</span> <span class="o">=</span> <span class="n">features_str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;List&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;Sequence&#39;&quot;</span><span class="p">)</span>
                                <span class="n">features_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">features_str</span><span class="p">)</span>
                                <span class="k">return</span> <span class="n">original_from_dict</span><span class="p">(</span><span class="n">features_dict</span><span class="p">)</span>

                            <span class="c1"># Temporarily patch</span>
                            <span class="n">datasets</span><span class="o">.</span><span class="n">Features</span><span class="o">.</span><span class="n">from_dict</span> <span class="o">=</span> <span class="n">patched_from_dict</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> with feature patching&quot;</span><span class="p">)</span>
                            <span class="k">finally</span><span class="p">:</span>
                                <span class="c1"># Restore original</span>
                                <span class="n">datasets</span><span class="o">.</span><span class="n">Features</span><span class="o">.</span><span class="n">from_dict</span> <span class="o">=</span> <span class="n">original_from_dict</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e3</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All SQuAD loading methods failed. Last error: </span><span class="si">{</span><span class="n">e3</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; uses deprecated &#39;List&#39; feature type that cannot be automatically fixed. &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Please try: pip install --upgrade datasets&gt;=2.14.0, &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;or consider using an alternative Q&amp;A dataset like &#39;allenai/sciq&#39; or &#39;deepmind/code_contests&#39;. &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e3</span><span class="p">)[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e3</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">error_msg</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                    <span class="c1"># Handle deprecated &#39;List&#39; feature type for other datasets</span>
                    <span class="k">if</span> <span class="s2">&quot;Feature type &#39;List&#39; not found&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;&#39;List&#39;&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; uses deprecated &#39;List&#39; feature type. &quot;</span>
                                     <span class="sa">f</span><span class="s2">&quot;Trying to load with download_mode=&#39;force_redownload&#39;...&quot;</span><span class="p">)</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">load_kwargs_retry</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                            <span class="n">load_kwargs_retry</span><span class="p">[</span><span class="s1">&#39;download_mode&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;force_redownload&#39;</span>
                            <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_retry</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_retry</span><span class="p">)</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded dataset with updated features&quot;</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e2</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load dataset: </span><span class="si">{</span><span class="n">e2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; uses deprecated &#39;List&#39; feature type. &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Please try: pip install --upgrade datasets&gt;=2.14.0. &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Original error: </span><span class="si">{</span><span class="n">error_msg</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
                    <span class="k">elif</span> <span class="s2">&quot;Config name is missing&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;config&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; requires a config/subset name. &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Add &#39;subset&#39; or &#39;config&#39; parameter to your DatasetConfig. &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="n">error_msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; requires a config/subset name. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Please add &#39;subset&#39; or &#39;config&#39; to your DatasetConfig. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Original error: </span><span class="si">{</span><span class="n">error_msg</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

            <span class="c1"># Apply subset selection</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
                <span class="n">original_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">ds_cfg</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied max_samples limit: </span><span class="si">{</span><span class="n">original_len</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">percent</span><span class="p">:</span>
                <span class="n">original_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
                <span class="n">max_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">percent</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_samples</span><span class="p">))</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied percent limit (</span><span class="si">{</span><span class="n">ds_cfg</span><span class="o">.</span><span class="n">percent</span><span class="si">}</span><span class="s2">%): </span><span class="si">{</span><span class="n">original_len</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

            <span class="c1"># Auto-detect schema if enabled</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;auto_detect_fields&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">auto_detect_fields</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-detecting dataset schema...&quot;</span><span class="p">)</span>
                <span class="n">detected_format</span> <span class="o">=</span> <span class="n">schema_detector</span><span class="o">.</span><span class="n">detect_format</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">detected_format</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Auto-detected dataset format: </span><span class="si">{</span><span class="n">detected_format</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;format_type&#39;</span><span class="p">):</span>
                        <span class="n">ds_cfg</span><span class="o">.</span><span class="n">format_type</span> <span class="o">=</span> <span class="n">detected_format</span>

            <span class="c1"># Apply field mappings</span>
            <span class="n">field_mappings</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;field_mappings&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">field_mappings</span><span class="p">:</span>
                <span class="n">field_mappings</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">field_mappings</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applying field mappings: </span><span class="si">{</span><span class="n">field_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">:</span>
                <span class="n">field_mappings</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">column_mapping</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applying column mappings: </span><span class="si">{</span><span class="n">field_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">field_mappings</span><span class="p">:</span>
                <span class="c1"># Only rename columns that exist in the dataset</span>
                <span class="n">valid_mappings</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">field_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">}</span>
                <span class="k">if</span> <span class="n">valid_mappings</span><span class="p">:</span>
                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">valid_mappings</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns: </span><span class="si">{</span><span class="n">valid_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No valid column mappings found. Available columns: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Log dataset structure</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample data (first item): </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Task-specific formatting</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_dataset_for_task</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">ds_cfg</span><span class="p">)</span>

            <span class="c1"># Split train/test</span>
            <span class="c1"># Always create eval split if dataset has at least 2 samples (minimum for split)</span>
            <span class="c1"># For very small datasets, use a smaller test_size to ensure eval set has at least 1 sample</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>
                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># 10% for larger datasets</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># 20% for medium datasets (ensures at least 1 eval sample)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># 20% for very small datasets (2-4 samples -&gt; at least 1 eval)</span>

                <span class="n">split_ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Split dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> eval&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Only skip split if dataset has less than 2 samples</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset too small for split (only </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples), using all for training. No eval dataset created.&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset prepared: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> training samples&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_format_dataset_for_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">ds_cfg</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Format dataset based on task type.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Formatting dataset for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Select appropriate formatter</span>
        <span class="n">can_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;apply_chat_template&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_with_chat_template</span> <span class="k">if</span> <span class="n">can_template</span> <span class="k">else</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_instruction_following</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">SUPERVISED_FINE_TUNING</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_with_chat_template</span> <span class="k">if</span> <span class="n">can_template</span> <span class="k">else</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_supervised_fine_tuning</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_text_generation</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_with_chat_template</span> <span class="k">if</span> <span class="n">can_template</span> <span class="k">else</span> <span class="n">TaskFormatter</span><span class="o">.</span><span class="n">format_chat_completion</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Apply formatting</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">formatted_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">formatter</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">ds_cfg</span><span class="p">),</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">remove_columns</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Formatting for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Verify formatting</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">formatted_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample formatted text (first 200 chars): </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">][:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">formatted_dataset</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error formatting dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Fallback to simple formatting</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Using fallback formatting&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fallback_format</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">ds_cfg</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_fallback_format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">ds_cfg</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fallback formatting when task-specific formatting fails.&quot;&quot;&quot;</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">simple_format</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># Try common column names</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="s2">&quot;instruction&quot;</span> <span class="ow">in</span> <span class="n">examples</span> <span class="ow">and</span> <span class="s2">&quot;response&quot;</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">examples</span><span class="p">[</span><span class="s1">&#39;instruction&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">examples</span><span class="p">[</span><span class="s1">&#39;response&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">elif</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Use first text-like column</span>
                    <span class="n">first_col</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">first_col</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>

                <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">simple_format</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup TRL SFTTrainer with task-aware configuration.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL SFTTrainer for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Get training parameters</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> \
                        <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">3</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> \
                        <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2</span>
            <span class="n">grad_accum</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-4</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">2e-4</span>
            <span class="n">save_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">500</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output&#39;</span>
            <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

                <span class="c1"># Create SFT configuration</span>

            <span class="c1"># Create SFT configuration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_config</span> <span class="o">=</span> <span class="n">SFTConfig</span><span class="p">(</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">grad_accum</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
                <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
                <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>  
                <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;tensorboard&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Get max_seq_length</span>
            <span class="n">max_seq_len</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2048</span>

            <span class="c1"># Task-specific trainer settings</span>
            <span class="n">packing</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Generally disable packing for better quality</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">:</span>
                <span class="n">packing</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Can enable packing for simple text generation</span>

            <span class="c1"># Create trainer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_config</span><span class="p">,</span>
                <span class="n">dataset_text_field</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span>
                <span class="n">dataset_num_proc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">packing</span><span class="o">=</span><span class="n">packing</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFTTrainer setup completed for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training config: </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2"> epochs, batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute training with Unsloth optimizations.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting Unsloth SFT training for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="c1"># Setup components</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

            <span class="c1"># Suppress Unsloth&#39;s informational warning about num_items_in_batch</span>
            <span class="c1"># This is a known limitation with Qwen2 models and gradient accumulation</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*num_items_in_batch.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*Qwen2ForCausalLM does not accept.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
                <span class="c1"># Start training</span>
                <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Save model</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

            <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

            <span class="c1"># Compile results</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
                <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
                <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">global_step</span><span class="p">,</span>
                <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
                <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth SFT training completed in </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">, Final loss: </span><span class="si">{</span><span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the trained model with task-specific metrics.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset available&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">{}</span>

            <span class="k">if</span> <span class="n">eval_dataset</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluating Unsloth SFT model for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Suppress Unsloth&#39;s informational warning about num_items_in_batch</span>
            <span class="c1"># This is a known limitation with Qwen2 models and gradient accumulation</span>
            <span class="c1"># It doesn&#39;t affect functionality, just makes gradient accumulation slightly less accurate</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*num_items_in_batch.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*Qwen2ForCausalLM does not accept.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
                <span class="c1"># Run basic evaluation from TRL trainer</span>
                <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

            <span class="c1"># Add task-specific metrics</span>
            <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;task_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>

            <span class="c1"># Calculate perplexity from loss (if available)</span>
            <span class="k">if</span> <span class="s2">&quot;eval_loss&quot;</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_perplexity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not calculate perplexity: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Add comprehensive quality metrics using SFTEvaluator</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.evaluator</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTEvaluator</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">SFTEvaluator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
                    <span class="n">quality_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
                        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                    <span class="p">)</span>

                    <span class="c1"># Merge quality metrics (avoid duplicates)</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">quality_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>  <span class="c1"># Don&#39;t override existing metrics</span>
                            <span class="n">eval_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">quality_metrics</span><span class="p">)</span><span class="si">}</span><span class="s2"> quality metrics&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not compute quality metrics: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation results: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span><span class="si">}</span><span class="s2"> metrics computed&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">eval_results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate task-specific sample outputs.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generating </span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s2"> samples for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Get task-specific prompts</span>
            <span class="n">sample_prompts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sample_prompts_for_task</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>

            <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_prompts</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Tokenize input</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

                    <span class="c1"># Move to device</span>
                    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

                    <span class="c1"># Generate response</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                            <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                            <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                            <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="p">)</span>

                    <span class="c1"># Decode response</span>
                    <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

                    <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                        <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                        <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
                        <span class="s2">&quot;sample_id&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="p">})</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate sample </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                        <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                        <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Generation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;sample_id&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="p">})</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">samples</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample generation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_sample_prompts_for_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get task-specific sample prompts for generation.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">INSTRUCTION_FOLLOWING</span><span class="p">:</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Explain machine learning.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Write a Python function.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">What is AI?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">Describe deep learning.&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&lt;|im_start|&gt;user</span><span class="se">\n</span><span class="s2">How does training work?&lt;|im_end|&gt;</span><span class="se">\n</span><span class="s2">&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">CHAT_COMPLETION</span><span class="p">:</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;Human: Hello!</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: How are you?</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: Explain quantum computing.</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: Tell me a joke.</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Human: What&#39;s the weather?</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">:</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;The future of AI is&quot;</span><span class="p">,</span>
                <span class="s2">&quot;In a world where&quot;</span><span class="p">,</span>
                <span class="s2">&quot;The key to success is&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Technology has changed&quot;</span><span class="p">,</span>
                <span class="s2">&quot;The most important skill is&quot;</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># SUPERVISED_FINE_TUNING</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="s2">Explain machine learning.</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="s2">Write code.</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="s2">What is AI?</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="s2">Describe NLP.</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;### Instruction:</span><span class="se">\n</span><span class="s2">How to train models?</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">]</span>

        <span class="k">return</span> <span class="n">prompts</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the trained model with task metadata.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output&#39;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving Unsloth model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Save using Unsloth&#39;s optimized saving</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="c1"># Save training configuration with task type</span>
            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="p">{}</span>
            <span class="n">config_dict</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Store for push_to_hub</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="o">=</span> <span class="n">save_path</span>

            <span class="k">return</span> <span class="n">save_path</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained model with task type detection.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Unsloth model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Try to load task type from config</span>
            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
            <span class="k">if</span> <span class="n">config_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">saved_config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                    <span class="k">if</span> <span class="s1">&#39;task_type&#39;</span> <span class="ow">in</span> <span class="n">saved_config</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="n">TaskType</span><span class="p">(</span><span class="n">saved_config</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">])</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Load model and tokenizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2048</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Evaluate the trained model with task-specific metrics.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate the trained model with task-specific metrics.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset available&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluating Unsloth SFT model for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Suppress Unsloth&#39;s informational warning about num_items_in_batch</span>
        <span class="c1"># This is a known limitation with Qwen2 models and gradient accumulation</span>
        <span class="c1"># It doesn&#39;t affect functionality, just makes gradient accumulation slightly less accurate</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*num_items_in_batch.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*Qwen2ForCausalLM does not accept.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
            <span class="c1"># Run basic evaluation from TRL trainer</span>
            <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

        <span class="c1"># Add task-specific metrics</span>
        <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;task_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>

        <span class="c1"># Calculate perplexity from loss (if available)</span>
        <span class="k">if</span> <span class="s2">&quot;eval_loss&quot;</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_perplexity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eval_results</span><span class="p">[</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not calculate perplexity: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Add comprehensive quality metrics using SFTEvaluator</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.evaluator</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTEvaluator</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">evaluator</span> <span class="o">=</span> <span class="n">SFTEvaluator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
                <span class="n">quality_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="p">)</span>

                <span class="c1"># Merge quality metrics (avoid duplicates)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">quality_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>  <span class="c1"># Don&#39;t override existing metrics</span>
                        <span class="n">eval_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Added </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">quality_metrics</span><span class="p">)</span><span class="si">}</span><span class="s2"> quality metrics&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not compute quality metrics: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation results: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span><span class="si">}</span><span class="s2"> metrics computed&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eval_results</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.generate_samples" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_samples</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.generate_samples" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate task-specific sample outputs.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate task-specific sample outputs.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generating </span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s2"> samples for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Get task-specific prompts</span>
        <span class="n">sample_prompts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sample_prompts_for_task</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_prompts</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Tokenize input</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

                <span class="c1"># Move to device</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

                <span class="c1"># Generate response</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                        <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                        <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="p">)</span>

                <span class="c1"># Decode response</span>
                <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span>
                    <span class="s2">&quot;sample_id&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="p">})</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate sample </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Generation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;sample_id&quot;</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="p">})</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample generation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if Unsloth is available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if Unsloth is available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a trained model with task type detection.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a trained model with task type detection.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Unsloth model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Try to load task type from config</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
        <span class="k">if</span> <span class="n">config_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">saved_config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                <span class="k">if</span> <span class="s1">&#39;task_type&#39;</span> <span class="ow">in</span> <span class="n">saved_config</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="n">TaskType</span><span class="p">(</span><span class="n">saved_config</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">])</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2048</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the trained model with task metadata.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the trained model with task metadata.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output&#39;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving Unsloth model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save using Unsloth&#39;s optimized saving</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="c1"># Save training configuration with task type</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">config_dict</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Store for push_to_hub</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="o">=</span> <span class="n">save_path</span>

        <span class="k">return</span> <span class="n">save_path</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup and prepare dataset for training (required by abstract base class).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup and prepare dataset for training (required by abstract base class).&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.setup_dataset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_dataset</span><span class="p">()</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_dataset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup and prepare dataset with task-aware formatting.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup and prepare dataset with task-aware formatting.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

        <span class="n">ds_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">ds_cfg</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Prepare load_dataset arguments</span>
        <span class="n">load_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Add split parameter</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">split</span><span class="p">:</span>
            <span class="n">load_kwargs</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">split</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">load_kwargs</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span>

        <span class="c1"># Handle dataset config/subset (for datasets like wikitext that require it)</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">name</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;subset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">subset</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using dataset config/subset: </span><span class="si">{</span><span class="n">dataset_config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">config</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using dataset config: </span><span class="si">{</span><span class="n">dataset_config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load dataset with or without config</span>
        <span class="c1"># Special handling for SQuAD (both v1.1 and v2.0) which use deprecated &#39;List&#39; feature type</span>
        <span class="k">if</span> <span class="s2">&quot;squad&quot;</span> <span class="ow">in</span> <span class="n">dataset_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected SQuAD dataset. Using workaround for deprecated &#39;List&#39; feature type...&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Method 1: Try loading with builder to bypass feature validation</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset_builder</span>
                <span class="n">builder</span> <span class="o">=</span> <span class="n">load_dataset_builder</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span> <span class="k">if</span> <span class="n">dataset_config</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

                <span class="c1"># Download and prepare</span>
                <span class="n">builder</span><span class="o">.</span><span class="n">download_and_prepare</span><span class="p">()</span>

                <span class="c1"># Load from cache, bypassing feature type validation</span>
                <span class="n">split_name</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">as_dataset</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="n">split_name</span><span class="p">)</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> using builder workaround&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e_builder</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Builder method failed: </span><span class="si">{</span><span class="n">e_builder</span><span class="si">}</span><span class="s2">. Trying alternative approach...&quot;</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Method 2: Try loading with ignore_verifications (if supported)</span>
                    <span class="n">load_kwargs_alt</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="n">load_kwargs_alt</span><span class="p">[</span><span class="s1">&#39;download_mode&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;force_redownload&#39;</span>
                    <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_alt</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_alt</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> with force_redownload&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e2</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Force redownload failed: </span><span class="si">{</span><span class="n">e2</span><span class="si">}</span><span class="s2">. Trying feature patching...&quot;</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="c1"># Method 3: Patch Features.from_dict to handle List -&gt; Sequence conversion</span>
                        <span class="kn">import</span><span class="w"> </span><span class="nn">datasets</span>
                        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
                        <span class="n">original_from_dict</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Features</span><span class="o">.</span><span class="n">from_dict</span>

                        <span class="k">def</span><span class="w"> </span><span class="nf">patched_from_dict</span><span class="p">(</span><span class="n">features_dict</span><span class="p">):</span>
<span class="w">                            </span><span class="sd">&quot;&quot;&quot;Patch to convert &#39;List&#39; to &#39;Sequence&#39; in feature dict.&quot;&quot;&quot;</span>
                            <span class="c1"># Convert to string, replace, convert back</span>
                            <span class="n">features_str</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">features_dict</span><span class="p">)</span>
                            <span class="n">features_str</span> <span class="o">=</span> <span class="n">features_str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;&quot;List&quot;&#39;</span><span class="p">,</span> <span class="s1">&#39;&quot;Sequence&quot;&#39;</span><span class="p">)</span>
                            <span class="n">features_str</span> <span class="o">=</span> <span class="n">features_str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;List&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;Sequence&#39;&quot;</span><span class="p">)</span>
                            <span class="n">features_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">features_str</span><span class="p">)</span>
                            <span class="k">return</span> <span class="n">original_from_dict</span><span class="p">(</span><span class="n">features_dict</span><span class="p">)</span>

                        <span class="c1"># Temporarily patch</span>
                        <span class="n">datasets</span><span class="o">.</span><span class="n">Features</span><span class="o">.</span><span class="n">from_dict</span> <span class="o">=</span> <span class="n">patched_from_dict</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> with feature patching&quot;</span><span class="p">)</span>
                        <span class="k">finally</span><span class="p">:</span>
                            <span class="c1"># Restore original</span>
                            <span class="n">datasets</span><span class="o">.</span><span class="n">Features</span><span class="o">.</span><span class="n">from_dict</span> <span class="o">=</span> <span class="n">original_from_dict</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e3</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;All SQuAD loading methods failed. Last error: </span><span class="si">{</span><span class="n">e3</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; uses deprecated &#39;List&#39; feature type that cannot be automatically fixed. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Please try: pip install --upgrade datasets&gt;=2.14.0, &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;or consider using an alternative Q&amp;A dataset like &#39;allenai/sciq&#39; or &#39;deepmind/code_contests&#39;. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e3</span><span class="p">)[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e3</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">error_msg</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="c1"># Handle deprecated &#39;List&#39; feature type for other datasets</span>
                <span class="k">if</span> <span class="s2">&quot;Feature type &#39;List&#39; not found&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;&#39;List&#39;&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; uses deprecated &#39;List&#39; feature type. &quot;</span>
                                 <span class="sa">f</span><span class="s2">&quot;Trying to load with download_mode=&#39;force_redownload&#39;...&quot;</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">load_kwargs_retry</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                        <span class="n">load_kwargs_retry</span><span class="p">[</span><span class="s1">&#39;download_mode&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;force_redownload&#39;</span>
                        <span class="k">if</span> <span class="n">dataset_config</span><span class="p">:</span>
                            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dataset_config</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_retry</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="o">**</span><span class="n">load_kwargs_retry</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully loaded dataset with updated features&quot;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e2</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load dataset: </span><span class="si">{</span><span class="n">e2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; uses deprecated &#39;List&#39; feature type. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Please try: pip install --upgrade datasets&gt;=2.14.0. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Original error: </span><span class="si">{</span><span class="n">error_msg</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
                <span class="k">elif</span> <span class="s2">&quot;Config name is missing&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;config&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; requires a config/subset name. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Add &#39;subset&#39; or &#39;config&#39; parameter to your DatasetConfig. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="n">error_msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Dataset &#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">&#39; requires a config/subset name. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Please add &#39;subset&#39; or &#39;config&#39; to your DatasetConfig. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Original error: </span><span class="si">{</span><span class="n">error_msg</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Apply subset selection</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
            <span class="n">original_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">ds_cfg</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied max_samples limit: </span><span class="si">{</span><span class="n">original_len</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">percent</span><span class="p">:</span>
            <span class="n">original_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">percent</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_samples</span><span class="p">))</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied percent limit (</span><span class="si">{</span><span class="n">ds_cfg</span><span class="o">.</span><span class="n">percent</span><span class="si">}</span><span class="s2">%): </span><span class="si">{</span><span class="n">original_len</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Auto-detect schema if enabled</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;auto_detect_fields&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">auto_detect_fields</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-detecting dataset schema...&quot;</span><span class="p">)</span>
            <span class="n">detected_format</span> <span class="o">=</span> <span class="n">schema_detector</span><span class="o">.</span><span class="n">detect_format</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">detected_format</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Auto-detected dataset format: </span><span class="si">{</span><span class="n">detected_format</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;format_type&#39;</span><span class="p">):</span>
                    <span class="n">ds_cfg</span><span class="o">.</span><span class="n">format_type</span> <span class="o">=</span> <span class="n">detected_format</span>

        <span class="c1"># Apply field mappings</span>
        <span class="n">field_mappings</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;field_mappings&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">field_mappings</span><span class="p">:</span>
            <span class="n">field_mappings</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">field_mappings</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applying field mappings: </span><span class="si">{</span><span class="n">field_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ds_cfg</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">:</span>
            <span class="n">field_mappings</span> <span class="o">=</span> <span class="n">ds_cfg</span><span class="o">.</span><span class="n">column_mapping</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applying column mappings: </span><span class="si">{</span><span class="n">field_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">field_mappings</span><span class="p">:</span>
            <span class="c1"># Only rename columns that exist in the dataset</span>
            <span class="n">valid_mappings</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">field_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">valid_mappings</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">valid_mappings</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns: </span><span class="si">{</span><span class="n">valid_mappings</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No valid column mappings found. Available columns: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Log dataset structure</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample data (first item): </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Task-specific formatting</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_dataset_for_task</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">ds_cfg</span><span class="p">)</span>

        <span class="c1"># Split train/test</span>
        <span class="c1"># Always create eval split if dataset has at least 2 samples (minimum for split)</span>
        <span class="c1"># For very small datasets, use a smaller test_size to ensure eval set has at least 1 sample</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># 10% for larger datasets</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># 20% for medium datasets (ensures at least 1 eval sample)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># 20% for very small datasets (2-4 samples -&gt; at least 1 eval)</span>

            <span class="n">split_ds</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">split_ds</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Split dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> eval&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Only skip split if dataset has less than 2 samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset too small for split (only </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples), using all for training. No eval dataset created.&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset prepared: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> training samples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup Unsloth-optimized model with task-aware configuration.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model with task-aware configuration.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up Unsloth model for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Configure Unsloth model parameters</span>
        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;Unsloth SFT&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_torch_dtype</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

        <span class="c1"># Configure Unsloth model parameters</span>
        <span class="c1"># Unsloth only accepts load_in_4bit as boolean, not BitsAndBytesConfig parameters</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">,</span>  <span class="c1"># Use dtype from PrecisionHandler instead of None</span>
            <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Unsloth handles quantization internally - don&#39;t pass BitsAndBytesConfig parameters</span>
        <span class="c1"># Parameters like bnb_4bit_compute_dtype, bnb_4bit_quant_type, etc. are not supported</span>

        <span class="c1"># Load model with Unsloth optimizations</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">SyntaxError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># Handle Unsloth compiled module syntax errors (may be wrapped in RuntimeError)</span>
            <span class="n">error_msg</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;unsloth_compiled_module&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;unexpected indent&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth compilation error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;This is a known Unsloth issue with compiled modules.&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Suggested fixes:&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  1. Clear Unsloth cache: rm -rf ~/.cache/unsloth/&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  2. Retry training after clearing cache&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  3. Use TRL backend instead: backend=&#39;trl&#39;&quot;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Unsloth compiled module syntax error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This is a known Unsloth library issue. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Please clear the Unsloth cache and retry, or use TRL backend instead.&quot;</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Re-raise if it&#39;s a different error</span>
                <span class="k">raise</span>

        <span class="c1"># Detect model architecture for appropriate target modules</span>
        <span class="n">model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_target_modules_for_architecture</span><span class="p">(</span><span class="n">model_type</span><span class="p">)</span>

        <span class="c1"># Validate target modules exist in the model</span>
        <span class="n">available_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()]</span>
        <span class="n">valid_target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">tm</span> <span class="k">for</span> <span class="n">tm</span> <span class="ow">in</span> <span class="n">target_modules</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">tm</span> <span class="ow">in</span> <span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">available_modules</span><span class="p">)]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_target_modules</span><span class="p">:</span>
            <span class="c1"># Try to auto-detect target modules</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;None of the target modules </span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2"> found in model. Attempting auto-detection...&quot;</span><span class="p">)</span>
            <span class="n">valid_target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_auto_detect_target_modules</span><span class="p">(</span><span class="n">available_modules</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_target_modules</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Target modules </span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2"> not found in the base model (type: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">). &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Available modules include: </span><span class="si">{</span><span class="n">available_modules</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">... &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Please check the target modules and try again, or use a different model architecture.&quot;</span>
            <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using target modules for </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">valid_target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Configure model for training with LoRA</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
            <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># LoRA rank</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="n">valid_target_modules</span><span class="p">,</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="s2">&quot;unsloth&quot;</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
            <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">loftq_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Setup tokenizer based on task type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_tokenizer_for_task</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth model setup completed successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup Unsloth model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup TRL SFTTrainer with task-aware configuration.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup TRL SFTTrainer with task-aware configuration.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span><span class="p">,</span> <span class="n">SFTConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up TRL SFTTrainer for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Get training parameters</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> \
                    <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">3</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> \
                    <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2</span>
        <span class="n">grad_accum</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-4</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">2e-4</span>
        <span class="n">save_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">500</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output&#39;</span>
        <span class="c1"># === UNIFIED PRECISION HANDLING ===</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>

            <span class="c1"># Create SFT configuration</span>

        <span class="c1"># Create SFT configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_config</span> <span class="o">=</span> <span class="n">SFTConfig</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">grad_accum</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>  
            <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;tensorboard&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Get max_seq_length</span>
        <span class="n">max_seq_len</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2048</span>

        <span class="c1"># Task-specific trainer settings</span>
        <span class="n">packing</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Generally disable packing for better quality</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_GENERATION</span><span class="p">:</span>
            <span class="n">packing</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Can enable packing for simple text generation</span>

        <span class="c1"># Create trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_config</span><span class="p">,</span>
            <span class="n">dataset_text_field</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span>
            <span class="n">dataset_num_proc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">packing</span><span class="o">=</span><span class="n">packing</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TRL SFTTrainer setup completed for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training config: </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2"> epochs, batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute training with Unsloth optimizations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span>
<span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span>
<span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute training with Unsloth optimizations.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting Unsloth SFT training for task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Setup components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Suppress Unsloth&#39;s informational warning about num_items_in_batch</span>
        <span class="c1"># This is a known limitation with Qwen2 models and gradient accumulation</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*num_items_in_batch.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*Qwen2ForCausalLM does not accept.*&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
            <span class="c1"># Start training</span>
            <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Save model</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="c1"># Compile results</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;task_type&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">global_step</span><span class="p">,</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth SFT training completed in </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">, Final loss: </span><span class="si">{</span><span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.sft.sft.UnslothSFTTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.unsloth.sft.sft.UnslothSFTTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute a single training step (required by abstract base class).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/sft/sft.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute a single training step (required by abstract base class).&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Trainer not initialized. Call setup_model() first.&quot;</span><span class="p">)</span>

    <span class="c1"># The actual training step is handled by TRL&#39;s SFTTrainer</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Example</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.backends.unsloth.sft.sft</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnslothSFTTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTConfig</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">SFTConfig</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">UnslothSFTTrainer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<h4 id="unslothdpotrainer"><code>UnslothDPOTrainer</code><a class="headerlink" href="#unslothdpotrainer" title="Permanent link">&para;</a></h4>
<p>Unsloth backend for Direct Preference Optimization.</p>


<div class="doc doc-object doc-class">



<a id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.rl.trainer_base.TrainerBase">TrainerBase</span></code></p>



        <p>Unsloth-optimized DPO trainer using TRL's DPOTrainer.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">UnslothDPOTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unsloth-optimized DPO trainer using TRL&#39;s DPOTrainer.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize Unsloth DPO trainer.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if Unsloth DPO trainer is available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="c1"># Required abstract methods implementation</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_obj</span><span class="p">,</span> <span class="o">*</span><span class="n">attr_names</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely get config value from multiple possible attribute names.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">config_obj</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">config_obj</span><span class="p">[</span><span class="n">attr_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">default</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup data - delegates to setup_dataset.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup rewards - not used in DPO.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Single training step - handled by TRL internally.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Use train() method instead&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model and tokenizer for DPO.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Setting up Unsloth DPO model: </span><span class="si">{</span>
<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s1">&#39;auto&#39;</span>

            <span class="c1"># Configure Unsloth model parameters</span>
            <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Auto-detect</span>
                <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
                <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span>
            <span class="p">}</span>

            <span class="c1"># Add quantization parameters if specified</span>
            <span class="c1"># FIXED: Only add parameters that are valid for</span>
            <span class="c1"># FastLanguageModel.from_pretrained</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="p">:</span>
                <span class="c1"># These are the parameters that Unsloth&#39;s FastLanguageModel</span>
                <span class="c1"># accepts</span>
                <span class="n">valid_quant_params</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;use_gradient_checkpointing&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;rope_scaling&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;fix_tokenizer&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;use_cache&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;token&#39;</span>
                <span class="p">}</span>

                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">valid_quant_params</span> <span class="ow">and</span> <span class="n">key</span> <span class="o">!=</span> <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span>
                        <span class="n">model_kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                    <span class="c1"># Silently skip unsupported parameters like bnb_4bit_compute_dtype</span>
                    <span class="c1"># These are handled internally by Unsloth</span>

            <span class="c1"># Load model with Unsloth optimizations</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>

            <span class="c1"># Configure model for DPO training</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># LoRA rank</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="s2">&quot;unsloth&quot;</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
                <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">loftq_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Create reference model for DPO</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth DPO model setup completed successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup Unsloth DPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup and prepare preference dataset for DPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up DPO dataset with DataManager...&quot;</span><span class="p">)</span>

            <span class="c1"># Extract dataset configuration</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># Extract parameters</span>
            <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">)</span>
            <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Advanced DataManager features</span>
            <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">max_eval_samples</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_eval_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Loading DPO dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Initialize DataManager for DPO task</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>
            <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;dpo&quot;</span><span class="p">,</span>
                <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
                <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
                <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
                <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
                <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
                <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span> 
            <span class="p">)</span>

            <span class="c1"># Load dataset</span>
            <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
                <span class="n">dataset_name</span><span class="p">,</span>
                <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Extract train and validation splits</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span> 

            <span class="c1"># === ROBUST COLUMN DETECTION ===</span>
            <span class="c1"># Check what columns actually exist</span>
            <span class="n">available_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="n">available_columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Detect the column structure</span>
            <span class="n">has_prompt</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
            <span class="n">has_chosen</span> <span class="o">=</span> <span class="s2">&quot;chosen&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
            <span class="n">has_rejected</span> <span class="o">=</span> <span class="s2">&quot;rejected&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>

            <span class="c1"># Log first sample to understand the structure</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span>
                            <span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Define a robust filtering function that handles different column</span>
            <span class="c1"># structures</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">filter_valid_examples</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Filter out invalid examples with flexible column detection.&quot;&quot;&quot;</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># If we have the standard DPO format</span>
                    <span class="k">if</span> <span class="n">has_prompt</span> <span class="ow">and</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="p">)</span>

                    <span class="c1"># Alternative: dataset might have &#39;chosen&#39; and &#39;rejected&#39; only</span>
                    <span class="c1"># (TRL can handle this format too)</span>
                    <span class="k">elif</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_prompt</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="p">)</span>

                    <span class="c1"># If columns don&#39;t match expected format, log and skip</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Unexpected dataset format. Available columns: </span><span class="si">{</span><span class="n">available_columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">return</span> <span class="kc">False</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error filtering example: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>

            <span class="c1"># Filter empty examples</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">initial_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">filter_valid_examples</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid examples&quot;</span>
                <span class="p">)</span>
                <span class="n">filtered_count</span> <span class="o">=</span> <span class="n">initial_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">filtered_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Filtered out </span><span class="si">{</span><span class="n">filtered_count</span><span class="si">}</span><span class="s2"> invalid examples&quot;</span><span class="p">)</span>

            <span class="c1"># Filter by approximate token count</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">is_valid_length</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Check if example fits within max sequence length.&quot;&quot;&quot;</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Rough approximation: 1 token  4 characters</span>

                    <span class="c1"># Handle different column structures</span>
                    <span class="k">if</span> <span class="n">has_prompt</span><span class="p">:</span>
                        <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># If no prompt, we&#39;ll check chosen/rejected only</span>
                        <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="mi">0</span>

                    <span class="n">chosen_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                    <span class="n">rejected_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>

                    <span class="c1"># Each response is concatenated with prompt, so check both</span>
                    <span class="k">return</span> <span class="p">(</span>
                        <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">chosen_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span> <span class="ow">and</span>
                        <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">rejected_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error checking length: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>

            <span class="n">original_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">is_valid_length</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long sequences&quot;</span>
            <span class="p">)</span>
            <span class="n">filtered_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">original_size</span> <span class="o">-</span> <span class="n">filtered_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Filtered </span><span class="si">{</span>
<span class="w">                        </span><span class="n">original_size</span><span class="w"> </span><span class="o">-</span>
<span class="w">                        </span><span class="n">filtered_size</span><span class="si">}</span><span class="s2"> samples that were too long&quot;</span><span class="p">)</span>

            <span class="c1"># Apply same filtering to eval dataset if it exists</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">filter_valid_examples</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid eval examples&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">is_valid_length</span><span class="p">,</span>
                    <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long eval sequences&quot;</span>
                <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;DPO dataset prepared: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train samples&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

            <span class="c1"># Log final sample for debugging</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Final dataset structure:&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">preview</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> \
                            <span class="s2">&quot;...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="n">value</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup TRL DPOTrainer with Unsloth model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL DPOTrainer with Unsloth model&quot;</span><span class="p">)</span>

            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.precision_handler</span><span class="w"> </span><span class="kn">import</span> <span class="n">PrecisionHandler</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
            <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;GRPO (Unsloth)&quot;</span><span class="p">)</span>
            <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span>
                <span class="n">precision</span><span class="p">)</span>
            <span class="c1"># Get training parameters</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num_epochs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
            <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">max_steps</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

            <span class="c1"># Get output and logging parameters</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/unsloth_dpo&#39;</span><span class="p">)</span>
            <span class="n">run_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;unsloth_dpo&#39;</span><span class="p">)</span>

            <span class="c1"># Evaluation parameters</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
            <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>
            <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eval_loss&#39;</span><span class="p">)</span>
            <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Adjust eval strategy based on eval_dataset availability</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
                <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Logging parameters</span>
            <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
            <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Report to</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;report_to&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">loggers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loggers</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
            <span class="k">if</span> <span class="n">loggers</span> <span class="ow">and</span> <span class="n">report_to</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span><span class="p">:</span>
                <span class="n">report_to</span> <span class="o">=</span> <span class="n">loggers</span>

            <span class="c1"># Optimizer parameters</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
            <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>
            <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

            <span class="c1"># Additional training parameters</span>
            <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                <span class="s1">&#39;use_gradient_checkpointing&#39;</span><span class="p">,</span>
                <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">group_by_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;group_by_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">data_seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;data_seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">47</span><span class="p">)</span>

            <span class="c1"># DPO specific parameters</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">loss_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
            <span class="n">label_smoothing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;label_smoothing&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="n">truncation_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;truncation_mode&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;keep_end&#39;</span><span class="p">)</span>

            <span class="c1"># Sequence lengths</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">)</span>
            <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">max_seq_length</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
            <span class="c1"># Adjust save strategy to save on epoch</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">save_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span>

            <span class="c1"># Create DPO configuration</span>
            <span class="n">dpo_config</span> <span class="o">=</span> <span class="n">DPOConfig</span><span class="p">(</span>
                <span class="c1"># Output and logging</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
                <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
                <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
                <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span><span class="p">,</span>

                <span class="c1"># Evaluation</span>
                <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
                <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>
                <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
                <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
                <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>
                <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>

                <span class="c1"># Checkpointing</span>
                <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
                <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
                <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>

                <span class="c1"># Training parameters</span>
                <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
                <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
                <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">warmup_ratio</span><span class="p">,</span>
                <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
                <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>

                <span class="c1"># Optimizer and scheduler</span>
                <span class="n">optim</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="n">lr_scheduler_type</span><span class="p">,</span>

                <span class="c1"># DPO specific parameters</span>
                <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
                <span class="n">loss_type</span><span class="o">=</span><span class="n">loss_type</span><span class="p">,</span>
                <span class="n">label_smoothing</span><span class="o">=</span><span class="n">label_smoothing</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
                <span class="n">max_prompt_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
                <span class="n">truncation_mode</span><span class="o">=</span><span class="n">truncation_mode</span><span class="p">,</span>

                <span class="c1"># Seeds</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">data_seed</span><span class="o">=</span><span class="n">data_seed</span><span class="p">,</span>

                <span class="c1"># Performance</span>
                <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="n">gradient_checkpointing</span><span class="p">,</span>
                <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

                <span class="c1"># Precision</span>
                <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

                <span class="c1"># Other settings</span>
                <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
                <span class="n">backend_config</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;dpo&#39;</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">dpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

            <span class="c1"># Create trainer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">DPOTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span><span class="p">,</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPOTrainer setup completed&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup DPO trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run DPO training.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Unsloth DPO training&quot;</span><span class="p">)</span>

            <span class="c1"># Setup components</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

            <span class="c1"># Run training</span>
            <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Save model</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth DPO training completed successfully&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;train_runtime&quot;</span><span class="p">,</span>
                    <span class="mi">0</span><span class="p">),</span>
                <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;train_loss&quot;</span><span class="p">,</span>
                    <span class="mi">0</span><span class="p">),</span>
                <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">model_path</span><span class="p">,</span>
                <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;train_steps&quot;</span><span class="p">,</span>
                    <span class="mi">0</span><span class="p">)}</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DPO training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="c1"># def evaluate(self) -&gt; Dict[str, Any]:</span>
    <span class="c1">#     &quot;&quot;&quot;Evaluate the trained model.&quot;&quot;&quot;</span>
    <span class="c1">#     try:</span>
    <span class="c1">#         if not self.trainer or not self.eval_dataset:</span>
    <span class="c1">#             logger.warning(&quot;No trainer or evaluation dataset available&quot;)</span>
    <span class="c1">#             return {}</span>

    <span class="c1">#         logger.info(&quot;Running DPO evaluation&quot;)</span>

    <span class="c1">#         # Run evaluation</span>
    <span class="c1">#         eval_result = self.trainer.evaluate()</span>

    <span class="c1">#         logger.info(&quot;DPO evaluation completed&quot;)</span>

    <span class="c1">#         return {</span>
    <span class="c1">#             &quot;eval_loss&quot;: eval_result.get(&quot;eval_loss&quot;, 0),</span>
    <span class="c1">#             &quot;eval_metrics&quot;: eval_result</span>
    <span class="c1">#         }</span>

    <span class="c1">#     except Exception as e:</span>
    <span class="c1">#         logger.error(f&quot;DPO evaluation failed: {e}&quot;)</span>
    <span class="c1">#         return {}</span>
    <span class="c1"># def evaluate(</span>
    <span class="c1">#     self,</span>
    <span class="c1">#     eval_dataset=None,</span>
    <span class="c1">#     metric_key_prefix: str = &quot;eval&quot;,</span>
    <span class="c1">#     use_custom_evaluator: bool = True,</span>
    <span class="c1">#     **kwargs</span>
    <span class="c1"># ) -&gt; Dict[str, float]:</span>
    <span class="c1">#     &quot;&quot;&quot;GRPO-specific evaluation - auto-setup evaluators and delegate to parent.&quot;&quot;&quot;</span>

    <span class="c1">#     # Auto-setup evaluators on first call</span>
    <span class="c1">#     if self.base_evaluator is None and self.rl_evaluator is None:</span>
    <span class="c1">#         logger.info(&quot;Auto-initializing evaluators for first evaluation...&quot;)</span>
    <span class="c1">#         self.setup_custom_evaluator(evaluator_type=&quot;auto&quot;)</span>

    <span class="c1">#     # Call parent&#39;s unified evaluate method</span>
    <span class="c1">#     return super().evaluate(</span>
    <span class="c1">#         eval_dataset=eval_dataset,</span>
    <span class="c1">#         metric_key_prefix=metric_key_prefix,</span>
    <span class="c1">#         use_custom_evaluator=use_custom_evaluator,</span>
    <span class="c1">#         **kwargs</span>
    <span class="c1">#     )</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_preference_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate sample preference data for testing.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No tokenizer available for generation&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">[]</span>

            <span class="c1"># Sample prompts</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s2">&quot;Explain the concept of machine learning&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Write a short story about a robot&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Describe the benefits of renewable energy&quot;</span><span class="p">,</span>
                <span class="s2">&quot;What are the key principles of good software design?&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Explain quantum computing in simple terms&quot;</span>
            <span class="p">]</span>

            <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">prompts</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]):</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s2">&quot;chosen&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Sample chosen response </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;rejected&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Sample rejected response </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">})</span>

            <span class="k">return</span> <span class="n">samples</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate preference samples: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/dpo&#39;</span><span class="p">)</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saved successfully&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">save_path</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Save failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Load model and tokenizer</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize Unsloth DPO trainer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize Unsloth DPO trainer.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.generate_preference_samples" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_preference_samples</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.generate_preference_samples" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generate sample preference data for testing.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">generate_preference_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate sample preference data for testing.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No tokenizer available for generation&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Sample prompts</span>
        <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;Explain the concept of machine learning&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Write a short story about a robot&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Describe the benefits of renewable energy&quot;</span><span class="p">,</span>
            <span class="s2">&quot;What are the key principles of good software design?&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Explain quantum computing in simple terms&quot;</span>
        <span class="p">]</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">prompts</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]):</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                <span class="s2">&quot;chosen&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Sample chosen response </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="s2">&quot;rejected&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Sample rejected response </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">})</span>

        <span class="k">return</span> <span class="n">samples</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate preference samples: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if Unsloth DPO trainer is available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if Unsloth DPO trainer is available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a trained model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a trained model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/dpo&#39;</span><span class="p">)</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saved successfully&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">save_path</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Save failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup data - delegates to setup_dataset.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup data - delegates to setup_dataset.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_dataset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_dataset</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_dataset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup and prepare preference dataset for DPO training using unified DataManager.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup and prepare preference dataset for DPO training using unified DataManager.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up DPO dataset with DataManager...&quot;</span><span class="p">)</span>

        <span class="c1"># Extract dataset configuration</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Extract parameters</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Advanced DataManager features</span>
        <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">max_eval_samples</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_eval_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Loading DPO dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize DataManager for DPO task</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>
        <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;dpo&quot;</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
            <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
            <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
            <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
            <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span> 
        <span class="p">)</span>

        <span class="c1"># Load dataset</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Extract train and validation splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span> 

        <span class="c1"># === ROBUST COLUMN DETECTION ===</span>
        <span class="c1"># Check what columns actually exist</span>
        <span class="n">available_columns</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="n">available_columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Detect the column structure</span>
        <span class="n">has_prompt</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
        <span class="n">has_chosen</span> <span class="o">=</span> <span class="s2">&quot;chosen&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>
        <span class="n">has_rejected</span> <span class="o">=</span> <span class="s2">&quot;rejected&quot;</span> <span class="ow">in</span> <span class="n">available_columns</span>

        <span class="c1"># Log first sample to understand the structure</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Define a robust filtering function that handles different column</span>
        <span class="c1"># structures</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">filter_valid_examples</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Filter out invalid examples with flexible column detection.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># If we have the standard DPO format</span>
                <span class="k">if</span> <span class="n">has_prompt</span> <span class="ow">and</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
                    <span class="p">)</span>

                <span class="c1"># Alternative: dataset might have &#39;chosen&#39; and &#39;rejected&#39; only</span>
                <span class="c1"># (TRL can handle this format too)</span>
                <span class="k">elif</span> <span class="n">has_chosen</span> <span class="ow">and</span> <span class="n">has_rejected</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_prompt</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
                    <span class="p">)</span>

                <span class="c1"># If columns don&#39;t match expected format, log and skip</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Unexpected dataset format. Available columns: </span><span class="si">{</span><span class="n">available_columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error filtering example: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Filter empty examples</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">initial_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">filter_valid_examples</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid examples&quot;</span>
            <span class="p">)</span>
            <span class="n">filtered_count</span> <span class="o">=</span> <span class="n">initial_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">filtered_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Filtered out </span><span class="si">{</span><span class="n">filtered_count</span><span class="si">}</span><span class="s2"> invalid examples&quot;</span><span class="p">)</span>

        <span class="c1"># Filter by approximate token count</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">is_valid_length</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Check if example fits within max sequence length.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Rough approximation: 1 token  4 characters</span>

                <span class="c1"># Handle different column structures</span>
                <span class="k">if</span> <span class="n">has_prompt</span><span class="p">:</span>
                    <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If no prompt, we&#39;ll check chosen/rejected only</span>
                    <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">chosen_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;chosen&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>
                <span class="n">rejected_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rejected&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">//</span> <span class="mi">4</span>

                <span class="c1"># Each response is concatenated with prompt, so check both</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">chosen_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span> <span class="ow">and</span>
                    <span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">rejected_tokens</span> <span class="o">&lt;</span> <span class="n">max_length</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error checking length: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="n">original_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
            <span class="n">is_valid_length</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long sequences&quot;</span>
        <span class="p">)</span>
        <span class="n">filtered_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">original_size</span> <span class="o">-</span> <span class="n">filtered_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Filtered </span><span class="si">{</span>
<span class="w">                    </span><span class="n">original_size</span><span class="w"> </span><span class="o">-</span>
<span class="w">                    </span><span class="n">filtered_size</span><span class="si">}</span><span class="s2"> samples that were too long&quot;</span><span class="p">)</span>

        <span class="c1"># Apply same filtering to eval dataset if it exists</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">filter_valid_examples</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering invalid eval examples&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="n">is_valid_length</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering long eval sequences&quot;</span>
            <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;DPO dataset prepared: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train samples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Log final sample for debugging</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Final dataset structure:&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">preview</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span> <span class="o">+</span> \
                        <span class="s2">&quot;...&quot;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">100</span> <span class="k">else</span> <span class="n">value</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">preview</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup dataset: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup Unsloth-optimized model and tokenizer for DPO.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model and tokenizer for DPO.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Setting up Unsloth DPO model: </span><span class="si">{</span>
<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s1">&#39;auto&#39;</span>

        <span class="c1"># Configure Unsloth model parameters</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Auto-detect</span>
            <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span>
        <span class="p">}</span>

        <span class="c1"># Add quantization parameters if specified</span>
        <span class="c1"># FIXED: Only add parameters that are valid for</span>
        <span class="c1"># FastLanguageModel.from_pretrained</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="p">:</span>
            <span class="c1"># These are the parameters that Unsloth&#39;s FastLanguageModel</span>
            <span class="c1"># accepts</span>
            <span class="n">valid_quant_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;load_in_4bit&#39;</span><span class="p">,</span>
                <span class="s1">&#39;use_gradient_checkpointing&#39;</span><span class="p">,</span>
                <span class="s1">&#39;rope_scaling&#39;</span><span class="p">,</span>
                <span class="s1">&#39;fix_tokenizer&#39;</span><span class="p">,</span>
                <span class="s1">&#39;trust_remote_code&#39;</span><span class="p">,</span>
                <span class="s1">&#39;use_cache&#39;</span><span class="p">,</span>
                <span class="s1">&#39;token&#39;</span>
            <span class="p">}</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">valid_quant_params</span> <span class="ow">and</span> <span class="n">key</span> <span class="o">!=</span> <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span>
                    <span class="n">model_kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="c1"># Silently skip unsupported parameters like bnb_4bit_compute_dtype</span>
                <span class="c1"># These are handled internally by Unsloth</span>

        <span class="c1"># Load model with Unsloth optimizations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>

        <span class="c1"># Configure model for DPO training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># LoRA rank</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="s2">&quot;unsloth&quot;</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
            <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">loftq_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Create reference model for DPO</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth DPO model setup completed successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup Unsloth DPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup rewards - not used in DPO.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup rewards - not used in DPO.&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup TRL DPOTrainer with Unsloth model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup TRL DPOTrainer with Unsloth model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span><span class="p">,</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">ModelConfig</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL DPOTrainer with Unsloth model&quot;</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.precision_handler</span><span class="w"> </span><span class="kn">import</span> <span class="n">PrecisionHandler</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;GRPO (Unsloth)&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span>
            <span class="n">precision</span><span class="p">)</span>
        <span class="c1"># Get training parameters</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_epochs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="c1"># Get output and logging parameters</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./output/unsloth_dpo&#39;</span><span class="p">)</span>
        <span class="n">run_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;unsloth_dpo&#39;</span><span class="p">)</span>

        <span class="c1"># Evaluation parameters</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>
        <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;eval_loss&#39;</span><span class="p">)</span>
        <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Adjust eval strategy based on eval_dataset availability</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Logging parameters</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">save_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Report to</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;report_to&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">loggers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loggers</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="n">loggers</span> <span class="ow">and</span> <span class="n">report_to</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span><span class="p">:</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="n">loggers</span>

        <span class="c1"># Optimizer parameters</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
        <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>
        <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># Additional training parameters</span>
        <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;use_gradient_checkpointing&#39;</span><span class="p">,</span>
            <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">group_by_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;group_by_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">data_seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;data_seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">47</span><span class="p">)</span>

        <span class="c1"># DPO specific parameters</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">loss_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
        <span class="n">label_smoothing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;label_smoothing&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">truncation_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;truncation_mode&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;keep_end&#39;</span><span class="p">)</span>

        <span class="c1"># Sequence lengths</span>
        <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">)</span>
        <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">max_seq_length</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># Adjust save strategy to save on epoch</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">save_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span>

        <span class="c1"># Create DPO configuration</span>
        <span class="n">dpo_config</span> <span class="o">=</span> <span class="n">DPOConfig</span><span class="p">(</span>
            <span class="c1"># Output and logging</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
            <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span><span class="p">,</span>

            <span class="c1"># Evaluation</span>
            <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
            <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
            <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>
            <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>

            <span class="c1"># Checkpointing</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
            <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>

            <span class="c1"># Training parameters</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">warmup_ratio</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>

            <span class="c1"># Optimizer and scheduler</span>
            <span class="n">optim</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="n">lr_scheduler_type</span><span class="p">,</span>

            <span class="c1"># DPO specific parameters</span>
            <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
            <span class="n">loss_type</span><span class="o">=</span><span class="n">loss_type</span><span class="p">,</span>
            <span class="n">label_smoothing</span><span class="o">=</span><span class="n">label_smoothing</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">max_prompt_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">truncation_mode</span><span class="o">=</span><span class="n">truncation_mode</span><span class="p">,</span>

            <span class="c1"># Seeds</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">data_seed</span><span class="o">=</span><span class="n">data_seed</span><span class="p">,</span>

            <span class="c1"># Performance</span>
            <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="n">gradient_checkpointing</span><span class="p">,</span>
            <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

            <span class="c1"># Precision</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

            <span class="c1"># Other settings</span>
            <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
            <span class="n">backend_config</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;dpo&#39;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">dpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># Create trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">DPOTrainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_model</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">dpo_config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL DPOTrainer setup completed&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup DPO trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run DPO training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run DPO training.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Unsloth DPO training&quot;</span><span class="p">)</span>

        <span class="c1"># Setup components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Run training</span>
        <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Save model</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth DPO training completed successfully&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;train_runtime&quot;</span><span class="p">,</span>
                <span class="mi">0</span><span class="p">),</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;train_loss&quot;</span><span class="p">,</span>
                <span class="mi">0</span><span class="p">),</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">model_path</span><span class="p">,</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;train_steps&quot;</span><span class="p">,</span>
                <span class="mi">0</span><span class="p">)}</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DPO training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.dpo.dpo.UnslothDPOTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Single training step - handled by TRL internally.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/dpo/dpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single training step - handled by TRL internally.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Use train() method instead&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<h4 id="unslothppotrainer"><code>UnslothPPOTrainer</code><a class="headerlink" href="#unslothppotrainer" title="Permanent link">&para;</a></h4>
<p>Unsloth backend for Proximal Policy Optimization.</p>


<div class="doc doc-object doc-class">



<a id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.rl.trainer_base.TrainerBase">TrainerBase</span></code></p>



        <p>PPO trainer with hybrid Unsloth architecture.</p>
<p>Model Architecture:
- Policy Model: Unsloth FastLanguageModel + LoRA (trained, optimized)
- Reference Model: Unsloth FastLanguageModel (frozen, memory efficient)
- Reward Model: Standard HuggingFace (frozen, any architecture)
- Value Model: Standard HuggingFace (trained alongside policy)</p>
<p>Key Insight: Unsloth models need manual patches for apply_qkv method.
Standard models work naturally with TRL without patches.</p>
<p>Reward Model Options:
1. Pretrained: Load from HuggingFace (DeBERTa, RoBERTa, etc.)
2. Custom trained: Train using TRL's RewardTrainer
3. Hybrid: Fine-tune pretrained with custom reward functions</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span>
<span class="normal">2075</span>
<span class="normal">2076</span>
<span class="normal">2077</span>
<span class="normal">2078</span>
<span class="normal">2079</span>
<span class="normal">2080</span>
<span class="normal">2081</span>
<span class="normal">2082</span>
<span class="normal">2083</span>
<span class="normal">2084</span>
<span class="normal">2085</span>
<span class="normal">2086</span>
<span class="normal">2087</span>
<span class="normal">2088</span>
<span class="normal">2089</span>
<span class="normal">2090</span>
<span class="normal">2091</span>
<span class="normal">2092</span>
<span class="normal">2093</span>
<span class="normal">2094</span>
<span class="normal">2095</span>
<span class="normal">2096</span>
<span class="normal">2097</span>
<span class="normal">2098</span>
<span class="normal">2099</span>
<span class="normal">2100</span>
<span class="normal">2101</span>
<span class="normal">2102</span>
<span class="normal">2103</span>
<span class="normal">2104</span>
<span class="normal">2105</span>
<span class="normal">2106</span>
<span class="normal">2107</span>
<span class="normal">2108</span>
<span class="normal">2109</span>
<span class="normal">2110</span>
<span class="normal">2111</span>
<span class="normal">2112</span>
<span class="normal">2113</span>
<span class="normal">2114</span>
<span class="normal">2115</span>
<span class="normal">2116</span>
<span class="normal">2117</span>
<span class="normal">2118</span>
<span class="normal">2119</span>
<span class="normal">2120</span>
<span class="normal">2121</span>
<span class="normal">2122</span>
<span class="normal">2123</span>
<span class="normal">2124</span>
<span class="normal">2125</span>
<span class="normal">2126</span>
<span class="normal">2127</span>
<span class="normal">2128</span>
<span class="normal">2129</span>
<span class="normal">2130</span>
<span class="normal">2131</span>
<span class="normal">2132</span>
<span class="normal">2133</span>
<span class="normal">2134</span>
<span class="normal">2135</span>
<span class="normal">2136</span>
<span class="normal">2137</span>
<span class="normal">2138</span>
<span class="normal">2139</span>
<span class="normal">2140</span>
<span class="normal">2141</span>
<span class="normal">2142</span>
<span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span>
<span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span>
<span class="normal">2213</span>
<span class="normal">2214</span>
<span class="normal">2215</span>
<span class="normal">2216</span>
<span class="normal">2217</span>
<span class="normal">2218</span>
<span class="normal">2219</span>
<span class="normal">2220</span>
<span class="normal">2221</span>
<span class="normal">2222</span>
<span class="normal">2223</span>
<span class="normal">2224</span>
<span class="normal">2225</span>
<span class="normal">2226</span>
<span class="normal">2227</span>
<span class="normal">2228</span>
<span class="normal">2229</span>
<span class="normal">2230</span>
<span class="normal">2231</span>
<span class="normal">2232</span>
<span class="normal">2233</span>
<span class="normal">2234</span>
<span class="normal">2235</span>
<span class="normal">2236</span>
<span class="normal">2237</span>
<span class="normal">2238</span>
<span class="normal">2239</span>
<span class="normal">2240</span>
<span class="normal">2241</span>
<span class="normal">2242</span>
<span class="normal">2243</span>
<span class="normal">2244</span>
<span class="normal">2245</span>
<span class="normal">2246</span>
<span class="normal">2247</span>
<span class="normal">2248</span>
<span class="normal">2249</span>
<span class="normal">2250</span>
<span class="normal">2251</span>
<span class="normal">2252</span>
<span class="normal">2253</span>
<span class="normal">2254</span>
<span class="normal">2255</span>
<span class="normal">2256</span>
<span class="normal">2257</span>
<span class="normal">2258</span>
<span class="normal">2259</span>
<span class="normal">2260</span>
<span class="normal">2261</span>
<span class="normal">2262</span>
<span class="normal">2263</span>
<span class="normal">2264</span>
<span class="normal">2265</span>
<span class="normal">2266</span>
<span class="normal">2267</span>
<span class="normal">2268</span>
<span class="normal">2269</span>
<span class="normal">2270</span>
<span class="normal">2271</span>
<span class="normal">2272</span>
<span class="normal">2273</span>
<span class="normal">2274</span>
<span class="normal">2275</span>
<span class="normal">2276</span>
<span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span>
<span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span>
<span class="normal">2323</span>
<span class="normal">2324</span>
<span class="normal">2325</span>
<span class="normal">2326</span>
<span class="normal">2327</span>
<span class="normal">2328</span>
<span class="normal">2329</span>
<span class="normal">2330</span>
<span class="normal">2331</span>
<span class="normal">2332</span>
<span class="normal">2333</span>
<span class="normal">2334</span>
<span class="normal">2335</span>
<span class="normal">2336</span>
<span class="normal">2337</span>
<span class="normal">2338</span>
<span class="normal">2339</span>
<span class="normal">2340</span>
<span class="normal">2341</span>
<span class="normal">2342</span>
<span class="normal">2343</span>
<span class="normal">2344</span>
<span class="normal">2345</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">UnslothPPOTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;PPO trainer with hybrid Unsloth architecture.</span>

<span class="sd">    Model Architecture:</span>
<span class="sd">    - Policy Model: Unsloth FastLanguageModel + LoRA (trained, optimized)</span>
<span class="sd">    - Reference Model: Unsloth FastLanguageModel (frozen, memory efficient)</span>
<span class="sd">    - Reward Model: Standard HuggingFace (frozen, any architecture)</span>
<span class="sd">    - Value Model: Standard HuggingFace (trained alongside policy)</span>

<span class="sd">    Key Insight: Unsloth models need manual patches for apply_qkv method.</span>
<span class="sd">    Standard models work naturally with TRL without patches.</span>

<span class="sd">    Reward Model Options:</span>
<span class="sd">    1. Pretrained: Load from HuggingFace (DeBERTa, RoBERTa, etc.)</span>
<span class="sd">    2. Custom trained: Train using TRL&#39;s RewardTrainer</span>
<span class="sd">    3. Hybrid: Fine-tune pretrained with custom reward functions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Validate Unsloth is properly loaded</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;UNSLOTH_IS_PRESENT&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Unsloth PPO backend requires Unsloth to be imported first. &quot;</span>
                <span class="s2">&quot;This should be handled by the factory, but validation failed. &quot;</span>
                <span class="s2">&quot;Please report this as a bug.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Rest of existing initialization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if Unsloth and TRL are available and properly configured.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Check Unsloth installation</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Check if Unsloth is properly configured</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;UNSLOTH_IS_PRESENT&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Unsloth not properly initialized&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="c1"># Check TRL availability</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth PPO backend not available: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth PPO backend configuration error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_obj</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper to get config value from dict or object.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">config_obj</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">default</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_detect_model_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Detect if model should use Unsloth or standard loading.</span>

<span class="sd">        Returns:</span>
<span class="sd">            &#39;unsloth&#39;: Use Unsloth FastLanguageModel</span>
<span class="sd">            &#39;standard&#39;: Use standard transformers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check config override first</span>
        <span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">force_type</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;reward_value_loading_type&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">force_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="s1">&#39;reward_value_loading_type&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">force_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;unsloth&#39;</span><span class="p">,</span> <span class="s1">&#39;standard&#39;</span><span class="p">]:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using config-specified loading type: </span><span class="si">{</span><span class="n">force_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">force_type</span>

        <span class="c1"># Models that CANNOT use Unsloth (encoder-only models)</span>
        <span class="n">incompatible_models</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bert&#39;</span><span class="p">,</span> <span class="s1">&#39;roberta&#39;</span><span class="p">,</span> <span class="s1">&#39;distilbert&#39;</span><span class="p">,</span> <span class="s1">&#39;albert&#39;</span><span class="p">,</span> <span class="s1">&#39;electra&#39;</span><span class="p">,</span> <span class="s1">&#39;deberta&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">indicator</span> <span class="ow">in</span> <span class="n">model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">indicator</span> <span class="ow">in</span> <span class="n">incompatible_models</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using standard loading for encoder model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="s1">&#39;standard&#39;</span>

        <span class="c1"># Default to Unsloth for decoder models (Llama, GPT, Mistral, etc.)</span>
        <span class="c1"># This ensures they get proper rotary embedding patches</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using Unsloth loading for decoder model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s1">&#39;unsloth&#39;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_reward_value_models_unsloth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">quantization</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load reward/value models using Unsloth for optimization.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward/value models with Unsloth: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Check for integrated reward training first</span>
        <span class="n">reward_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;reward_model_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Check if integrated reward training is enabled</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;reward_training&#39;</span><span class="p">)</span> <span class="ow">and</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span> <span class="ow">and</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span><span class="o">.</span><span class="n">enabled</span><span class="p">):</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Training custom reward model before PPO...&quot;</span><span class="p">)</span>
            <span class="n">reward_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_custom_reward_model</span><span class="p">()</span>
            <span class="c1"># Override reward_model_name with trained model path</span>
            <span class="n">reward_model_name</span> <span class="o">=</span> <span class="n">reward_model_path</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Custom reward model trained and saved to: </span><span class="si">{</span><span class="n">reward_model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Get quantization settings (configurable per model)</span>
        <span class="n">reward_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_quantization&#39;</span><span class="p">,</span> <span class="n">quantization</span><span class="p">)</span>
        <span class="n">value_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;value_model_quantization&#39;</span><span class="p">,</span> <span class="n">quantization</span><span class="p">)</span>

        <span class="c1"># Load reward model</span>
        <span class="k">if</span> <span class="n">reward_model_name</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading pre-trained reward model: </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

            <span class="c1"># Load pre-trained reward model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">reward_model_name</span><span class="p">,</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Wrap with UniversalRewardModelWrapper for compatibility</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">UniversalRewardModelWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>

            <span class="c1"># DEBUG: Check wrapper</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Wrapped reward model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Wrapped reward model has score: </span><span class="si">{</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;score&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Base model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Base model has classifier: </span><span class="si">{</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;classifier&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Verify score method exists for Unsloth PPO compatibility</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Reward model wrapper missing score method!&quot;</span><span class="p">)</span>
                <span class="n">base_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                    <span class="k">def</span><span class="w"> </span><span class="nf">score_method</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">):</span>
                        <span class="k">return</span> <span class="n">base_model</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">score_method</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added score method to Unsloth reward model wrapper&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Reward model must have score() or classifier() method&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth reward model wrapper has score method&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Loaded pre-trained reward model with UniversalRewardModelWrapper&quot;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Create reward model from scratch (NO quantization for TRL compatibility)</span>
            <span class="n">reward_base</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># CRITICAL: Disable quantization for TRL compatibility</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_base</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
                <span class="n">reward_base</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
            <span class="n">hidden_size</span> <span class="o">=</span> <span class="n">reward_base</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
            <span class="n">base_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">reward_base</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">reward_base</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">base_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">reward_base</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Verify score layer was added correctly</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Failed to add score layer to Unsloth reward model&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth reward model score layer: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load value model similarly (NO quantization to avoid .to() errors in PPOTrainer)</span>
        <span class="n">value_base</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># CRITICAL: Disable quantization for TRL compatibility</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value_base</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
            <span class="n">value_base</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">value_base</span>
        <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">value_base</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">value_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">value_base</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Disable gradient checkpointing</span>
        <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">]:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Reward/value models loaded with Unsloth optimizations&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_reward_value_models_standard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load reward/value models using standard transformers (no Unsloth patches).&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward/value models with standard transformers: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

        <span class="c1"># Get quantization settings (configurable per model)</span>
        <span class="n">reward_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">value_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;value_model_quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="c1"># Get precision from config</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">):</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span><span class="o">.</span><span class="n">value</span>
        <span class="n">torch_dtype</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span> <span class="k">if</span> <span class="n">precision</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;float16&#39;</span><span class="p">,</span> <span class="s1">&#39;bfloat16&#39;</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>

        <span class="c1"># Load reward model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
            <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">reward_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Wrap with UniversalRewardModelWrapper for compatibility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">UniversalRewardModelWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>

        <span class="c1"># Verify score method for standard transformers path</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
            <span class="n">base_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">score_method</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">base_model</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">score_method</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added score method to standard reward model wrapper&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Standard reward model wrapper has score method&quot;</span><span class="p">)</span>

        <span class="c1"># Load value model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
            <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Disable gradient checkpointing</span>
        <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">]:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Standard HuggingFace models don&#39;t need Unsloth patches</span>
        <span class="c1"># They work naturally with TRL&#39;s PPOTrainer</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Reward/value models loaded with standard transformers&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_value_model_unsloth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">quantization</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load only value model using Unsloth.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading value model with Unsloth: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">value_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;value_model_quantization&#39;</span><span class="p">,</span> <span class="n">quantization</span><span class="p">)</span>

        <span class="n">value_base</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value_base</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
            <span class="n">value_base</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
        <span class="n">hidden_size</span> <span class="o">=</span> <span class="n">value_base</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">value_base</span>
        <span class="n">base_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">value_base</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">base_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">value_base</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Value model loaded with Unsloth optimizations&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_value_model_standard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load only value model using standard transformers (NO Unsloth patches).&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading value model with standard transformers: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Warn if trying to load Unsloth model with standard transformers</span>
        <span class="k">if</span> <span class="s2">&quot;unsloth&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Loading Unsloth model &#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&#39; with standard transformers&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot; This may cause compatibility issues with Unsloth&#39;s PPOTrainer&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot; Consider using a standard HuggingFace model or set reward_value_loading_type=&#39;unsloth&#39;&quot;</span><span class="p">)</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

        <span class="n">value_quant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;value_model_quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="c1"># Get precision from config</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">):</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span><span class="o">.</span><span class="n">value</span>
        <span class="n">torch_dtype</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span> <span class="k">if</span> <span class="n">precision</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;float16&#39;</span><span class="p">,</span> <span class="s1">&#39;bfloat16&#39;</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
            <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">value_quant</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># DEBUG: Check value model dtype after loading</span>
        <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Value model loaded with dtype: </span><span class="si">{</span><span class="n">value_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Target dtype was: </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get value model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># DO NOT apply Unsloth patches to standard models</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Value model loaded with standard transformers (no Unsloth patches)&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_hash</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate hash of relevant configuration for cache invalidation.&quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

        <span class="c1"># Get config values</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">)</span>
        <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;max_seq_length&quot;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="n">quantization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;quantization&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">reward_value_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;reward_value_model&quot;</span><span class="p">,</span> <span class="s2">&quot;meta-llama/Llama-3.2-1B-Instruct&quot;</span><span class="p">)</span>

        <span class="c1"># Get library versions</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="n">unsloth_version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">unsloth</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">unsloth_version</span> <span class="o">=</span> <span class="s2">&quot;not_installed&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>
            <span class="n">transformers_version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">transformers</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">transformers_version</span> <span class="o">=</span> <span class="s2">&quot;not_installed&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
            <span class="n">torch_version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="s2">&quot;unknown&quot;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">torch_version</span> <span class="o">=</span> <span class="s2">&quot;not_installed&quot;</span>

        <span class="n">config_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
            <span class="s1">&#39;max_seq_length&#39;</span><span class="p">:</span> <span class="n">max_seq_length</span><span class="p">,</span>
            <span class="s1">&#39;quantization&#39;</span><span class="p">:</span> <span class="n">quantization</span><span class="p">,</span>
            <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">:</span> <span class="n">gradient_checkpointing</span><span class="p">,</span>
            <span class="s1">&#39;reward_value_model&#39;</span><span class="p">:</span> <span class="n">reward_value_model</span><span class="p">,</span>
            <span class="s1">&#39;unsloth_version&#39;</span><span class="p">:</span> <span class="n">unsloth_version</span><span class="p">,</span>
            <span class="s1">&#39;transformers_version&#39;</span><span class="p">:</span> <span class="n">transformers_version</span><span class="p">,</span>
            <span class="s1">&#39;torch_version&#39;</span><span class="p">:</span> <span class="n">torch_version</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">config_str</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">config_str</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_clear_unsloth_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear Unsloth compiled cache to force recompilation.</span>

<span class="sd">        Args:</span>
<span class="sd">            force: If True, always clear cache. If False, only clear if config changed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

        <span class="c1"># Clear local cache</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">cwd</span><span class="p">()</span> <span class="o">/</span> <span class="s2">&quot;unsloth_compiled_cache&quot;</span>
        <span class="k">if</span> <span class="n">cache_dir</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">force</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Force clearing Unsloth compiled cache...&quot;</span><span class="p">)</span>
                <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Cleared local cache: </span><span class="si">{</span><span class="n">cache_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cache exists at: </span><span class="si">{</span><span class="n">cache_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Clear global Unsloth cache if set</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
        <span class="k">if</span> <span class="s1">&#39;UNSLOTH_COMPILED_CACHE&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
            <span class="n">global_cache</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;UNSLOTH_COMPILED_CACHE&#39;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">global_cache</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">force</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Force clearing global Unsloth cache...&quot;</span><span class="p">)</span>
                    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">global_cache</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Cleared global cache: </span><span class="si">{</span><span class="n">global_cache</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Global cache exists at: </span><span class="si">{</span><span class="n">global_cache</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set environment variable to force recompilation</span>
        <span class="k">if</span> <span class="n">force</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;UNSLOTH_FORCE_RECOMPILE&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Set UNSLOTH_FORCE_RECOMPILE=1&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_invalidate_unsloth_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Invalidate Unsloth cache if configuration has changed.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>

        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">cwd</span><span class="p">()</span> <span class="o">/</span> <span class="s2">&quot;unsloth_compiled_cache&quot;</span>
        <span class="n">config_file</span> <span class="o">=</span> <span class="n">cache_dir</span> <span class="o">/</span> <span class="s2">&quot;.config_hash&quot;</span>

        <span class="n">current_hash</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_hash</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current config hash: </span><span class="si">{</span><span class="n">current_hash</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config_file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">stored_hash</span> <span class="o">=</span> <span class="n">config_file</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">stored_hash</span> <span class="o">!=</span> <span class="n">current_hash</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Config changed (</span><span class="si">{</span><span class="n">stored_hash</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span><span class="si">}</span><span class="s2">... -&gt; </span><span class="si">{</span><span class="n">current_hash</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span><span class="si">}</span><span class="s2">...), invalidating cache&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">cache_dir</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Cleared Unsloth cache: </span><span class="si">{</span><span class="n">cache_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Config unchanged (</span><span class="si">{</span><span class="n">current_hash</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span><span class="si">}</span><span class="s2">...), reusing cache&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No previous cache found, will create new cache&quot;</span><span class="p">)</span>

        <span class="c1"># Ensure cache dir exists and store new hash</span>
        <span class="n">cache_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">config_file</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">current_hash</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_model_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate that model types are compatible with loading strategy.&quot;&quot;&quot;</span>
        <span class="c1"># Check value model</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;reward_value_model&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">loading_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;reward_value_loading_type&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">loading_type</span> <span class="o">==</span> <span class="s2">&quot;standard&quot;</span> <span class="ow">and</span> <span class="s2">&quot;unsloth&quot;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Incompatible configuration: reward_value_model=&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&#39; &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;with reward_value_loading_type=&#39;standard&#39;. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Either use a standard HuggingFace model or set loading_type=&#39;unsloth&#39;&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Check reward model</span>
        <span class="n">reward_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;reward_model_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reward_model_name</span> <span class="ow">and</span> <span class="s2">&quot;unsloth&quot;</span> <span class="ow">in</span> <span class="n">reward_model_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Using Unsloth reward model &#39;</span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&#39; with standard loading&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot; This may cause compatibility issues. Consider using a standard HuggingFace reward model&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_disable_gradient_checkpointing_for_all</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Disable gradient checkpointing on all models - UNSLOTH-SAFE VERSION.&quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_safe_replace_gc_attr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;(unknown)&quot;</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Replace gradient checkpointing attributes safely.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># DON&#39;T replace _gradient_checkpointing_func - just disable the flag</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">):</span>
                    <span class="n">obj</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="c1"># For config objects</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
                    <span class="n">cfg</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">):</span>
                        <span class="n">cfg</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;use_cache&quot;</span><span class="p">):</span>
                        <span class="n">cfg</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indent</span><span class="si">}</span><span class="s2"> Disabled GC flags on </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indent</span><span class="si">}</span><span class="s2"> Could not disable GC on </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_recursive_disable</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">depth</span> <span class="o">&gt;</span> <span class="mi">6</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="n">indent</span> <span class="o">=</span> <span class="s2">&quot;  &quot;</span> <span class="o">*</span> <span class="n">depth</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indent</span><span class="si">}</span><span class="s2">Disabling GC on </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> (depth=</span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># 1. Use official API if available</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing_disable&quot;</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indent</span><span class="si">}</span><span class="s2"> Called gradient_checkpointing_disable()&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indent</span><span class="si">}</span><span class="s2"> gradient_checkpointing_disable failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># 2. Disable flags (but DON&#39;T replace functions)</span>
            <span class="n">_safe_replace_gc_attr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">indent</span><span class="p">)</span>

            <span class="c1"># 3. Recurse into known wrappers</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">,</span> <span class="s2">&quot;transformer&quot;</span><span class="p">,</span> <span class="s2">&quot;bert&quot;</span><span class="p">,</span> <span class="s2">&quot;roberta&quot;</span><span class="p">]:</span>
                <span class="n">inner</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">inner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">inner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">model</span><span class="p">:</span>
                    <span class="n">_recursive_disable</span><span class="p">(</span><span class="n">inner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">attr_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; UNSLOTH-SAFE GRADIENT CHECKPOINTING DISABLE&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;policy_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;policy_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;ref_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ref_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;value_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;value_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;reward_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
        <span class="p">]:</span>
            <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&gt;&gt;&gt; Processing </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">_recursive_disable</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; UNSLOTH-SAFE DISABLE COMPLETE&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;policy_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;policy_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;ref_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ref_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;value_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;value_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;reward_model&quot;</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
        <span class="p">]:</span>
            <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&gt;&gt;&gt; Processing </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">_recursive_disable</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; NUCLEAR DISABLE COMPLETE (SAFE MODE)&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># =========================================================================================</span>
    <span class="c1"># FORCE DISABLE (used for specific model)</span>
    <span class="c1"># =========================================================================================</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_force_disable_gradient_checkpointing_on_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forcefully disable gradient checkpointing - UNSLOTH SAFE.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># 1. Call disable() wherever possible</span>
            <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="n">model</span><span class="p">,</span>
                <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="p">]:</span>
                <span class="k">if</span> <span class="n">target</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing_disable&quot;</span><span class="p">):</span>
                    <span class="n">target</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: called gradient_checkpointing_disable()&quot;</span><span class="p">)</span>

            <span class="c1"># 2. Disable config flags</span>
            <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="p">[</span><span class="n">model</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]:</span>
                <span class="n">cfg</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">cfg</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">):</span>
                        <span class="n">cfg</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;use_cache&quot;</span><span class="p">):</span>
                        <span class="n">cfg</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># 3. DON&#39;T replace _gradient_checkpointing_func - Unsloth needs it!</span>
            <span class="c1"># Just set the flag to False on layers</span>
            <span class="n">inner</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inner</span><span class="p">,</span> <span class="s2">&quot;layers&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">layers</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">):</span>
                        <span class="n">layer</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: disabled GC flags on </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span><span class="si">}</span><span class="s2"> layers&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Force-disabled GC on </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> (Unsloth-safe)&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Error disabling GC on </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_patch_transformers_validation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Global patch for transformers validation to ignore num_logits_to_keep.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers.generation.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenerationMixin</span>

            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">GenerationMixin</span><span class="p">,</span> <span class="s2">&quot;_is_patched_validation&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="k">return</span>

            <span class="n">original_validate</span> <span class="o">=</span> <span class="n">GenerationMixin</span><span class="o">.</span><span class="n">_validate_model_kwargs</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">patched_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">):</span>
                <span class="c1"># Strip num_logits_to_keep if present to avoid ValueError</span>
                <span class="k">if</span> <span class="s1">&#39;num_logits_to_keep&#39;</span> <span class="ow">in</span> <span class="n">model_kwargs</span><span class="p">:</span>
                    <span class="c1"># logger.info(&quot;Global Patch: Stripped num_logits_to_keep from validation&quot;)</span>
                    <span class="n">model_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;num_logits_to_keep&#39;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">original_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="p">)</span>

            <span class="n">GenerationMixin</span><span class="o">.</span><span class="n">_validate_model_kwargs</span> <span class="o">=</span> <span class="n">patched_validate</span>
            <span class="n">GenerationMixin</span><span class="o">.</span><span class="n">_is_patched_validation</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Globally patched transformers._validate_model_kwargs&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Failed to patch transformers validation: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Patch model&#39;s forward method to ignore incompatible kwargs (like position_ids).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Determine target model (handle wrappers)</span>
        <span class="n">target_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">):</span>
            <span class="n">target_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">):</span>
            <span class="n">target_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">target_model</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot patch forward: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> has no forward method&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># Check if model is Decoder (Llama, GPT, etc.) or Encoder (BERT, RoBERTa, DistilBERT)</span>
        <span class="c1"># Only patch decoders conditionally; ALWAYS strip position_ids for encoders</span>
        <span class="n">is_decoder</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">is_encoder</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="n">model_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model_type&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">decoder_models</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;llama&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt&#39;</span><span class="p">,</span> <span class="s1">&#39;mistral&#39;</span><span class="p">,</span> <span class="s1">&#39;gemma&#39;</span><span class="p">,</span> <span class="s1">&#39;qwen&#39;</span><span class="p">,</span> <span class="s1">&#39;opt&#39;</span><span class="p">,</span> <span class="s1">&#39;bloom&#39;</span><span class="p">]</span>
            <span class="n">encoder_models</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bert&#39;</span><span class="p">,</span> <span class="s1">&#39;roberta&#39;</span><span class="p">,</span> <span class="s1">&#39;distilbert&#39;</span><span class="p">,</span> <span class="s1">&#39;albert&#39;</span><span class="p">,</span> <span class="s1">&#39;electra&#39;</span><span class="p">,</span> <span class="s1">&#39;deberta&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">dec</span> <span class="ow">in</span> <span class="n">model_type</span> <span class="k">for</span> <span class="n">dec</span> <span class="ow">in</span> <span class="n">decoder_models</span><span class="p">):</span>
                <span class="n">is_decoder</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">enc</span> <span class="ow">in</span> <span class="n">model_type</span> <span class="k">for</span> <span class="n">enc</span> <span class="ow">in</span> <span class="n">encoder_models</span><span class="p">):</span>
                <span class="n">is_encoder</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_decoder</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_encoder</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Patch the forward method of the model itself</span>
        <span class="n">original_forward</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">forward</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">patched_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># For encoders: ALWAYS strip position_ids and use_cache (they don&#39;t support them)</span>
            <span class="c1"># For decoders: Only strip position_ids during training/eval (not inference)</span>
            <span class="k">if</span> <span class="n">is_encoder</span><span class="p">:</span>
                <span class="k">if</span> <span class="s1">&#39;position_ids&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;position_ids&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="s1">&#39;use_cache&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;use_cache&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># is_decoder</span>
                <span class="n">is_inference</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;use_cache&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;past_key_values&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_inference</span> <span class="ow">and</span> <span class="s1">&#39;position_ids&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;position_ids&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">original_forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">types</span>
        <span class="n">target_model</span><span class="o">.</span><span class="n">forward</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">MethodType</span><span class="p">(</span><span class="n">patched_forward</span><span class="p">,</span> <span class="n">target_model</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Patched </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> forward to conditionally ignore position_ids&quot;</span><span class="p">)</span>

        <span class="c1"># CRITICAL: Also patch the BACKBONE forward because get_reward calls it directly!</span>
        <span class="c1"># get_reward does: lm_backbone = getattr(model, model.base_model_prefix); lm_backbone(...)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;base_model_prefix&quot;</span><span class="p">):</span>
            <span class="n">backbone_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model_prefix</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backbone_name</span><span class="p">):</span>
                <span class="n">backbone</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backbone_name</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">backbone</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">backbone</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">target_model</span><span class="p">:</span>
                    <span class="n">original_backbone_forward</span> <span class="o">=</span> <span class="n">backbone</span><span class="o">.</span><span class="n">forward</span>

                    <span class="k">def</span><span class="w"> </span><span class="nf">patched_backbone_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                        <span class="c1"># For encoders: ALWAYS strip position_ids and use_cache</span>
                        <span class="c1"># For decoders: Only strip position_ids during training/eval</span>
                        <span class="k">if</span> <span class="n">is_encoder</span><span class="p">:</span>
                            <span class="k">if</span> <span class="s1">&#39;position_ids&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                                <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;position_ids&#39;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="s1">&#39;use_cache&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                                <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;use_cache&#39;</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>  <span class="c1"># is_decoder</span>
                            <span class="n">is_inference</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;use_cache&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;past_key_values&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_inference</span> <span class="ow">and</span> <span class="s1">&#39;position_ids&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                                <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;position_ids&#39;</span><span class="p">)</span>
                        <span class="k">return</span> <span class="n">original_backbone_forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

                    <span class="n">backbone</span><span class="o">.</span><span class="n">forward</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">MethodType</span><span class="p">(</span><span class="n">patched_backbone_forward</span><span class="p">,</span> <span class="n">backbone</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Patched backbone (</span><span class="si">{</span><span class="n">backbone_name</span><span class="si">}</span><span class="s2">) forward to conditionally ignore position_ids&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_patch_model_generate_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Patch model&#39;s generate method to remove incompatible kwargs.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Recursive patching for wrappers (PeftModel, etc.)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">model</span><span class="p">:</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_generate_for_compatibility</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.base_model&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;generate&quot;</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="c1"># Avoid double patching</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">,</span> <span class="s2">&quot;_is_patched_compatibility&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">original_generate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">patched_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># Strip num_logits_to_keep if present (causes transformers validation error)</span>
            <span class="k">if</span> <span class="s1">&#39;num_logits_to_keep&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;num_logits_to_keep&#39;</span><span class="p">)</span>

            <span class="c1"># DEBUG: Force keys_to_ignore_at_inference to include num_logits_to_keep</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;keys_to_ignore_at_inference&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="s1">&#39;num_logits_to_keep&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="p">:</span>
                    <span class="c1"># self.config.keys_to_ignore_at_inference.append(&#39;num_logits_to_keep&#39;) # Modify in place</span>
                    <span class="c1"># Some configs use tuples?</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;num_logits_to_keep&#39;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">original_generate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">patched_generate</span><span class="o">.</span><span class="n">_is_patched_compatibility</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">types</span>
        <span class="n">model</span><span class="o">.</span><span class="n">generate</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">MethodType</span><span class="p">(</span><span class="n">patched_generate</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Patched </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> generate to ignore num_logits_to_keep&quot;</span><span class="p">)</span>

        <span class="c1"># CRITICAL: If model has _old_generate (Unsloth), patch it too!</span>
        <span class="c1"># Unsloth&#39;s generate might ADD num_logits_to_keep and then call _old_generate</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;_old_generate&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found _old_generate on </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">. Patching it.&quot;</span><span class="p">)</span>
            <span class="n">original_old_generate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_old_generate</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">patched_old_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="k">if</span> <span class="s1">&#39;num_logits_to_keep&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="c1"># logger.info(f&quot;Stripped num_logits_to_keep in _old_generate of {model_name}&quot;)</span>
                    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;num_logits_to_keep&#39;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">original_old_generate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="kn">import</span><span class="w"> </span><span class="nn">types</span>
            <span class="n">model</span><span class="o">.</span><span class="n">_old_generate</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">MethodType</span><span class="p">(</span><span class="n">patched_old_generate</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Patched </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> _old_generate to ignore num_logits_to_keep&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; _old_generate NOT found on </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> (Type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># =========================================================================================</span>
    <span class="c1"># Integration inside setup_model (simplified relevant part)</span>
    <span class="c1"># =========================================================================================</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model and tokenizer for PPO.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
            <span class="c1"># CRITICAL: Clear cache and patch classes BEFORE any model loading</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">.unsloth_patches</span><span class="w"> </span><span class="kn">import</span> <span class="n">clear_all_unsloth_caches</span><span class="p">,</span> <span class="n">patch_attention_classes_globally</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Step 1: Clearing Unsloth caches...&quot;</span><span class="p">)</span>
            <span class="n">clear_all_unsloth_caches</span><span class="p">()</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Step 2: Patching attention classes at class level...&quot;</span><span class="p">)</span>
            <span class="n">patch_attention_classes_globally</span><span class="p">()</span>

            <span class="c1"># Validate model compatibility</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_model_compatibility</span><span class="p">()</span>

            <span class="c1"># Check if user wants to clear cache (additional clearing if requested)</span>
            <span class="n">clear_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;clear_unsloth_cache&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">clear_cache</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Additional cache clearing requested (clear_unsloth_cache=True)&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_clear_unsloth_cache</span><span class="p">(</span><span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Smart cache invalidation based on config changes</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_invalidate_unsloth_cache</span><span class="p">()</span>

            <span class="c1"># Get config values</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">)</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;max_seq_length&quot;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
            <span class="n">quantization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;quantization&quot;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="c1"># Get precision from config to ensure consistency across all models</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">):</span>
                <span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span><span class="o">.</span><span class="n">value</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2"> for all models&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up Unsloth PPO model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Load tokenizer first (before any model loading)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl.trainer.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">SIMPLE_CHAT_TEMPLATE</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Tokenizer setup</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s2">&quot;pad_token&quot;</span><span class="p">:</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">})</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying Unsloth chat template for PPO...&quot;</span><span class="p">)</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

                <span class="c1"># Get chat template from config if available</span>
                <span class="n">chat_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;chat_template&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                <span class="c1"># Default mapping</span>
                <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;role&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;user&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;assistant&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">}</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_chat_template</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span> <span class="k">if</span> <span class="n">chat_template</span> <span class="k">else</span> <span class="s2">&quot;llama-3&quot;</span><span class="p">,</span> <span class="c1"># Default to llama-3</span>
                        <span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied chat template: </span><span class="si">{</span><span class="n">chat_template</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">chat_template</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;llama-3 (default)&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to apply Unsloth chat template: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Falling back to SIMPLE_CHAT_TEMPLATE.&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="n">SIMPLE_CHAT_TEMPLATE</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer ready (vocab=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Check if separate reward model is specified</span>
            <span class="n">reward_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
                <span class="s2">&quot;reward_model_name&quot;</span><span class="p">,</span> 
                <span class="kc">None</span>
            <span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="o">.</span><span class="n">source_type</span><span class="o">==</span><span class="s2">&quot;custom_trained&quot;</span><span class="p">:</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="o">.</span><span class="n">training_config</span><span class="o">.</span><span class="n">base_model_name</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_train_and_load_custom_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="o">.</span><span class="n">training_config</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
              <span class="k">pass</span>

            <span class="k">if</span> <span class="n">reward_model_name</span><span class="p">:</span>
                <span class="c1"># Check if reward model is already loaded and wrapped</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model already loaded: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">return</span>

                <span class="c1"># Load specialized reward model (e.g., DeBERTa, RoBERTa, or Llama-based)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading specialized reward model: </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

                <span class="c1"># Detect if reward model is a decoder (Llama, Mistral, etc.) or encoder (BERT, RoBERTa, etc.)</span>
                <span class="n">reward_model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect_model_type</span><span class="p">(</span><span class="n">reward_model_name</span><span class="p">)</span>

                <span class="c1"># Load reward model with config precision</span>
                <span class="n">torch_dtype</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span> <span class="k">if</span> <span class="n">precision</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;float16&#39;</span><span class="p">,</span> <span class="s1">&#39;bfloat16&#39;</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>

                <span class="k">if</span> <span class="n">reward_model_type</span> <span class="o">==</span> <span class="s1">&#39;unsloth&#39;</span><span class="p">:</span>
                    <span class="c1"># Load decoder-based reward model via Unsloth</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward model via Unsloth (decoder model): </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                        <span class="n">model_name</span><span class="o">=</span><span class="n">reward_model_name</span><span class="p">,</span>
                        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
                        <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Disable quantization for reward model</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Reward model loaded via Unsloth&quot;</span><span class="p">)</span>

                    <span class="c1"># Unsloth loads as CausalLM. We need to add a score head if it&#39;s missing.</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Adding ad-hoc score head to Unsloth model&quot;</span><span class="p">)</span>
                        <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Ad-hoc score head added&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Load encoder-based reward model via standard transformers</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward model via standard transformers (encoder model): </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                        <span class="n">reward_model_name</span><span class="p">,</span>
                        <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
                        <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                        <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Reward model loaded via standard transformers&quot;</span><span class="p">)</span>

                <span class="c1"># CRITICAL: Ensure ALL parameters are converted to the correct dtype</span>
                <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Before conversion - reward model dtype: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Convert the entire model to the target dtype</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>

                <span class="c1"># Wrap with UniversalRewardModelWrapper for compatibility</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">UniversalRewardModelWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: After .to() conversion - reward model dtype: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Also ensure all submodules are converted</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">old_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                        <span class="n">new_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="k">if</span> <span class="n">DEBUG</span> <span class="ow">and</span> <span class="n">old_dtype</span> <span class="o">!=</span> <span class="n">new_dtype</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Converted </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.weight from </span><span class="si">{</span><span class="n">old_dtype</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">DEBUG</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.weight already </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;bias&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">old_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                        <span class="n">new_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="k">if</span> <span class="n">DEBUG</span> <span class="ow">and</span> <span class="n">old_dtype</span> <span class="o">!=</span> <span class="n">new_dtype</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Converted </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.bias from </span><span class="si">{</span><span class="n">old_dtype</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">DEBUG</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.bias already </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># CRITICAL: Check the classification head specifically</span>
                <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Classifier weight dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Classifier bias dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;None&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Score weight dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Score bias dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">bias</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;None&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="c1"># Final verification</span>
                    <span class="n">final_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Final reward model dtype: </span><span class="si">{</span><span class="n">final_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Target dtype was: </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Reward model loaded with </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2"> precision&quot;</span><span class="p">)</span>

                <span class="c1"># CRITICAL: Check if classifier is actually in the right dtype</span>
                <span class="c1"># Handle different model architectures for head layer</span>
                <span class="n">head_layer</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                    <span class="n">head_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span>
                    <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Using classifier - weight dtype: </span><span class="si">{</span><span class="n">head_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                    <span class="n">head_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span>
                    <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Using score - weight dtype: </span><span class="si">{</span><span class="n">head_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="si">}</span><span class="s2"> has no classifier or score layer&quot;</span><span class="p">)</span>

                <span class="c1"># CRITICAL: Ensure head layer is in the right dtype</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Use .to() which handles recursion for complex heads (like RoBERTa)</span>
                    <span class="n">head_layer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Converted head layer to </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Could not convert head layer to </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Load reward tokenizer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">reward_model_name</span><span class="p">)</span>

                <span class="c1"># Load value model using same model as policy</span>
                <span class="n">reward_value_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
                    <span class="s2">&quot;reward_value_model&quot;</span><span class="p">,</span> 
                    <span class="n">model_name</span>  <span class="c1"># Use policy model for value model</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">reward_value_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">reward_value_model</span> <span class="o">=</span> <span class="n">model_name</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value model: </span><span class="si">{</span><span class="n">reward_value_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect_model_type</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;unsloth&#39;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load_value_model_unsloth</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">quantization</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load_value_model_standard</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>

                <span class="c1"># DEBUG: Check value model dtype</span>
                <span class="k">if</span> <span class="n">DEBUG</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;value_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Value model dtype: </span><span class="si">{</span><span class="n">value_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get value model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Original behavior: use same model for reward/value</span>
                <span class="n">reward_value_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
                    <span class="s2">&quot;reward_value_model&quot;</span><span class="p">,</span> 
                    <span class="kc">None</span> <span class="c1"># Default to None, we will set to model_name if missing</span>
                <span class="p">)</span>

                <span class="c1"># Fallback to policy model if not specified</span>
                <span class="k">if</span> <span class="n">reward_value_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">reward_value_model</span> <span class="o">=</span> <span class="n">model_name</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward/value model: </span><span class="si">{</span><span class="n">reward_value_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect_model_type</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;unsloth&#39;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load_reward_value_models_unsloth</span><span class="p">(</span>
                    <span class="n">reward_value_model</span><span class="p">,</span> 
                        <span class="n">max_seq_length</span><span class="p">,</span> 
                        <span class="n">quantization</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load_reward_value_models_standard</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>

            <span class="c1"># NOW build policy/ref models (Unsloth already imported at top)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Building policy/ref models with Unsloth...&quot;</span><span class="p">)</span>

            <span class="c1"># Load Unsloth policy model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>  <span class="c1"># FIXED: Explicitly set dtype to bfloat16</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
            <span class="p">)</span>

            <span class="c1"># CRITICAL FIX: Apply LoRA with use_gradient_checkpointing=False</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying LoRA WITHOUT gradient checkpointing...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
                <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># CHANGED: Set to False directly</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
                <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Using class-level patches applied before model loading</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">.unsloth_patches</span><span class="w"> </span><span class="kn">import</span> <span class="n">verify_attention_patches</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using class-level patches applied before model loading&quot;</span><span class="p">)</span>
            <span class="n">verify_attention_patches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">)</span>

            <span class="c1"># FIX: Add num_logits_to_keep to ignored keys to prevent generation error</span>
            <span class="c1"># Apply to all reachable configs to be safe</span>
            <span class="n">models_to_fix</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">):</span> <span class="n">models_to_fix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">base_model</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">):</span> <span class="n">models_to_fix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models_to_fix</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;keys_to_ignore_at_inference&quot;</span><span class="p">):</span>
                        <span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">if</span> <span class="s2">&quot;num_logits_to_keep&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="p">:</span>
                        <span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;num_logits_to_keep&quot;</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Added num_logits_to_keep to keys_to_ignore_at_inference for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Policy model ready&quot;</span><span class="p">)</span>

            <span class="c1"># DEBUG: Check policy model dtype</span>
            <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">policy_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model dtype: </span><span class="si">{</span><span class="n">policy_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get policy model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Reference model (no quantization, no GC) - USE SAME DTYPE AS POLICY</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reference model...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>  <span class="c1"># FIXED: Use bfloat16 to match policy model</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># Using class-level patches applied before model loading</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using class-level patches applied before model loading&quot;</span><span class="p">)</span>
            <span class="n">verify_attention_patches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Reference model ready&quot;</span><span class="p">)</span>

            <span class="c1"># DEBUG: Check ref model dtype</span>
            <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">ref_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Reference model dtype: </span><span class="si">{</span><span class="n">ref_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get ref model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; All models loaded successfully&quot;</span><span class="p">)</span>

            <span class="c1"># Log model architecture</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model Architecture:&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Policy:    </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Unsloth + LoRA)&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Reference: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Unsloth frozen)&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Reward:    </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Standard HF)&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;value_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Value:     </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Standard HF)&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

            <span class="c1"># Load reward model if specified</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_load_reward_model_strict</span><span class="p">()</span>

            <span class="c1"># CRITICAL: Patch models to ignore position_ids (for compatibility with TRL get_reward)</span>
            <span class="c1"># Apply to ALL models including reward model (especially important for encoder models like BERT/RoBERTa/DistilBERT)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;policy_model&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span> <span class="s2">&quot;ref_model&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s2">&quot;value_model&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL FIX: Patch reward model attention layers with apply_qkv from policy model</span>
            <span class="c1"># This is necessary when loading multiple Unsloth models, as the second instance might miss the patch</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">policy_attn</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                        <span class="k">if</span> <span class="s1">&#39;Attention&#39;</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                            <span class="n">policy_attn</span> <span class="o">=</span> <span class="n">module</span>
                            <span class="k">break</span>

                    <span class="k">if</span> <span class="n">policy_attn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy_attn</span><span class="p">,</span> <span class="s1">&#39;apply_qkv&#39;</span><span class="p">):</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Patching reward model attention layers with Unsloth methods from policy model...&quot;</span><span class="p">)</span>
                        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                            <span class="k">if</span> <span class="s1">&#39;Attention&#39;</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                                <span class="n">patched_module</span> <span class="o">=</span> <span class="kc">False</span>
                                <span class="c1"># Copy all apply_* methods (apply_qkv, apply_o, etc.)</span>
                                <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">policy_attn</span><span class="p">):</span>
                                    <span class="k">if</span> <span class="n">attr_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;apply_&#39;</span><span class="p">):</span>
                                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                                            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">policy_attn</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">))</span>
                                            <span class="n">patched_module</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="k">if</span> <span class="n">patched_module</span><span class="p">:</span>
                                    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Patched </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> attention layers in reward model&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Policy model has no apply_qkv to copy&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to patch apply_qkv on reward model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># For wrapped reward models, patch the underlying model</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;_model&#39;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span> <span class="s2">&quot;reward_model._model&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s2">&quot;reward_model&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Patch generate to ignore num_logits_to_keep</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_generate_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;policy_model&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_generate_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span> <span class="s2">&quot;ref_model&quot;</span><span class="p">)</span> <span class="c1"># Although ref_model usually doesn&#39;t generate</span>

            <span class="c1"># GLOBAL: Patch transformers validation as a last resort</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_transformers_validation</span><span class="p">()</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Failed to setup model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_reward_model_strict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load reward model with strict validation, NO fallbacks.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_source&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No reward_model_source in config, skipping custom reward model&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;reward_model_source is None, skipping custom reward model&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">reward_source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span>

        <span class="c1"># Validate source before loading</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardModelValidator</span>
        <span class="n">RewardModelValidator</span><span class="o">.</span><span class="n">validate_reward_source</span><span class="p">(</span><span class="n">reward_source</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward model: source_type=</span><span class="si">{</span><span class="n">reward_source</span><span class="o">.</span><span class="n">source_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">reward_source</span><span class="o">.</span><span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;pretrained_hf&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_pretrained_hf_reward_model</span><span class="p">(</span><span class="n">reward_source</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">reward_source</span><span class="o">.</span><span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;pretrained_local&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_local_reward_model</span><span class="p">(</span><span class="n">reward_source</span><span class="o">.</span><span class="n">model_path</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">reward_source</span><span class="o">.</span><span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;custom_trained&quot;</span><span class="p">:</span>
                <span class="c1"># self.reward_model = self._train_and_load_custom_reward_model(reward_source.training_config)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_load_local_reward_model</span><span class="p">(</span><span class="n">reward_source</span><span class="o">.</span><span class="n">training_config</span><span class="o">.</span><span class="n">base_model_name</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid source_type: </span><span class="si">{</span><span class="n">reward_source</span><span class="o">.</span><span class="n">source_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Wrap with UniversalRewardModelWrapper for TRL compatibility</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="n">UniversalRewardModelWrapper</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">UniversalRewardModelWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>

                <span class="c1"># CRITICAL: Add score method directly to the model for TRL compatibility</span>
                <span class="c1"># TRL&#39;s get_reward might bypass the wrapper and call model.score() directly</span>
                <span class="n">base_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                        <span class="k">def</span><span class="w"> </span><span class="nf">score_method</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">):</span>
                            <span class="k">return</span> <span class="n">base_model</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
                        <span class="n">base_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">score_method</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Added score method to base reward model&quot;</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                        <span class="k">pass</span>  <span class="c1"># Already has it</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot; Reward model has no classifier or score layer&quot;</span><span class="p">)</span>

                <span class="c1"># Verify wrapper score method exists</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Reward model wrapper missing score method!&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                        <span class="k">def</span><span class="w"> </span><span class="nf">score_method</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">):</span>
                            <span class="k">return</span> <span class="n">base_model</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">score_method</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added score method to reward model wrapper&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Reward model must have score() or classifier() method&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Reward model wrapper has score method&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Reward model loaded successfully&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Failed to load reward model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_pretrained_hf_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load pre-trained reward model from HuggingFace Hub.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardModelLoader</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading HF reward model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">RewardModelLoader</span><span class="p">()</span>
        <span class="c1"># Use ignore_mismatched_sizes to handle models trained with different num_labels</span>
        <span class="k">return</span> <span class="n">loader</span><span class="o">.</span><span class="n">load_from_huggingface</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_local_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load reward model from local path.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardModelLoader</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading local reward model: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">RewardModelLoader</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loader</span><span class="o">.</span><span class="n">load_from_local</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_train_and_load_custom_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train custom reward model from reward functions.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardModelTrainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training custom reward model from reward functions&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">training_config</span><span class="o">.</span><span class="n">reward_functions</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training texts: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">training_config</span><span class="o">.</span><span class="n">training_texts</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Get reward functions from registry</span>
        <span class="n">reward_funcs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">RewardRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">training_config</span><span class="o">.</span><span class="n">reward_functions</span>
        <span class="p">]</span>

        <span class="c1"># Create trainer</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">RewardModelTrainer</span><span class="p">(</span>
            <span class="n">base_model_name</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">base_model_name</span><span class="p">,</span>
            <span class="n">reward_functions</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>
            <span class="n">composite_weights</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">reward_weights</span>
        <span class="p">)</span>

        <span class="c1"># Generate training data</span>
        <span class="n">training_data</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">generate_training_data</span><span class="p">(</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">training_texts</span><span class="p">,</span>
            <span class="n">references</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">reference_texts</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">)</span>

        <span class="c1"># Train model</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_reward_model</span><span class="p">(</span>
            <span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_epochs</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Custom reward model trained: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load trained model</span>
        <span class="c1"># return self._load_local_reward_model(model_path)</span>
        <span class="k">return</span> <span class="n">model_path</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup reward functions based on configuration mode.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up Unsloth PPO reward functions...&quot;</span><span class="p">)</span>

        <span class="c1"># Determine mode</span>
        <span class="n">has_pretrained</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">has_reward_funcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">fine_tune_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">has_pretrained</span> <span class="ow">and</span> 
            <span class="n">has_reward_funcs</span> <span class="ow">and</span> 
            <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_source&#39;</span><span class="p">)</span> <span class="ow">and</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span> <span class="ow">and</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="p">,</span> <span class="s1">&#39;fine_tune_with_rewards&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Check if reward training is enabled</span>
        <span class="n">should_train_model</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;reward_training&#39;</span><span class="p">)</span> <span class="ow">and</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span> <span class="ow">and</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span><span class="o">.</span><span class="n">enabled</span>
        <span class="p">)</span>

        <span class="c1"># Mode 1: Pretrained only</span>
        <span class="k">if</span> <span class="n">has_pretrained</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">fine_tune_mode</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Pretrained reward model (using as-is)&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;   Reward functions will be ignored&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">return</span>

        <span class="c1"># Mode 2: Custom trained (handled in _load_reward_model_strict)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_pretrained</span> <span class="ow">and</span> <span class="n">has_reward_funcs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">should_train_model</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Custom reward model training&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;   Will train new model using reward functions&quot;</span><span class="p">)</span>
                <span class="c1"># Setup reward functions for training</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_setup_reward_functions</span><span class="p">()</span>
                <span class="k">return</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># NEW: Use reward functions directly with FunctionBasedRewardModel</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Direct reward function usage&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;   Reward functions will be wrapped in FunctionBasedRewardModel&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_setup_reward_functions</span><span class="p">()</span>
                <span class="k">return</span>

        <span class="c1"># Mode 3: Hybrid (fine-tune)</span>
        <span class="k">if</span> <span class="n">fine_tune_mode</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Hybrid (fine-tune pretrained with reward functions)&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_reward_functions</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fine_tune_reward_model</span><span class="p">()</span>
            <span class="k">return</span>

        <span class="c1"># No rewards configured</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No reward model or functions configured&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_setup_reward_functions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal method to setup reward functions.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">:</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">)</span>
            <span class="n">reward_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>
            <span class="n">reward_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">reward_clip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">reward_config</span><span class="p">,</span> <span class="s1">&#39;clip&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Get reward function from registry</span>
            <span class="n">reward_func</span> <span class="o">=</span> <span class="n">RewardRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span><span class="n">reward_type</span><span class="p">)</span>

            <span class="c1"># Apply weight</span>
            <span class="k">if</span> <span class="n">reward_weight</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">weighted_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">reward_weight</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="n">reward_func</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">func</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">reward_func</span> <span class="o">=</span> <span class="n">weighted_reward</span>

            <span class="c1"># Apply clipping</span>
            <span class="k">if</span> <span class="n">reward_clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">clipped_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="n">reward_clip</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="n">reward_func</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="o">-</span><span class="n">clip</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">clip</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)))</span>
                <span class="n">reward_func</span> <span class="o">=</span> <span class="n">clipped_reward</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward_func</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_fine_tune_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fine-tune pretrained reward model with reward functions.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Fine-tuning pretrained reward model...&quot;</span><span class="p">)</span>
        <span class="c1"># Use reward functions to generate additional training data</span>
        <span class="c1"># Fine-tune the loaded model</span>
        <span class="c1"># This is optional advanced feature</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;  Fine-tuning not yet implemented, using pretrained as-is&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute rewards for given texts using configured reward functions.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No reward functions configured, returning zero rewards&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>

        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">reward_func</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">references</span><span class="p">[</span><span class="n">texts</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">text</span><span class="p">)]</span> <span class="k">if</span> <span class="n">references</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error computing reward for text: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="mf">0.0</span>

            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_detect_dataset_format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Detect dataset format.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;messages&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;chat_format&quot;</span>
        <span class="k">elif</span> <span class="s2">&quot;chosen&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="ow">and</span> <span class="s2">&quot;rejected&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;hh_rlhf_with_prompt&quot;</span> <span class="k">if</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">else</span> <span class="s2">&quot;hh_rlhf_no_prompt&quot;</span>
        <span class="k">elif</span> <span class="s2">&quot;instruction&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;alpaca_format&quot;</span>
        <span class="k">elif</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;simple_text&quot;</span>
        <span class="k">elif</span> <span class="s2">&quot;input&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="ow">and</span> <span class="s2">&quot;output&quot;</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;input_output&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;unknown&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_parse_element_by_format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">element</span><span class="p">,</span> <span class="n">format_type</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Parse dataset element - EXACT SAME AS WORKING CODE.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">format_type</span> <span class="o">==</span> <span class="s2">&quot;chat_format&quot;</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">element</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">][:</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">format_type</span> <span class="o">==</span> <span class="s2">&quot;hh_rlhf_with_prompt&quot;</span><span class="p">:</span>
            <span class="n">query_text</span> <span class="o">=</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">query_text</span><span class="p">}]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">messages</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">format_type</span> <span class="o">==</span> <span class="s2">&quot;hh_rlhf_no_prompt&quot;</span><span class="p">:</span>
            <span class="n">chosen_text</span> <span class="o">=</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;chosen&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="k">if</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Human:&quot;</span> <span class="ow">in</span> <span class="n">chosen_text</span> <span class="ow">and</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Assistant:&quot;</span> <span class="ow">in</span> <span class="n">chosen_text</span><span class="p">:</span>
                <span class="n">parts</span> <span class="o">=</span> <span class="n">chosen_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Assistant:&quot;</span><span class="p">)</span>
                <span class="n">human_part</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Human:&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">chosen_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Human:&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">elif</span> <span class="s2">&quot;Human:&quot;</span> <span class="ow">in</span> <span class="n">chosen_text</span> <span class="ow">and</span> <span class="s2">&quot;Assistant:&quot;</span> <span class="ow">in</span> <span class="n">chosen_text</span><span class="p">:</span>
                <span class="n">parts</span> <span class="o">=</span> <span class="n">chosen_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;Assistant:&quot;</span><span class="p">)</span>
                <span class="n">human_part</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Human:&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">chosen_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;Human:&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lines</span> <span class="o">=</span> <span class="n">chosen_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="n">human_part</span> <span class="o">=</span> <span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">lines</span> <span class="k">else</span> <span class="n">chosen_text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">human_part</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">human_part</span> <span class="o">=</span> <span class="n">chosen_text</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_part</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">padding_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot; What do you think about this?&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding_ids</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">format_type</span> <span class="o">==</span> <span class="s2">&quot;alpaca_format&quot;</span><span class="p">:</span>
            <span class="n">instruction</span> <span class="o">=</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;instruction&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;input&quot;</span> <span class="ow">in</span> <span class="n">element</span> <span class="ow">and</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="n">query_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">instruction</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Input: </span><span class="si">{</span><span class="n">element</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">query_text</span> <span class="o">=</span> <span class="n">instruction</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">query_text</span><span class="p">}]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">messages</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">format_type</span> <span class="o">==</span> <span class="s2">&quot;simple_text&quot;</span><span class="p">:</span>
            <span class="n">query_text</span> <span class="o">=</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">query_text</span><span class="p">}]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">messages</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">format_type</span> <span class="o">==</span> <span class="s2">&quot;input_output&quot;</span><span class="p">:</span>
            <span class="n">query_text</span> <span class="o">=</span> <span class="n">element</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">query_text</span><span class="p">}]</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
                <span class="n">messages</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown format: </span><span class="si">{</span><span class="n">format_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Remove trailing EOS</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">eos_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">if</span> <span class="n">eos_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_ids</span> <span class="ow">and</span> <span class="n">input_ids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">eos_id</span><span class="p">:</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># Ensure minimum length</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
            <span class="n">padding_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot; Please elaborate.&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">input_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding_ids</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_ids</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets for PPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up PPO datasets with DataManager...&quot;</span><span class="p">)</span>

        <span class="c1"># Extract dataset configuration</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multiple datasets provided, using first one&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

        <span class="c1"># Extract parameters</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
        <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Advanced DataManager features</span>
        <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">percent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize DataManager for PPO task</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

        <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;sft&quot;</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>
            <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
            <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
            <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span>
        <span class="p">)</span>

        <span class="c1"># Load dataset - DataManager handles everything</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">max_eval_samples</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_eval_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="c1"># Extract train and validation splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>





        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

        <span class="c1"># Tokenize dataset for PPO</span>
        <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Tokenize prompts for PPO training.&quot;&quot;&quot;</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="p">[]))</span>

            <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">prompts</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
            <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>

            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span> <span class="s2">&quot;lengths&quot;</span><span class="p">:</span> <span class="n">lengths</span><span class="p">}</span>

        <span class="c1"># Tokenize datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">tokenize_function</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                <span class="n">tokenize_function</span><span class="p">,</span>
                <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Filter by length</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtering sequences longer than </span><span class="si">{</span><span class="n">max_prompt_length</span><span class="si">}</span><span class="s2"> tokens...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering train dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
                <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering eval dataset&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final dataset sizes - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Verify dataset structure</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span> \
            <span class="s2">&quot;The last token should not be an EOS token&quot;</span>

        <span class="c1"># Log sample</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample tokenized prompt (first 100 chars): </span><span class="si">{</span><span class="n">decoded</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup TRL PPOTrainer.&quot;&quot;&quot;</span>
        <span class="c1"># Set global reference for patched_get_reward</span>
        <span class="k">global</span> <span class="n">GLOBAL_UNSLOTH_TRAINER_REF</span>
        <span class="n">GLOBAL_UNSLOTH_TRAINER_REF</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up PPOTrainer&quot;</span><span class="p">)</span>

            <span class="c1"># Logging configuration with defaults</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
            <span class="n">run_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;ppo_experiment&#39;</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">)</span>

            <span class="c1"># Training parameters from config with defaults</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">1</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">grad_accum</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="n">kl_coef</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
            <span class="n">cliprange</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
            <span class="n">cliprange_value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange_value&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
            <span class="n">vf_coef</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;vf_coef&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lam&#39;</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
            <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">num_ppo_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_ppo_epochs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">4</span>
            <span class="n">whiten_rewards</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;whiten_rewards&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="n">response_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;response_length&#39;</span><span class="p">,</span> <span class="mi">53</span><span class="p">)</span>
            <span class="n">stop_token</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;stop_token&#39;</span><span class="p">,</span> <span class="s1">&#39;eos&#39;</span><span class="p">)</span>
            <span class="n">missing_eos_penalty</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;missing_eos_penalty&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">save_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
            <span class="n">save_strategy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">save_total_limit</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">100</span>
            <span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
            <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="n">gradient_checkpointing_kwargs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_kwargs&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_reentrant&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>

            <span class="c1"># Seed with default</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">42</span><span class="p">)</span>

            <span class="c1"># Precision handling - direct string comparison with default</span>
            <span class="n">precision_str</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">precision_str</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">):</span>  <span class="c1"># Handle enum</span>
                <span class="n">precision_str</span> <span class="o">=</span> <span class="n">precision_str</span><span class="o">.</span><span class="n">value</span>

            <span class="n">bf16</span> <span class="o">=</span> <span class="n">precision_str</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bf16&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">]</span>
            <span class="n">fp16</span> <span class="o">=</span> <span class="n">precision_str</span> <span class="o">==</span> <span class="s1">&#39;fp16&#39;</span>

            <span class="c1"># Calculate total episodes</span>
            <span class="n">total_episodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_epochs</span>

            <span class="c1"># Create PPOConfig</span>
            <span class="n">ppo_config</span> <span class="o">=</span> <span class="n">PPOConfig</span><span class="p">(</span>
                <span class="n">exp_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">mini_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">grad_accum</span><span class="p">,</span>
                <span class="n">total_episodes</span><span class="o">=</span><span class="n">total_episodes</span><span class="p">,</span>
                <span class="n">num_ppo_epochs</span><span class="o">=</span><span class="n">num_ppo_epochs</span><span class="p">,</span>
                <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">cliprange</span><span class="o">=</span><span class="n">cliprange</span><span class="p">,</span>
                <span class="n">cliprange_value</span><span class="o">=</span><span class="n">cliprange_value</span><span class="p">,</span>
                <span class="n">vf_coef</span><span class="o">=</span><span class="n">vf_coef</span><span class="p">,</span>
                <span class="n">kl_coef</span><span class="o">=</span><span class="n">kl_coef</span><span class="p">,</span>
                <span class="n">whiten_rewards</span><span class="o">=</span><span class="n">whiten_rewards</span><span class="p">,</span>
                <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
                <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
                <span class="n">response_length</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
                <span class="n">stop_token</span><span class="o">=</span><span class="n">stop_token</span><span class="p">,</span>
                <span class="n">missing_eos_penalty</span><span class="o">=</span><span class="n">missing_eos_penalty</span><span class="p">,</span>
                <span class="n">local_rollout_forward_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
                <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
                <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>
                <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
                <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>
                <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
                <span class="n">bf16</span><span class="o">=</span><span class="n">bf16</span><span class="p">,</span>
                <span class="n">fp16</span><span class="o">=</span><span class="n">fp16</span><span class="p">,</span>
                <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
                <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
                <span class="n">backend_config</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ppo&#39;</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">ppo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>


            <span class="c1"># DEBUG: Final dtype check before creating trainer</span>
            <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; DEBUG: Final dtype check before PPOTrainer creation:&quot;</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">reward_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Reward model final dtype: </span><span class="si">{</span><span class="n">reward_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;value_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Value model final dtype: </span><span class="si">{</span><span class="n">value_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">policy_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model final dtype: </span><span class="si">{</span><span class="n">policy_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                    <span class="c1"># CRITICAL: Test a forward pass to check hidden states dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; DEBUG: Testing forward pass dtypes...&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
                        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
                                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s1">&#39;hidden_states&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">:</span>
                                    <span class="n">hidden_dtype</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
                                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model hidden states dtype: </span><span class="si">{</span><span class="n">hidden_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model outputs type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not test policy model forward pass: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get final dtypes: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Check if we should use function-based reward model</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_functions&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Use function-based reward model</span>
                    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.rl.function_based_reward_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">FunctionBasedRewardModel</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Using function-based reward model with reward functions&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward function(s) configured&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

                    <span class="c1"># Get device and dtype from policy model</span>
                    <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
                    <span class="n">dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">FunctionBasedRewardModel</span><span class="p">(</span>
                        <span class="n">reward_functions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">,</span>
                        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; FunctionBasedRewardModel created and moved to device&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;TRL PPOTrainer requires either:</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;  - reward_model: A neural network reward model (pretrained or custom trained)</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;    Examples: &#39;OpenAssistant/reward-model-deberta-v3-large-v2&#39;, &#39;Skywork/Skywork-Reward-V2-Qwen3-0.6B&#39;</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;  - reward_functions: Rule-based reward functions (will be wrapped in FunctionBasedRewardModel)</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;    Example: [{&#39;type&#39;: &#39;length&#39;, &#39;weight&#39;: 1.0}, {&#39;type&#39;: &#39;sentiment&#39;, &#39;weight&#39;: 0.5}]</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;  - reward_training.enabled=True: Train a custom reward model from reward functions</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="s2">&quot;Please provide one of these options.&quot;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Neural reward model provided</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Using neural network reward model&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Reward model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Create trainer with strict generation limits</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">PPOTrainer</span><span class="p">(</span>
                <span class="n">args</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
                <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span>
                <span class="n">reward_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span>
                <span class="n">value_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Patch PolicyAndValueWrapper (keep this)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_patch_policy_wrapper</span><span class="p">()</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PPOTrainer created successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_patch_policy_wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Patch PolicyAndValueWrapper to add missing methods for Unsloth compatibility.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">wrapper</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">wrapper</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="c1"># Add gradient_checkpointing_disable method if missing</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">_disable_gc</span><span class="p">():</span>
<span class="w">                    </span><span class="sd">&quot;&quot;&quot;Disable gradient checkpointing on underlying models.&quot;&quot;&quot;</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">policy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">policy</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
                            <span class="n">policy</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
                        <span class="n">base</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">base</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">):</span>
                            <span class="n">base</span><span class="o">.</span><span class="n">gradient_checkpointing_disable</span><span class="p">()</span>
                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="k">pass</span>

                <span class="nb">setattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_disable&#39;</span><span class="p">,</span> <span class="n">_disable_gc</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added gradient_checkpointing_disable() to PolicyAndValueWrapper&quot;</span><span class="p">)</span>

            <span class="c1"># Add gradient_checkpointing_enable method if missing</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_enable&#39;</span><span class="p">):</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">_enable_gc</span><span class="p">(</span><span class="n">gradient_checkpointing_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">                    </span><span class="sd">&quot;&quot;&quot;Enable gradient checkpointing on underlying models.&quot;&quot;&quot;</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">policy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">policy</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_enable&#39;</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">gradient_checkpointing_kwargs</span><span class="p">:</span>
                                <span class="n">policy</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">(</span><span class="n">gradient_checkpointing_kwargs</span><span class="o">=</span><span class="n">gradient_checkpointing_kwargs</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">policy</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>
                        <span class="n">base</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">base</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_enable&#39;</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">gradient_checkpointing_kwargs</span><span class="p">:</span>
                                <span class="n">base</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">(</span><span class="n">gradient_checkpointing_kwargs</span><span class="o">=</span><span class="n">gradient_checkpointing_kwargs</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">base</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>
                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="k">pass</span>

                <span class="nb">setattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_enable&#39;</span><span class="p">,</span> <span class="n">_enable_gc</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added gradient_checkpointing_enable() to PolicyAndValueWrapper&quot;</span><span class="p">)</span>

            <span class="c1"># Add generate method if missing (for Unsloth)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;generate&#39;</span><span class="p">):</span>
                <span class="n">policy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">base</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">policy</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s1">&#39;generate&#39;</span><span class="p">):</span>
                    <span class="n">target</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">generate</span>
                <span class="k">elif</span> <span class="n">base</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="s1">&#39;generate&#39;</span><span class="p">):</span>
                    <span class="n">target</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">generate</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">_delegate_generate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">target</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

                <span class="nb">setattr</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="s1">&#39;generate&#39;</span><span class="p">,</span> <span class="n">_delegate_generate</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added generate() to PolicyAndValueWrapper&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not patch PolicyAndValueWrapper: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Not used - TRL handles training loop.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Not used - TRL handles data loading.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute PPO training.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Unsloth PPO training&quot;</span><span class="p">)</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="c1"># Setup everything</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

            <span class="c1"># Train</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running PPO training...&quot;</span><span class="p">)</span>
            <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">generate_and_log_samples</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">sample_logging</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_functions&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                    <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;post-train&quot;</span><span class="p">,</span>
                    <span class="n">log</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">sample_error</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to log qualitative samples: </span><span class="si">{</span><span class="n">sample_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Save</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

            <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

            <span class="c1"># TRL PPOTrainer.train() may return None (or an object without global_step).</span>
            <span class="c1"># Use training_history length as a robust fallback so examples don&#39;t report 0 steps.</span>
            <span class="n">fallback_steps</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;training_history&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">:</span>
                    <span class="n">fallback_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">fallback_steps</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
                <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">training_result</span><span class="p">,</span> <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
                <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">training_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">fallback_steps</span><span class="p">,</span>
                <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
                <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
                <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s2">&quot;num_datasets&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_train_custom_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train a custom reward model using the reward_training config.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardModelTrainer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.factory</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_reward_functions</span>

        <span class="n">reward_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span>

        <span class="c1"># Create reward functions from config</span>
        <span class="k">if</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="n">reward_functions</span> <span class="o">=</span> <span class="n">create_reward_functions</span><span class="p">(</span><span class="n">reward_config</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Default reward functions if none specified</span>
            <span class="n">reward_functions</span> <span class="o">=</span> <span class="n">create_reward_functions</span><span class="p">([</span>
                <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;length&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;min_length&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;max_length&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span>
                <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;sentiment&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;positive_weight&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span>
                <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;coherence&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;threshold&#39;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">}},</span>
                <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;safety&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;strict&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}}</span>
            <span class="p">])</span>

        <span class="c1"># Create composite weights</span>
        <span class="n">composite_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">reward_functions</span><span class="p">)</span>

        <span class="c1"># Determine base model for reward training</span>
        <span class="n">base_model_name</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">base_model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span>

        <span class="c1"># Create reward model trainer</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">RewardModelTrainer</span><span class="p">(</span>
            <span class="n">base_model_name</span><span class="o">=</span><span class="n">base_model_name</span><span class="p">,</span>
            <span class="n">reward_functions</span><span class="o">=</span><span class="n">reward_functions</span><span class="p">,</span>
            <span class="n">composite_weights</span><span class="o">=</span><span class="n">composite_weights</span>
        <span class="p">)</span>

        <span class="c1"># Load training data</span>
        <span class="n">training_texts</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">load_training_data</span><span class="p">(</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">training_texts</span><span class="p">,</span>
            <span class="n">dataset_name</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">dataset_path</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span>
            <span class="n">dataset_split</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">dataset_split</span><span class="p">,</span>
            <span class="n">text_column</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">text_column</span><span class="p">,</span>
            <span class="n">max_samples</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">max_samples</span>
        <span class="p">)</span>

        <span class="c1"># Generate training dataset</span>
        <span class="n">training_data</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">generate_training_data</span><span class="p">(</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">training_texts</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">)</span>

        <span class="c1"># Train the reward model</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_reward_model</span><span class="p">(</span>
            <span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">num_epochs</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">reward_config</span><span class="o">.</span><span class="n">logging_steps</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Custom reward model training completed: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_path</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate model with fallback for missing memory tracker.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset provided&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">{}</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Evaluating...&quot;</span><span class="p">)</span>

            <span class="c1"># Initialize memory tracker if missing</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;_memory_tracker&#39;</span><span class="p">):</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainerMemoryTracker</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">_memory_tracker</span> <span class="o">=</span> <span class="n">TrainerMemoryTracker</span><span class="p">(</span><span class="n">skip_memory_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initialized missing memory tracker&quot;</span><span class="p">)</span>

            <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">eval_results</span>

        <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;_memory_tracker&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory tracker error during evaluation: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping evaluation - this is a known TRL/Transformers compatibility issue&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;eval_skipped&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;reason&quot;</span><span class="p">:</span> <span class="s2">&quot;memory_tracker_missing&quot;</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">raise</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>    
    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saved successfully&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">save_path</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Save failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loaded successfully&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Load failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Not used - TRL handles data loading.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Not used - TRL handles data loading.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Evaluate model with fallback for missing memory tracker.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2277</span>
<span class="normal">2278</span>
<span class="normal">2279</span>
<span class="normal">2280</span>
<span class="normal">2281</span>
<span class="normal">2282</span>
<span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span>
<span class="normal">2293</span>
<span class="normal">2294</span>
<span class="normal">2295</span>
<span class="normal">2296</span>
<span class="normal">2297</span>
<span class="normal">2298</span>
<span class="normal">2299</span>
<span class="normal">2300</span>
<span class="normal">2301</span>
<span class="normal">2302</span>
<span class="normal">2303</span>
<span class="normal">2304</span>
<span class="normal">2305</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate model with fallback for missing memory tracker.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No evaluation dataset provided&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Evaluating...&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize memory tracker if missing</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;_memory_tracker&#39;</span><span class="p">):</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainerMemoryTracker</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">_memory_tracker</span> <span class="o">=</span> <span class="n">TrainerMemoryTracker</span><span class="p">(</span><span class="n">skip_memory_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initialized missing memory tracker&quot;</span><span class="p">)</span>

        <span class="n">eval_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">eval_results</span>

    <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="s1">&#39;_memory_tracker&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory tracker error during evaluation: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping evaluation - this is a known TRL/Transformers compatibility issue&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;eval_skipped&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;reason&quot;</span><span class="p">:</span> <span class="s2">&quot;memory_tracker_missing&quot;</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>    
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if Unsloth and TRL are available and properly configured.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if Unsloth and TRL are available and properly configured.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Check Unsloth installation</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

        <span class="c1"># Check if Unsloth is properly configured</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;UNSLOTH_IS_PRESENT&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Unsloth not properly initialized&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Check TRL availability</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth PPO backend not available: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsloth PPO backend configuration error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2327</span>
<span class="normal">2328</span>
<span class="normal">2329</span>
<span class="normal">2330</span>
<span class="normal">2331</span>
<span class="normal">2332</span>
<span class="normal">2333</span>
<span class="normal">2334</span>
<span class="normal">2335</span>
<span class="normal">2336</span>
<span class="normal">2337</span>
<span class="normal">2338</span>
<span class="normal">2339</span>
<span class="normal">2340</span>
<span class="normal">2341</span>
<span class="normal">2342</span>
<span class="normal">2343</span>
<span class="normal">2344</span>
<span class="normal">2345</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loaded successfully&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Load failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2306</span>
<span class="normal">2307</span>
<span class="normal">2308</span>
<span class="normal">2309</span>
<span class="normal">2310</span>
<span class="normal">2311</span>
<span class="normal">2312</span>
<span class="normal">2313</span>
<span class="normal">2314</span>
<span class="normal">2315</span>
<span class="normal">2316</span>
<span class="normal">2317</span>
<span class="normal">2318</span>
<span class="normal">2319</span>
<span class="normal">2320</span>
<span class="normal">2321</span>
<span class="normal">2322</span>
<span class="normal">2323</span>
<span class="normal">2324</span>
<span class="normal">2325</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;training_config.yaml&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saved successfully&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">save_path</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Save failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets for PPO training using unified DataManager.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets for PPO training using unified DataManager.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up PPO datasets with DataManager...&quot;</span><span class="p">)</span>

    <span class="c1"># Extract dataset configuration</span>
    <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multiple datasets provided, using first one&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

    <span class="c1"># Extract parameters</span>
    <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
    <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Advanced DataManager features</span>
    <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">percent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;percent&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize DataManager for PPO task</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

    <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;sft&quot;</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span>
        <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
        <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
        <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span>
    <span class="p">)</span>

    <span class="c1"># Load dataset - DataManager handles everything</span>
    <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
        <span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
        <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">max_eval_samples</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_eval_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Extract train and validation splits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>


    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span>





    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

    <span class="c1"># Tokenize dataset for PPO</span>
    <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_prompt_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenize prompts for PPO training.&quot;&quot;&quot;</span>
        <span class="n">prompts</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="n">examples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="p">[]))</span>

        <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompts</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span> <span class="s2">&quot;lengths&quot;</span><span class="p">:</span> <span class="n">lengths</span><span class="p">}</span>

    <span class="c1"># Tokenize datasets</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">tokenize_function</span><span class="p">,</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">tokenize_function</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Filter by length</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Filtering sequences longer than </span><span class="si">{</span><span class="n">max_prompt_length</span><span class="si">}</span><span class="s2"> tokens...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
        <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering train dataset&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;lengths&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Filtering eval dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final dataset sizes - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Verify dataset structure</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span> \
        <span class="s2">&quot;The last token should not be an EOS token&quot;</span>

    <span class="c1"># Log sample</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample tokenized prompt (first 100 chars): </span><span class="si">{</span><span class="n">decoded</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup Unsloth-optimized model and tokenizer for PPO.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model and tokenizer for PPO.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
        <span class="c1"># CRITICAL: Clear cache and patch classes BEFORE any model loading</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.unsloth_patches</span><span class="w"> </span><span class="kn">import</span> <span class="n">clear_all_unsloth_caches</span><span class="p">,</span> <span class="n">patch_attention_classes_globally</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Step 1: Clearing Unsloth caches...&quot;</span><span class="p">)</span>
        <span class="n">clear_all_unsloth_caches</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Step 2: Patching attention classes at class level...&quot;</span><span class="p">)</span>
        <span class="n">patch_attention_classes_globally</span><span class="p">()</span>

        <span class="c1"># Validate model compatibility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_model_compatibility</span><span class="p">()</span>

        <span class="c1"># Check if user wants to clear cache (additional clearing if requested)</span>
        <span class="n">clear_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;clear_unsloth_cache&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">clear_cache</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;  Additional cache clearing requested (clear_unsloth_cache=True)&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_clear_unsloth_cache</span><span class="p">(</span><span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Smart cache invalidation based on config changes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_invalidate_unsloth_cache</span><span class="p">()</span>

        <span class="c1"># Get config values</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">)</span>
        <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;max_seq_length&quot;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="n">quantization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;quantization&quot;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="c1"># Get precision from config to ensure consistency across all models</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">):</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span><span class="o">.</span><span class="n">value</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2"> for all models&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up Unsloth PPO model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load tokenizer first (before any model loading)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl.trainer.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">SIMPLE_CHAT_TEMPLATE</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Tokenizer setup</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s2">&quot;pad_token&quot;</span><span class="p">:</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">})</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying Unsloth chat template for PPO...&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Get chat template from config if available</span>
            <span class="n">chat_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s1">&#39;chat_template&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Default mapping</span>
            <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;role&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="s2">&quot;user&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;assistant&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">}</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_chat_template</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span> <span class="k">if</span> <span class="n">chat_template</span> <span class="k">else</span> <span class="s2">&quot;llama-3&quot;</span><span class="p">,</span> <span class="c1"># Default to llama-3</span>
                    <span class="n">mapping</span><span class="o">=</span><span class="n">mapping</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applied chat template: </span><span class="si">{</span><span class="n">chat_template</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">chat_template</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;llama-3 (default)&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to apply Unsloth chat template: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Falling back to SIMPLE_CHAT_TEMPLATE.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="n">SIMPLE_CHAT_TEMPLATE</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer ready (vocab=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Check if separate reward model is specified</span>
        <span class="n">reward_model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
            <span class="s2">&quot;reward_model_name&quot;</span><span class="p">,</span> 
            <span class="kc">None</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="o">.</span><span class="n">source_type</span><span class="o">==</span><span class="s2">&quot;custom_trained&quot;</span><span class="p">:</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="o">.</span><span class="n">training_config</span><span class="o">.</span><span class="n">base_model_name</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">_train_and_load_custom_reward_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="o">.</span><span class="n">training_config</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
          <span class="k">pass</span>

        <span class="k">if</span> <span class="n">reward_model_name</span><span class="p">:</span>
            <span class="c1"># Check if reward model is already loaded and wrapped</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward model already loaded: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span>

            <span class="c1"># Load specialized reward model (e.g., DeBERTa, RoBERTa, or Llama-based)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading specialized reward model: </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

            <span class="c1"># Detect if reward model is a decoder (Llama, Mistral, etc.) or encoder (BERT, RoBERTa, etc.)</span>
            <span class="n">reward_model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect_model_type</span><span class="p">(</span><span class="n">reward_model_name</span><span class="p">)</span>

            <span class="c1"># Load reward model with config precision</span>
            <span class="n">torch_dtype</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span> <span class="k">if</span> <span class="n">precision</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;float16&#39;</span><span class="p">,</span> <span class="s1">&#39;bfloat16&#39;</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>

            <span class="k">if</span> <span class="n">reward_model_type</span> <span class="o">==</span> <span class="s1">&#39;unsloth&#39;</span><span class="p">:</span>
                <span class="c1"># Load decoder-based reward model via Unsloth</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward model via Unsloth (decoder model): </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="n">reward_model_name</span><span class="p">,</span>
                    <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
                    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Disable quantization for reward model</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Reward model loaded via Unsloth&quot;</span><span class="p">)</span>

                <span class="c1"># Unsloth loads as CausalLM. We need to add a score head if it&#39;s missing.</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Adding ad-hoc score head to Unsloth model&quot;</span><span class="p">)</span>
                    <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Ad-hoc score head added&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Load encoder-based reward model via standard transformers</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading reward model via standard transformers (encoder model): </span><span class="si">{</span><span class="n">reward_model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                    <span class="n">reward_model_name</span><span class="p">,</span>
                    <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">,</span>
                    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
                    <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Reward model loaded via standard transformers&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Ensure ALL parameters are converted to the correct dtype</span>
            <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Before conversion - reward model dtype: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Convert the entire model to the target dtype</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>

            <span class="c1"># Wrap with UniversalRewardModelWrapper for compatibility</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">UniversalRewardModelWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: After .to() conversion - reward model dtype: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Also ensure all submodules are converted</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">old_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                    <span class="n">new_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="k">if</span> <span class="n">DEBUG</span> <span class="ow">and</span> <span class="n">old_dtype</span> <span class="o">!=</span> <span class="n">new_dtype</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Converted </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.weight from </span><span class="si">{</span><span class="n">old_dtype</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">DEBUG</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.weight already </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;bias&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">old_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                    <span class="n">new_dtype</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="k">if</span> <span class="n">DEBUG</span> <span class="ow">and</span> <span class="n">old_dtype</span> <span class="o">!=</span> <span class="n">new_dtype</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Converted </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.bias from </span><span class="si">{</span><span class="n">old_dtype</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">DEBUG</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.bias already </span><span class="si">{</span><span class="n">new_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Check the classification head specifically</span>
            <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Classifier weight dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Classifier bias dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;None&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Score weight dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Score bias dtype: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">bias</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;None&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Final verification</span>
                <span class="n">final_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Final reward model dtype: </span><span class="si">{</span><span class="n">final_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Target dtype was: </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Reward model loaded with </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2"> precision&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Check if classifier is actually in the right dtype</span>
            <span class="c1"># Handle different model architectures for head layer</span>
            <span class="n">head_layer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">):</span>
                <span class="n">head_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">classifier</span>
                <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Using classifier - weight dtype: </span><span class="si">{</span><span class="n">head_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">):</span>
                <span class="n">head_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">score</span>
                <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Using score - weight dtype: </span><span class="si">{</span><span class="n">head_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="si">}</span><span class="s2"> has no classifier or score layer&quot;</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Ensure head layer is in the right dtype</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Use .to() which handles recursion for complex heads (like RoBERTa)</span>
                <span class="n">head_layer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Converted head layer to </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Could not convert head layer to </span><span class="si">{</span><span class="n">torch_dtype</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Load reward tokenizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">reward_model_name</span><span class="p">)</span>

            <span class="c1"># Load value model using same model as policy</span>
            <span class="n">reward_value_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
                <span class="s2">&quot;reward_value_model&quot;</span><span class="p">,</span> 
                <span class="n">model_name</span>  <span class="c1"># Use policy model for value model</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">reward_value_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">reward_value_model</span> <span class="o">=</span> <span class="n">model_name</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value model: </span><span class="si">{</span><span class="n">reward_value_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect_model_type</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;unsloth&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_value_model_unsloth</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">quantization</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_value_model_standard</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>

            <span class="c1"># DEBUG: Check value model dtype</span>
            <span class="k">if</span> <span class="n">DEBUG</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;value_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Value model dtype: </span><span class="si">{</span><span class="n">value_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get value model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Original behavior: use same model for reward/value</span>
            <span class="n">reward_value_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
                <span class="s2">&quot;reward_value_model&quot;</span><span class="p">,</span> 
                <span class="kc">None</span> <span class="c1"># Default to None, we will set to model_name if missing</span>
            <span class="p">)</span>

            <span class="c1"># Fallback to policy model if not specified</span>
            <span class="k">if</span> <span class="n">reward_value_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">reward_value_model</span> <span class="o">=</span> <span class="n">model_name</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward/value model: </span><span class="si">{</span><span class="n">reward_value_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">model_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect_model_type</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s1">&#39;unsloth&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_reward_value_models_unsloth</span><span class="p">(</span>
                <span class="n">reward_value_model</span><span class="p">,</span> 
                    <span class="n">max_seq_length</span><span class="p">,</span> 
                    <span class="n">quantization</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_reward_value_models_standard</span><span class="p">(</span><span class="n">reward_value_model</span><span class="p">)</span>

        <span class="c1"># NOW build policy/ref models (Unsloth already imported at top)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Building policy/ref models with Unsloth...&quot;</span><span class="p">)</span>

        <span class="c1"># Load Unsloth policy model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>  <span class="c1"># FIXED: Explicitly set dtype to bfloat16</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># CRITICAL FIX: Apply LoRA with use_gradient_checkpointing=False</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying LoRA WITHOUT gradient checkpointing...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unsloth_model</span><span class="p">,</span>
            <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># CHANGED: Set to False directly</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
            <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Using class-level patches applied before model loading</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.unsloth_patches</span><span class="w"> </span><span class="kn">import</span> <span class="n">verify_attention_patches</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using class-level patches applied before model loading&quot;</span><span class="p">)</span>
        <span class="n">verify_attention_patches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">)</span>

        <span class="c1"># FIX: Add num_logits_to_keep to ignored keys to prevent generation error</span>
        <span class="c1"># Apply to all reachable configs to be safe</span>
        <span class="n">models_to_fix</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">):</span> <span class="n">models_to_fix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">base_model</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">):</span> <span class="n">models_to_fix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models_to_fix</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;keys_to_ignore_at_inference&quot;</span><span class="p">):</span>
                    <span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="s2">&quot;num_logits_to_keep&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="p">:</span>
                    <span class="n">m</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keys_to_ignore_at_inference</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;num_logits_to_keep&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Added num_logits_to_keep to keys_to_ignore_at_inference for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Policy model ready&quot;</span><span class="p">)</span>

        <span class="c1"># DEBUG: Check policy model dtype</span>
        <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">policy_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model dtype: </span><span class="si">{</span><span class="n">policy_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get policy model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Reference model (no quantization, no GC) - USE SAME DTYPE AS POLICY</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading reference model...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>  <span class="c1"># FIXED: Use bfloat16 to match policy model</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Using class-level patches applied before model loading</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using class-level patches applied before model loading&quot;</span><span class="p">)</span>
        <span class="n">verify_attention_patches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Reference model ready&quot;</span><span class="p">)</span>

        <span class="c1"># DEBUG: Check ref model dtype</span>
        <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">ref_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Reference model dtype: </span><span class="si">{</span><span class="n">ref_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get ref model dtype: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; All models loaded successfully&quot;</span><span class="p">)</span>

        <span class="c1"># Log model architecture</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model Architecture:&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Policy:    </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Unsloth + LoRA)&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Reference: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Unsloth frozen)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Reward:    </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Standard HF)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;value_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Value:     </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> (Standard HF)&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

        <span class="c1"># Load reward model if specified</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_load_reward_model_strict</span><span class="p">()</span>

        <span class="c1"># CRITICAL: Patch models to ignore position_ids (for compatibility with TRL get_reward)</span>
        <span class="c1"># Apply to ALL models including reward model (especially important for encoder models like BERT/RoBERTa/DistilBERT)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;policy_model&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span> <span class="s2">&quot;ref_model&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span> <span class="s2">&quot;value_model&quot;</span><span class="p">)</span>

        <span class="c1"># CRITICAL FIX: Patch reward model attention layers with apply_qkv from policy model</span>
        <span class="c1"># This is necessary when loading multiple Unsloth models, as the second instance might miss the patch</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">policy_attn</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                    <span class="k">if</span> <span class="s1">&#39;Attention&#39;</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                        <span class="n">policy_attn</span> <span class="o">=</span> <span class="n">module</span>
                        <span class="k">break</span>

                <span class="k">if</span> <span class="n">policy_attn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy_attn</span><span class="p">,</span> <span class="s1">&#39;apply_qkv&#39;</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Patching reward model attention layers with Unsloth methods from policy model...&quot;</span><span class="p">)</span>
                    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                        <span class="k">if</span> <span class="s1">&#39;Attention&#39;</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                            <span class="n">patched_module</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="c1"># Copy all apply_* methods (apply_qkv, apply_o, etc.)</span>
                            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">policy_attn</span><span class="p">):</span>
                                <span class="k">if</span> <span class="n">attr_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;apply_&#39;</span><span class="p">):</span>
                                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                                        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">policy_attn</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">))</span>
                                        <span class="n">patched_module</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="k">if</span> <span class="n">patched_module</span><span class="p">:</span>
                                <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Patched </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> attention layers in reward model&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Policy model has no apply_qkv to copy&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to patch apply_qkv on reward model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># For wrapped reward models, patch the underlying model</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s1">&#39;_model&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span> <span class="s2">&quot;reward_model._model&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_forward_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="s2">&quot;reward_model&quot;</span><span class="p">)</span>

        <span class="c1"># CRITICAL: Patch generate to ignore num_logits_to_keep</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_generate_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span> <span class="s2">&quot;policy_model&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_model_generate_for_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span> <span class="s2">&quot;ref_model&quot;</span><span class="p">)</span> <span class="c1"># Although ref_model usually doesn&#39;t generate</span>

        <span class="c1"># GLOBAL: Patch transformers validation as a last resort</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_transformers_validation</span><span class="p">()</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Failed to setup model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup reward functions based on configuration mode.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup reward functions based on configuration mode.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up Unsloth PPO reward functions...&quot;</span><span class="p">)</span>

    <span class="c1"># Determine mode</span>
    <span class="n">has_pretrained</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">has_reward_funcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">fine_tune_mode</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">has_pretrained</span> <span class="ow">and</span> 
        <span class="n">has_reward_funcs</span> <span class="ow">and</span> 
        <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;reward_model_source&#39;</span><span class="p">)</span> <span class="ow">and</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span> <span class="ow">and</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reward_model_source</span><span class="p">,</span> <span class="s1">&#39;fine_tune_with_rewards&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Check if reward training is enabled</span>
    <span class="n">should_train_model</span> <span class="o">=</span> <span class="p">(</span>
        <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;reward_training&#39;</span><span class="p">)</span> <span class="ow">and</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span> <span class="ow">and</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_training</span><span class="o">.</span><span class="n">enabled</span>
    <span class="p">)</span>

    <span class="c1"># Mode 1: Pretrained only</span>
    <span class="k">if</span> <span class="n">has_pretrained</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">fine_tune_mode</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Pretrained reward model (using as-is)&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;   Reward functions will be ignored&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">return</span>

    <span class="c1"># Mode 2: Custom trained (handled in _load_reward_model_strict)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_pretrained</span> <span class="ow">and</span> <span class="n">has_reward_funcs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">should_train_model</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Custom reward model training&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;   Will train new model using reward functions&quot;</span><span class="p">)</span>
            <span class="c1"># Setup reward functions for training</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_reward_functions</span><span class="p">()</span>
            <span class="k">return</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># NEW: Use reward functions directly with FunctionBasedRewardModel</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Direct reward function usage&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;   Reward functions will be wrapped in FunctionBasedRewardModel&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_reward_functions</span><span class="p">()</span>
            <span class="k">return</span>

    <span class="c1"># Mode 3: Hybrid (fine-tune)</span>
    <span class="k">if</span> <span class="n">fine_tune_mode</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Mode: Hybrid (fine-tune pretrained with reward functions)&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_reward_functions</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fine_tune_reward_model</span><span class="p">()</span>
        <span class="k">return</span>

    <span class="c1"># No rewards configured</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No reward model or functions configured&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup TRL PPOTrainer.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span>
<span class="normal">2074</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup TRL PPOTrainer.&quot;&quot;&quot;</span>
    <span class="c1"># Set global reference for patched_get_reward</span>
    <span class="k">global</span> <span class="n">GLOBAL_UNSLOTH_TRAINER_REF</span>
    <span class="n">GLOBAL_UNSLOTH_TRAINER_REF</span> <span class="o">=</span> <span class="bp">self</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOTrainer</span><span class="p">,</span> <span class="n">PPOConfig</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up PPOTrainer&quot;</span><span class="p">)</span>

        <span class="c1"># Logging configuration with defaults</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
        <span class="n">run_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;ppo_experiment&#39;</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">)</span>

        <span class="c1"># Training parameters from config with defaults</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">1</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">grad_accum</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">)</span>
        <span class="n">kl_coef</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
        <span class="n">cliprange</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="n">cliprange_value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange_value&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="n">vf_coef</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;vf_coef&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lam&#39;</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">num_ppo_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_ppo_epochs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">4</span>
        <span class="n">whiten_rewards</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;whiten_rewards&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">response_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;response_length&#39;</span><span class="p">,</span> <span class="mi">53</span><span class="p">)</span>
        <span class="n">stop_token</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;stop_token&#39;</span><span class="p">,</span> <span class="s1">&#39;eos&#39;</span><span class="p">)</span>
        <span class="n">missing_eos_penalty</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;missing_eos_penalty&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">save_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_steps&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_strategy&#39;</span><span class="p">,</span> <span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">save_total_limit</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">100</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">gradient_checkpointing_kwargs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_kwargs&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;use_reentrant&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>

        <span class="c1"># Seed with default</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">42</span><span class="p">)</span>

        <span class="c1"># Precision handling - direct string comparison with default</span>
        <span class="n">precision_str</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">precision_str</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">):</span>  <span class="c1"># Handle enum</span>
            <span class="n">precision_str</span> <span class="o">=</span> <span class="n">precision_str</span><span class="o">.</span><span class="n">value</span>

        <span class="n">bf16</span> <span class="o">=</span> <span class="n">precision_str</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bf16&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">]</span>
        <span class="n">fp16</span> <span class="o">=</span> <span class="n">precision_str</span> <span class="o">==</span> <span class="s1">&#39;fp16&#39;</span>

        <span class="c1"># Calculate total episodes</span>
        <span class="n">total_episodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_epochs</span>

        <span class="c1"># Create PPOConfig</span>
        <span class="n">ppo_config</span> <span class="o">=</span> <span class="n">PPOConfig</span><span class="p">(</span>
            <span class="n">exp_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">mini_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">grad_accum</span><span class="p">,</span>
            <span class="n">total_episodes</span><span class="o">=</span><span class="n">total_episodes</span><span class="p">,</span>
            <span class="n">num_ppo_epochs</span><span class="o">=</span><span class="n">num_ppo_epochs</span><span class="p">,</span>
            <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">cliprange</span><span class="o">=</span><span class="n">cliprange</span><span class="p">,</span>
            <span class="n">cliprange_value</span><span class="o">=</span><span class="n">cliprange_value</span><span class="p">,</span>
            <span class="n">vf_coef</span><span class="o">=</span><span class="n">vf_coef</span><span class="p">,</span>
            <span class="n">kl_coef</span><span class="o">=</span><span class="n">kl_coef</span><span class="p">,</span>
            <span class="n">whiten_rewards</span><span class="o">=</span><span class="n">whiten_rewards</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
            <span class="n">response_length</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
            <span class="n">stop_token</span><span class="o">=</span><span class="n">stop_token</span><span class="p">,</span>
            <span class="n">missing_eos_penalty</span><span class="o">=</span><span class="n">missing_eos_penalty</span><span class="p">,</span>
            <span class="n">local_rollout_forward_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_steps</span><span class="p">,</span>
            <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>
            <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">bf16</span><span class="o">=</span><span class="n">bf16</span><span class="p">,</span>
            <span class="n">fp16</span><span class="o">=</span><span class="n">fp16</span><span class="p">,</span>
            <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
            <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
            <span class="n">backend_config</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ppo&#39;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">ppo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>


        <span class="c1"># DEBUG: Final dtype check before creating trainer</span>
        <span class="k">if</span> <span class="n">DEBUG</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; DEBUG: Final dtype check before PPOTrainer creation:&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">reward_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Reward model final dtype: </span><span class="si">{</span><span class="n">reward_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;value_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Value model final dtype: </span><span class="si">{</span><span class="n">value_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">policy_dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model final dtype: </span><span class="si">{</span><span class="n">policy_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># CRITICAL: Test a forward pass to check hidden states dtype</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; DEBUG: Testing forward pass dtypes...&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;policy_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s1">&#39;hidden_states&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">:</span>
                                <span class="n">hidden_dtype</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
                                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model hidden states dtype: </span><span class="si">{</span><span class="n">hidden_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Policy model outputs type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not test policy model forward pass: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; DEBUG: Could not get final dtypes: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Check if we should use function-based reward model</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_model&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_functions&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Use function-based reward model</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.rl.function_based_reward_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">FunctionBasedRewardModel</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Using function-based reward model with reward functions&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward function(s) configured&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

                <span class="c1"># Get device and dtype from policy model</span>
                <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">FunctionBasedRewardModel</span><span class="p">(</span>
                    <span class="n">reward_functions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">,</span>
                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; FunctionBasedRewardModel created and moved to device&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;TRL PPOTrainer requires either:</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;  - reward_model: A neural network reward model (pretrained or custom trained)</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;    Examples: &#39;OpenAssistant/reward-model-deberta-v3-large-v2&#39;, &#39;Skywork/Skywork-Reward-V2-Qwen3-0.6B&#39;</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;  - reward_functions: Rule-based reward functions (will be wrapped in FunctionBasedRewardModel)</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;    Example: [{&#39;type&#39;: &#39;length&#39;, &#39;weight&#39;: 1.0}, {&#39;type&#39;: &#39;sentiment&#39;, &#39;weight&#39;: 0.5}]</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;  - reward_training.enabled=True: Train a custom reward model from reward functions</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;Please provide one of these options.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Neural reward model provided</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Using neural network reward model&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Reward model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Create trainer with strict generation limits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">PPOTrainer</span><span class="p">(</span>
            <span class="n">args</span><span class="o">=</span><span class="n">ppo_config</span><span class="p">,</span>
            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
            <span class="n">ref_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ref_model</span><span class="p">,</span>
            <span class="n">reward_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span>
            <span class="n">value_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">value_model</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Patch PolicyAndValueWrapper (keep this)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patch_policy_wrapper</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PPOTrainer created successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute PPO training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span>
<span class="normal">2169</span>
<span class="normal">2170</span>
<span class="normal">2171</span>
<span class="normal">2172</span>
<span class="normal">2173</span>
<span class="normal">2174</span>
<span class="normal">2175</span>
<span class="normal">2176</span>
<span class="normal">2177</span>
<span class="normal">2178</span>
<span class="normal">2179</span>
<span class="normal">2180</span>
<span class="normal">2181</span>
<span class="normal">2182</span>
<span class="normal">2183</span>
<span class="normal">2184</span>
<span class="normal">2185</span>
<span class="normal">2186</span>
<span class="normal">2187</span>
<span class="normal">2188</span>
<span class="normal">2189</span>
<span class="normal">2190</span>
<span class="normal">2191</span>
<span class="normal">2192</span>
<span class="normal">2193</span>
<span class="normal">2194</span>
<span class="normal">2195</span>
<span class="normal">2196</span>
<span class="normal">2197</span>
<span class="normal">2198</span>
<span class="normal">2199</span>
<span class="normal">2200</span>
<span class="normal">2201</span>
<span class="normal">2202</span>
<span class="normal">2203</span>
<span class="normal">2204</span>
<span class="normal">2205</span>
<span class="normal">2206</span>
<span class="normal">2207</span>
<span class="normal">2208</span>
<span class="normal">2209</span>
<span class="normal">2210</span>
<span class="normal">2211</span>
<span class="normal">2212</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute PPO training.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Unsloth PPO training&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Setup everything</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Train</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Running PPO training...&quot;</span><span class="p">)</span>
        <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">generate_and_log_samples</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">sample_logging</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;reward_functions&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">stage</span><span class="o">=</span><span class="s2">&quot;post-train&quot;</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">sample_error</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to log qualitative samples: </span><span class="si">{</span><span class="n">sample_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/ppo&#39;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving to: </span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="c1"># TRL PPOTrainer.train() may return None (or an object without global_step).</span>
        <span class="c1"># Use training_history length as a robust fallback so examples don&#39;t report 0 steps.</span>
        <span class="n">fallback_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;training_history&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">:</span>
                <span class="n">fallback_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">fallback_steps</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">training_result</span><span class="p">,</span> <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">training_result</span><span class="p">,</span> <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">fallback_steps</span><span class="p">,</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
            <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;num_datasets&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.ppo.ppo.UnslothPPOTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Not used - TRL handles training loop.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/ppo/ppo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2143</span>
<span class="normal">2144</span>
<span class="normal">2145</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Not used - TRL handles training loop.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<h4 id="unslothgrpotrainer"><code>UnslothGRPOTrainer</code><a class="headerlink" href="#unslothgrpotrainer" title="Permanent link">&para;</a></h4>
<p>Unsloth backend for Group Relative Policy Optimization.</p>


<div class="doc doc-object doc-class">



<a id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="aligntune.core.rl.trainer_base.TrainerBase">TrainerBase</span></code></p>



        <p>GRPO trainer using Unsloth's FastLanguageModel for optimized training.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  29</span>
<span class="normal">  30</span>
<span class="normal">  31</span>
<span class="normal">  32</span>
<span class="normal">  33</span>
<span class="normal">  34</span>
<span class="normal">  35</span>
<span class="normal">  36</span>
<span class="normal">  37</span>
<span class="normal">  38</span>
<span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">UnslothGRPOTrainer</span><span class="p">(</span><span class="n">TrainerBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GRPO trainer using Unsloth&#39;s FastLanguageModel for optimized training.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">UnifiedConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_cache</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_manager</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_configs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_evaluator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if Unsloth and TRL are available.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_obj</span><span class="p">,</span> <span class="o">*</span><span class="n">attr_names</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely get config value from multiple possible attribute names.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">config_obj</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">config_obj</span><span class="p">[</span><span class="n">attr_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="n">attr_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config_obj</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">default</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model and tokenizer for GRPO.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Handle both dict and object config</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;name_or_path&#39;</span><span class="p">)</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
                <span class="n">quantization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
                <span class="n">quantization</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up Unsloth GRPO model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Configure Unsloth model parameters</span>
            <span class="c1"># Unsloth only accepts: max_seq_length, dtype, and load_in_4bit</span>
            <span class="c1"># Other quantization params are NOT passed to from_pretrained</span>
            <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s1">&#39;auto&#39;</span>
            <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="n">max_seq_length</span><span class="p">,</span>
                <span class="c1"># Auto-detect (Unsloth will use bfloat16 automatically)</span>
                <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span> <span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">quantization</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="kc">True</span><span class="p">,</span>
                <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model with kwargs: </span><span class="si">{</span><span class="n">model_kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Load model with Unsloth optimizations</span>
            <span class="c1"># NOTE: Unsloth handles all quantization internally - don&#39;t pass</span>
            <span class="c1"># bnb_4bit params</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>

            <span class="c1"># Set pad token if not present</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

            <span class="c1"># Configure model for GRPO training with LoRA (use config values)</span>
            <span class="c1"># NOTE: AlignTune configs may be dataclasses or dicts depending on how the trainer was created.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_peft&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
                <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_r&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
                <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_alpha&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">lora_r</span><span class="p">)))</span>
                <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_dropout&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s2">&quot;lora_target_modules&quot;</span><span class="p">,</span>
                    <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">use_peft</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;use_peft&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
                <span class="n">lora_r</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lora_r&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
                <span class="n">lora_alpha</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lora_alpha&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">lora_r</span><span class="p">)))</span>
                <span class="n">lora_dropout</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lora_dropout&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="s2">&quot;lora_target_modules&quot;</span><span class="p">,</span>
                    <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">r</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">lora_r</span><span class="p">),</span>
                    <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span>
                    <span class="n">lora_alpha</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">lora_alpha</span><span class="p">),</span>
                    <span class="n">lora_dropout</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">lora_dropout</span><span class="p">),</span>
                    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="s2">&quot;unsloth&quot;</span> <span class="k">if</span> <span class="n">gradient_checkpointing</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
                    <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">loftq_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth GRPO model setup completed successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup Unsloth GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup reward functions using the centralized registry system.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up reward functions for GRPO...&quot;</span><span class="p">)</span>

        <span class="c1"># Get reward configurations</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;rewards&#39;</span><span class="p">):</span>
            <span class="n">rewards_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">rewards_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;No reward configurations found, using default rewards&quot;</span><span class="p">)</span>
            <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;length&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentiment&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;positive_weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;safety&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                            <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}},</span> <span class="p">{</span>
                                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;diversity&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span>
                                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">]</span>

        <span class="c1"># Load reward functions from the registry</span>
        <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="n">rewards_config</span><span class="p">:</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1">#  SPECIAL CASE: custom reward function passed directly</span>
                <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="s1">&#39;reward_function&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;reward_function&#39;</span><span class="p">]</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot; Loaded custom reward function (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                    <span class="c1"># Store directly - no registry needed</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                        <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;custom&quot;</span>
                    <span class="p">})</span>
                    <span class="k">continue</span>  <span class="c1"># Skip registry lookup</span>

                <span class="c1"># Use the rewards registry to get reward functions</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span> <span class="k">as</span> <span class="n">RewardsRegistry</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardConfig</span><span class="p">,</span> <span class="n">RewardType</span>

                <span class="c1"># Map common variations to standard names</span>
                <span class="n">reward_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;math&#39;</span><span class="p">:</span> <span class="s1">&#39;math_reasoning&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;code_quality&#39;</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_type</span><span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Convert reward type string to enum</span>
                    <span class="n">reward_type_enum</span> <span class="o">=</span> <span class="n">RewardType</span><span class="p">[</span><span class="n">reward_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>

                    <span class="c1"># Create RewardConfig with weight and params</span>
                    <span class="n">reward_cfg</span> <span class="o">=</span> <span class="n">RewardConfig</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="o">=</span><span class="n">reward_type_enum</span><span class="p">,</span>
                        <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Weight will be applied separately</span>
                        <span class="n">params</span><span class="o">=</span><span class="n">params</span>
                    <span class="p">)</span>

                    <span class="c1"># Get reward function from registry</span>
                    <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_cfg</span><span class="p">)</span>
                    <span class="c1"># Extract the callable compute method</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot; Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward from registry (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                    <span class="c1"># Reward type not in enum, try registry by name</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward type &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; not in RewardType enum, trying registry by name&quot;</span><span class="p">)</span>
                    <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                        <span class="n">reward_type</span><span class="p">)</span>

                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                        <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                        <span class="k">continue</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot; Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward by name (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="c1"># Store reward function with metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                    <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">reward_type</span>
                <span class="p">})</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to load reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">continue</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;No reward functions were loaded! Adding a simple default length reward.&quot;</span><span class="p">)</span>
            <span class="c1"># Add a simple fallback reward so training doesn&#39;t fail</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">default_length_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">length</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="mf">0.5</span>
                <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mf">200.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="mf">1.0</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">default_length_reward</span><span class="p">,</span>
                <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;default_length&quot;</span>
            <span class="p">})</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added default length reward as fallback&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot; Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions successfully&quot;</span><span class="p">)</span>

        <span class="c1"># Log summary of loaded rewards</span>
        <span class="n">reward_summary</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_summary</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_combined_reward_function</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">completions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Combined reward function that applies all registered rewards.</span>

<span class="sd">        Args:</span>
<span class="sd">            completions: List of generated completions</span>
<span class="sd">            **kwargs: Additional arguments from TRL including:</span>
<span class="sd">                - prompts: List of prompts</span>
<span class="sd">                - test_list: List of test cases (for code datasets like MBPP)</span>
<span class="sd">                - answer/solution/reference: Reference answers (for math datasets)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">completions</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Debug: log what TRL is passing (once)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_logged_kwargs&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[DEBUG] _combined_reward_function kwargs keys: </span><span class="si">{</span>
<span class="w">                    </span><span class="nb">list</span><span class="p">(</span>
<span class="w">                        </span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;test_list&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;test_list&#39;</span><span class="p">][:</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;test_list&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;empty&#39;</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[DEBUG] test_list found, sample: </span><span class="si">{</span><span class="n">sample</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;[DEBUG] test_list NOT in kwargs!&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logged_kwargs</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">batch_rewards</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Extract batch data from kwargs (TRL passes these as lists)</span>
        <span class="n">test_lists</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;test_list&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">))</span>
        <span class="c1"># CHECK MULTIPLE POSSIBLE REFERENCE COLUMN NAMES</span>
        <span class="c1"># Try different column names in order of preference</span>
        <span class="n">references</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">ref_key</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s1">&#39;answer&#39;</span><span class="p">,</span>
            <span class="s1">&#39;solution&#39;</span><span class="p">,</span>
            <span class="s1">&#39;reference&#39;</span><span class="p">,</span>
            <span class="s1">&#39;response&#39;</span><span class="p">,</span>
            <span class="s1">&#39;ground_truth&#39;</span><span class="p">,</span>
                <span class="s1">&#39;target&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">ref_key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">references</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">ref_key</span><span class="p">]</span>
                <span class="c1"># print(f&quot;[INFO] Found reference data in column: &#39;{ref_key}&#39;&quot;)</span>
                <span class="k">break</span>

        <span class="c1"># If no reference column found, use None for all completions</span>
        <span class="k">if</span> <span class="n">references</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[WARNING] No reference column found. Checked: answer, solution, reference, ground_truth, target&quot;</span><span class="p">)</span>

        <span class="c1"># Ensure lists match completion length</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_lists</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">test_lists</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_lists</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">completion</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">completions</span><span class="p">):</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c1"># Get per-sample data</span>
            <span class="n">test_cases</span> <span class="o">=</span> <span class="n">test_lists</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_lists</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">reference</span> <span class="o">=</span> <span class="n">references</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">references</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">rf</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>

                    <span class="c1"># Handle different reward function signatures</span>
                    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func</span><span class="p">):</span>
                        <span class="c1"># Try different calling patterns</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="c1"># Pattern 1: text + test_cases (for code execution)</span>
                            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                <span class="n">completion</span><span class="p">,</span> <span class="n">test_cases</span><span class="o">=</span><span class="n">test_cases</span><span class="p">)</span>
                        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="c1"># Pattern 2: Just text</span>
                                <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
                            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                <span class="k">try</span><span class="p">:</span>
                                    <span class="c1"># Pattern 3: text + reference</span>
                                    <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                        <span class="n">completion</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">reference</span><span class="p">)</span>
                                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                    <span class="k">try</span><span class="p">:</span>
                                        <span class="c1"># Pattern 4: text + reference + context</span>
                                        <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_func</span><span class="p">(</span>
                                            <span class="n">completion</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="p">{})</span>
                                    <span class="k">except</span> <span class="ne">BaseException</span><span class="p">:</span>
                                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                                            <span class="sa">f</span><span class="s2">&quot;Could not call reward function </span><span class="si">{</span>
<span class="w">                                                </span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, returning 0&quot;</span><span class="p">)</span>
                                        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Reward function </span><span class="si">{</span>
<span class="w">                                </span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> is not callable&quot;</span><span class="p">)</span>
                        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>

                    <span class="c1"># Apply weight</span>
                    <span class="n">weighted_reward</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">*</span> <span class="n">weight</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">weighted_reward</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward </span><span class="si">{</span>
<span class="w">                            </span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span>
<span class="w">                            </span><span class="n">reward</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (weighted: </span><span class="si">{</span>
<span class="w">                            </span><span class="n">weighted_reward</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error computing reward </span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">batch_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>

        <span class="c1"># Log batch statistics with completions summary</span>
        <span class="k">if</span> <span class="n">batch_rewards</span><span class="p">:</span>
            <span class="n">successful</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">partial</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">failed</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">batch_rewards</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;BATCH REWARDS: </span><span class="si">{</span><span class="n">successful</span><span class="si">}</span><span class="s2"> passed | </span><span class="si">{</span><span class="n">partial</span><span class="si">}</span><span class="s2"> partial | </span><span class="si">{</span><span class="n">failed</span><span class="si">}</span><span class="s2"> failed | total=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">len</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Reward stats: min=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">min</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">max</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, mean=</span><span class="si">{</span>
<span class="w">                    </span><span class="nb">sum</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="w"> </span><span class="o">/</span>
<span class="w">                    </span><span class="nb">len</span><span class="p">(</span><span class="n">batch_rewards</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">60</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">batch_rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets - compatible with base trainer interface.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup datasets for GRPO training using unified DataManager.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up GRPO datasets with DataManager...&quot;</span><span class="p">)</span>

        <span class="c1"># Extract dataset configuration</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

        <span class="c1"># Extract parameters</span>
        <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Advanced DataManager features</span>
        <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="c1"># Initialize DataManager for GRPO task</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

        <span class="c1"># Columns to preserve for reward computation (test cases, solutions,</span>
        <span class="c1"># etc.)</span>
        <span class="n">preserve_columns</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;test_list&#39;</span><span class="p">,</span>
            <span class="s1">&#39;test&#39;</span><span class="p">,</span>
            <span class="s1">&#39;answer&#39;</span><span class="p">,</span>
            <span class="s1">&#39;solution&#39;</span><span class="p">,</span>
            <span class="s1">&#39;code&#39;</span><span class="p">,</span>
            <span class="s1">&#39;canonical_solution&#39;</span><span class="p">}</span>

        <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;grpo&quot;</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
            <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
            <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
            <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
            <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span> 
        <span class="p">)</span>

        <span class="c1"># Load dataset - DataManager handles all the complexity</span>
        <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="p">,</span>
            <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
            <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
            <span class="n">max_samples</span><span class="o">=</span><span class="n">max_samples</span>
        <span class="p">)</span>

        <span class="c1"># Extract train and validation splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span> 


        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

        <span class="c1"># Log sample</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">prompt_col</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="k">if</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">else</span> <span class="s2">&quot;query&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Sample prompt (first 100 chars): </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="n">prompt_col</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup TRL GRPOTrainer with Unsloth model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL GRPOTrainer with Unsloth model&quot;</span><span class="p">)</span>

            <span class="c1"># Handle both dict and object config</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                     <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                     <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                                 <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
                <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-4</span><span class="p">)</span>
                <span class="n">save_interval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
                <span class="n">eval_interval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
                <span class="n">kl_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
                <span class="n">cliprange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
                <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">learning_rate</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-4</span><span class="p">)</span>
                <span class="n">save_interval</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
                <span class="n">eval_interval</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
                <span class="n">kl_coef</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
                <span class="n">cliprange</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>

            <span class="c1"># Get max sequence length from model config</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

            <span class="c1"># CRITICAL: Calculate max_prompt_length and max_completion_length</span>
            <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_seq_length</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>  <span class="c1"># 60% for prompt</span>
            <span class="n">max_completion_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                <span class="n">max_seq_length</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">)</span>  <span class="c1"># 40% for completion</span>

            <span class="c1"># Determine evaluation and save strategy based on eval_dataset</span>
            <span class="n">has_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

            <span class="c1"># Set save strategy</span>
            <span class="n">save_strategy</span> <span class="o">=</span> <span class="s2">&quot;steps&quot;</span>

            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.precision_handler</span><span class="w"> </span><span class="kn">import</span> <span class="n">PrecisionHandler</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
            <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;GRPO (Unsloth)&quot;</span><span class="p">)</span>
            <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span>
                <span class="n">precision</span><span class="p">)</span>
            <span class="c1"># Evaluation parameters</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>
            <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Adjust eval strategy based on eval_dataset availability</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
                <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
                <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Logging parameters</span>
            <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
            <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Report to</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;report_to&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">loggers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loggers</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
            <span class="k">if</span> <span class="n">loggers</span> <span class="ow">and</span> <span class="n">report_to</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span><span class="p">:</span>
                <span class="n">report_to</span> <span class="o">=</span> <span class="n">loggers</span>

            <span class="c1"># Run name</span>
            <span class="n">run_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;unsloth_grpo&#39;</span><span class="p">)</span>

            <span class="c1"># Optimizer parameters</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
            <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>
            <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

            <span class="c1"># Additional training parameters</span>
            <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                <span class="s1">&#39;use_gradient_checkpointing&#39;</span><span class="p">,</span>
                <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">,</span>
                <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">group_by_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;group_by_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">data_seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;data_seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">47</span><span class="p">)</span>
            <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s2">&quot;max_steps&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>

            <span class="c1"># GRPO specific parameters</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">kl_coef</span><span class="p">)</span>
            <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">cliprange</span><span class="p">)</span>
            <span class="n">loss_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
            <span class="n">scale_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;scale_rewards&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;group&#39;</span><span class="p">)</span>
            <span class="n">mask_truncated_completions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;mask_truncated_completions&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="n">top_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;top_p&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
            <span class="n">num_generations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_generations&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>
            <span class="c1"># TRL GRPOConfig supports GRPO variants: &quot;grpo&quot;, &quot;dapo&quot;, &quot;dr_grpo&quot;</span>
            <span class="n">VALID_GRPO_LOSS_TYPES</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;grpo&quot;</span><span class="p">,</span> <span class="s2">&quot;dapo&quot;</span><span class="p">,</span> <span class="s2">&quot;dr_grpo&quot;</span><span class="p">}</span>

            <span class="k">if</span> <span class="n">loss_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss_type</span> <span class="o">=</span> <span class="s2">&quot;grpo&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">loss_type</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="c1"># &quot;sigmoid&quot; is a DPO loss type, not valid for GRPO - raise error</span>
            <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;loss_type=&#39;sigmoid&#39; is a DPO/IPO loss type and is not valid for GRPO training. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid GRPO loss types are: </span><span class="si">{</span><span class="n">VALID_GRPO_LOSS_TYPES</span><span class="si">}</span><span class="s2"> use grpo&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">loss_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">VALID_GRPO_LOSS_TYPES</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Unknown loss_type=&#39;</span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s2">&#39; for GRPO. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid GRPO loss types are: </span><span class="si">{</span><span class="n">VALID_GRPO_LOSS_TYPES</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Adjust save strategy to save on epoch</span>
            <span class="n">save_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="s2">&quot;steps&quot;</span>

            <span class="c1"># Create GRPO configuration</span>
            <span class="n">grpo_config</span> <span class="o">=</span> <span class="n">GRPOConfig</span><span class="p">(</span>
                <span class="c1"># Output and logging</span>
                <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
                <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
                <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
                <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span><span class="p">,</span>
                <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
                <span class="c1"># Evaluation</span>
                <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
                <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>
                <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
                <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
                <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>
                <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>

                <span class="c1"># Checkpointing</span>
                <span class="n">save_steps</span><span class="o">=</span><span class="n">save_interval</span><span class="p">,</span>
                <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
                <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>

                <span class="c1"># Training parameters</span>
                <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
                <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">warmup_ratio</span><span class="p">,</span>
                <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
                <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>

                <span class="c1"># Optimizer and scheduler</span>
                <span class="n">optim</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="n">lr_scheduler_type</span><span class="p">,</span>

                <span class="c1"># GRPO specific parameters</span>
                <span class="n">max_prompt_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
                <span class="n">max_completion_length</span><span class="o">=</span><span class="n">max_completion_length</span><span class="p">,</span>
                <span class="n">num_generations</span><span class="o">=</span><span class="n">num_generations</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
                <span class="n">loss_type</span><span class="o">=</span><span class="n">loss_type</span><span class="p">,</span>
                <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span>
                <span class="n">scale_rewards</span><span class="o">=</span><span class="n">scale_rewards</span><span class="p">,</span>
                <span class="n">mask_truncated_completions</span><span class="o">=</span><span class="n">mask_truncated_completions</span><span class="p">,</span>

                <span class="c1"># Seeds</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">data_seed</span><span class="o">=</span><span class="n">data_seed</span><span class="p">,</span>

                <span class="c1"># Performance</span>
                <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="n">gradient_checkpointing</span><span class="p">,</span>
                <span class="n">group_by_length</span><span class="o">=</span><span class="n">group_by_length</span><span class="p">,</span>
                <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

                <span class="c1"># Precision</span>
                <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

                <span class="c1"># Other settings</span>
                <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
                <span class="n">backend_config</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;grpo&#39;</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">grpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="c1"># Rest of your code stays the same...</span>

            <span class="c1"># Get max_seq_length for text truncation in reward functions</span>
            <span class="c1"># Use conservative limit: most reward models (e.g., toxic-bert) have max_length=512</span>
            <span class="c1"># Truncate to min(512, model_max_seq_length) to prevent tensor</span>
            <span class="c1"># shape mismatches</span>
            <span class="n">model_max_seq_length</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># Default</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="n">model_max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">model_max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
            <span class="c1"># Use conservative 512 limit for reward functions (most reward</span>
            <span class="c1"># models expect this)</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">model_max_seq_length</span><span class="p">)</span>

            <span class="c1"># # Create trainer with reward functions</span>
            <span class="c1"># self.trainer = GRPOTrainer(</span>
            <span class="c1">#     model=self.model,</span>
            <span class="c1">#     tokenizer=self.tokenizer,</span>
            <span class="c1">#     train_dataset=self.train_dataset,</span>
            <span class="c1">#     eval_dataset=self.eval_dataset,</span>
            <span class="c1">#     args=grpo_config,</span>
            <span class="c1">#     reward_funcs=self._combined_reward_function if self.reward_functions else None,</span>
            <span class="c1"># )</span>
            <span class="c1"># # Create GRPO trainer</span>

            <span class="n">use_rewards_directly</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> 
                <span class="s1">&#39;use_rewards_directly&#39;</span><span class="p">,</span> 
                <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">use_rewards_directly</span><span class="p">:</span>
                <span class="c1"># Use functions directly (no wrapper)</span>
                <span class="n">reward_funcs</span> <span class="o">=</span> <span class="n">use_rewards_directly</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Using </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions DIRECTLY&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use combined wrapper (default)</span>
                <span class="n">reward_funcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Using _combined_reward_function wrapper&quot;</span><span class="p">)</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
            <span class="n">should_use_pure_trl</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PURE_TRL_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span>

            <span class="k">if</span> <span class="n">should_use_pure_trl</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PURE_TRL_MODE enabled - using pure TRL API&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                    <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                    <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">reward_funcs</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Detected Unsloth environment&quot;</span><span class="p">)</span>

                    <span class="c1"># Unsloth expects a list of functions</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="c1"># Already a list (direct mode)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Passing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">)</span><span class="si">}</span><span class="s2"> functions directly&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                            <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>  <span class="c1"># List of functions</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Single function (wrapper mode) - wrap it for Unsloth</span>
                        <span class="c1"># logger.info(&quot;Wrapping _combined_reward_function for Unsloth&quot;)</span>
                        <span class="c1"># def unsloth_reward_wrapper(prompts=None, completions=None, **kwargs):</span>
                        <span class="c1">#     if completions is None:</span>
                        <span class="c1">#         return [0.0] * (len(prompts) if prompts else 1)</span>
                        <span class="c1">#     return reward_funcs(completions, **kwargs)</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                            <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>  <span class="c1"># List with wrapper</span>
                        <span class="p">)</span>

                <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using pure TRL (no Unsloth)&quot;</span><span class="p">)</span>

                    <span class="c1"># Pure TRL can accept either format</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="c1"># Direct mode: pass list as-is</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                            <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Wrapper mode: wrap in list</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                            <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                            <span class="n">reward_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">reward_funcs</span><span class="p">],</span>  <span class="c1"># Wrap single function in list</span>
                        <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO trainer setup completed successfully!&quot;</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPOTrainer setup completed&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup GRPO trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Execute a single training step.</span>

<span class="sd">        NOTE: For Unsloth GRPO, the actual training is handled by TRL&#39;s GRPOTrainer,</span>
<span class="sd">        so this method is not used during training. It&#39;s implemented to satisfy</span>
<span class="sd">        the TrainerBase abstract method requirement.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This method is required by TrainerBase but not used in Unsloth GRPO</span>
        <span class="c1"># because TRL&#39;s GRPOTrainer handles the training loop internally</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;train_step() called but Unsloth GRPO uses TRL&#39;s internal training loop&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create data loader for training.</span>

<span class="sd">        NOTE: For Unsloth GRPO, data loading is handled by TRL&#39;s GRPOTrainer,</span>
<span class="sd">        so this method returns None. It&#39;s implemented to satisfy the TrainerBase</span>
<span class="sd">        abstract method requirement if it exists.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This method might be required by TrainerBase but not used in Unsloth GRPO</span>
        <span class="c1"># because TRL&#39;s GRPOTrainer handles data loading internally</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;create_data_loader() called but Unsloth GRPO uses TRL&#39;s internal data loading&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute GRPO training with Unsloth optimizations.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Unsloth GRPO training&quot;</span><span class="p">)</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="c1"># Setup components</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
            <span class="n">use_rewards_directly</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;use_rewards_directly&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">use_rewards_directly</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping setup_rewards() - using reward functions directly from config&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

            <span class="c1"># Start training</span>
            <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Get output directory</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                     <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                     <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                                 <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

            <span class="c1"># Save model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

            <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

            <span class="c1"># Compile results</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
                <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="n">training_result</span><span class="p">,</span>
                    <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
                <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="n">training_result</span><span class="p">,</span>
                    <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
                <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
                <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
                <span class="s2">&quot;num_datasets&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                        <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsloth GRPO training completed in </span><span class="si">{</span>
<span class="w">                    </span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">training_result</span><span class="p">,</span> <span class="s1">&#39;training_loss&#39;</span><span class="p">):</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final loss: </span><span class="si">{</span><span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GRPO training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="c1"># def evaluate(self) -&gt; Dict[str, Any]:</span>
    <span class="c1">#     &quot;&quot;&quot;Evaluate the trained GRPO model.&quot;&quot;&quot;</span>
    <span class="c1">#     try:</span>
    <span class="c1">#         if not self.eval_dataset:</span>
    <span class="c1">#             logger.warning(&quot;No evaluation dataset available&quot;)</span>
    <span class="c1">#             return {}</span>

    <span class="c1">#         logger.info(&quot;Evaluating Unsloth GRPO model&quot;)</span>

    <span class="c1">#         # Run evaluation</span>
    <span class="c1">#         eval_results = self.trainer.evaluate()</span>

    <span class="c1">#         logger.info(f&quot;GRPO evaluation results: {eval_results}&quot;)</span>

    <span class="c1">#         return eval_results</span>

    <span class="c1">#     except Exception as e:</span>
    <span class="c1">#         logger.error(f&quot;GRPO evaluation failed: {e}&quot;)</span>
    <span class="c1">#         raise</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span><span class="p">,</span>
        <span class="n">use_custom_evaluator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;GRPO-specific evaluation - auto-setup evaluators and delegate to parent.&quot;&quot;&quot;</span>

        <span class="c1"># Auto-setup evaluators on first call</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-initializing evaluators for first evaluation...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_custom_evaluator</span><span class="p">(</span><span class="n">evaluator_type</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

        <span class="c1"># Call parent&#39;s unified evaluate method</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">metric_key_prefix</span><span class="o">=</span><span class="n">metric_key_prefix</span><span class="p">,</span>
            <span class="n">use_custom_evaluator</span><span class="o">=</span><span class="n">use_custom_evaluator</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the trained GRPO model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">default_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                       <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                       <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                                   <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

            <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving Unsloth GRPO model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Save using Unsloth&#39;s optimized saving</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

            <span class="c1"># Save training configuration</span>
            <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;grpo_training_config.yaml&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GRPO model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">save_path</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained GRPO model.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Unsloth GRPO model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

            <span class="c1"># Handle both dict and object config</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

            <span class="c1"># Load model and tokenizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO model loaded successfully&quot;</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.create_data_loader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_data_loader</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.create_data_loader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create data loader for training.</p>
<p>NOTE: For Unsloth GRPO, data loading is handled by TRL's GRPOTrainer,
so this method returns None. It's implemented to satisfy the TrainerBase
abstract method requirement if it exists.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create data loader for training.</span>

<span class="sd">    NOTE: For Unsloth GRPO, data loading is handled by TRL&#39;s GRPOTrainer,</span>
<span class="sd">    so this method returns None. It&#39;s implemented to satisfy the TrainerBase</span>
<span class="sd">    abstract method requirement if it exists.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This method might be required by TrainerBase but not used in Unsloth GRPO</span>
    <span class="c1"># because TRL&#39;s GRPOTrainer handles data loading internally</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
        <span class="s2">&quot;create_data_loader() called but Unsloth GRPO uses TRL&#39;s internal data loading&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="n">use_custom_evaluator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>GRPO-specific evaluation - auto-setup evaluators and delegate to parent.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metric_key_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span><span class="p">,</span>
    <span class="n">use_custom_evaluator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GRPO-specific evaluation - auto-setup evaluators and delegate to parent.&quot;&quot;&quot;</span>

    <span class="c1"># Auto-setup evaluators on first call</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_evaluator</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_evaluator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Auto-initializing evaluators for first evaluation...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_custom_evaluator</span><span class="p">(</span><span class="n">evaluator_type</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

    <span class="c1"># Call parent&#39;s unified evaluate method</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
        <span class="n">metric_key_prefix</span><span class="o">=</span><span class="n">metric_key_prefix</span><span class="p">,</span>
        <span class="n">use_custom_evaluator</span><span class="o">=</span><span class="n">use_custom_evaluator</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.is_available" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_available</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.is_available" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Check if Unsloth and TRL are available.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_available</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if Unsloth and TRL are available.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.load_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.load_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a trained GRPO model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a trained GRPO model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading Unsloth GRPO model from: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

        <span class="c1"># Handle both dict and object config</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

        <span class="c1"># Load model and tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the trained GRPO model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the trained GRPO model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_path</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                   <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                   <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                               <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

        <span class="n">save_path</span> <span class="o">=</span> <span class="n">path</span> <span class="ow">or</span> <span class="n">default_path</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving Unsloth GRPO model to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Save using Unsloth&#39;s optimized saving</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="c1"># Save training configuration</span>
        <span class="n">config_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;grpo_training_config.yaml&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;to_dict&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GRPO model saved successfully to: </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">save_path</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to save GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets - compatible with base trainer interface.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets - compatible with base trainer interface.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_dataset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_dataset" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_dataset</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_dataset" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup datasets for GRPO training using unified DataManager.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup datasets for GRPO training using unified DataManager.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up GRPO datasets with DataManager...&quot;</span><span class="p">)</span>

    <span class="c1"># Extract dataset configuration</span>
    <span class="n">dataset_config</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dataset_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No dataset configuration found&quot;</span><span class="p">)</span>

    <span class="c1"># Extract parameters</span>
    <span class="n">dataset_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;imdb&#39;</span><span class="p">)</span>
    <span class="n">split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">config_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;config_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">system_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;system_prompt&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">enable_thinking</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;enable_thinking&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Advanced DataManager features</span>
    <span class="n">column_mapping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;column_mapping&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">processing_batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;processing_batched&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
        <span class="n">dataset_config</span><span class="p">,</span> <span class="s1">&#39;max_samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2"> (split: </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">, config: </span><span class="si">{</span><span class="n">config_name</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize DataManager for GRPO task</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.data.manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataManager</span>

    <span class="c1"># Columns to preserve for reward computation (test cases, solutions,</span>
    <span class="c1"># etc.)</span>
    <span class="n">preserve_columns</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;test_list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;test&#39;</span><span class="p">,</span>
        <span class="s1">&#39;answer&#39;</span><span class="p">,</span>
        <span class="s1">&#39;solution&#39;</span><span class="p">,</span>
        <span class="s1">&#39;code&#39;</span><span class="p">,</span>
        <span class="s1">&#39;canonical_solution&#39;</span><span class="p">}</span>

    <span class="n">manager</span> <span class="o">=</span> <span class="n">DataManager</span><span class="p">(</span>
        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;grpo&quot;</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
        <span class="n">column_mapping</span><span class="o">=</span><span class="n">column_mapping</span><span class="p">,</span>
        <span class="n">processing_fn</span><span class="o">=</span><span class="n">processing_fn</span><span class="p">,</span>
        <span class="n">processing_batched</span><span class="o">=</span><span class="n">processing_batched</span><span class="p">,</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span><span class="p">,</span> 
        <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>              <span class="c1">#  ADD THIS - Pass tokenizer for chat template</span>
        <span class="n">enable_thinking</span><span class="o">=</span><span class="n">enable_thinking</span><span class="p">,</span> 
    <span class="p">)</span>

    <span class="c1"># Load dataset - DataManager handles all the complexity</span>
    <span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
        <span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">config_name</span><span class="o">=</span><span class="n">config_name</span><span class="p">,</span>
        <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
        <span class="n">max_samples</span><span class="o">=</span><span class="n">max_samples</span>
    <span class="p">)</span>

    <span class="c1"># Extract train and validation splits</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">dataset_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_dict</span> <span class="o">=</span> <span class="n">dataset_dict</span> 


    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Dataset loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> train examples&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Evaluation dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> examples&quot;</span><span class="p">)</span>

    <span class="c1"># Log sample</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">prompt_col</span> <span class="o">=</span> <span class="s2">&quot;prompt&quot;</span> <span class="k">if</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="n">sample</span> <span class="k">else</span> <span class="s2">&quot;query&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Sample prompt (first 100 chars): </span><span class="si">{</span><span class="n">sample</span><span class="p">[</span><span class="n">prompt_col</span><span class="p">][:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup Unsloth-optimized model and tokenizer for GRPO.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup Unsloth-optimized model and tokenizer for GRPO.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>

        <span class="c1"># Handle both dict and object config</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;name_or_path&#39;</span><span class="p">)</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
            <span class="n">quantization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
            <span class="n">quantization</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;quantization&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting up Unsloth GRPO model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Configure Unsloth model parameters</span>
        <span class="c1"># Unsloth only accepts: max_seq_length, dtype, and load_in_4bit</span>
        <span class="c1"># Other quantization params are NOT passed to from_pretrained</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device_map</span> <span class="ow">or</span> <span class="s1">&#39;auto&#39;</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="n">max_seq_length</span><span class="p">,</span>
            <span class="c1"># Auto-detect (Unsloth will use bfloat16 automatically)</span>
            <span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;load_in_4bit&quot;</span><span class="p">:</span> <span class="n">quantization</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_in_4bit&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">quantization</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model with kwargs: </span><span class="si">{</span><span class="n">model_kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load model with Unsloth optimizations</span>
        <span class="c1"># NOTE: Unsloth handles all quantization internally - don&#39;t pass</span>
        <span class="c1"># bnb_4bit params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>

        <span class="c1"># Set pad token if not present</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

        <span class="c1"># Configure model for GRPO training with LoRA (use config values)</span>
        <span class="c1"># NOTE: AlignTune configs may be dataclasses or dicts depending on how the trainer was created.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">use_peft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_peft&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">lora_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_r&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
            <span class="n">lora_alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_alpha&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">lora_r</span><span class="p">)))</span>
            <span class="n">lora_dropout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_dropout&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;lora_target_modules&quot;</span><span class="p">,</span>
                <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">use_peft</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;use_peft&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">lora_r</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lora_r&quot;</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
            <span class="n">lora_alpha</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lora_alpha&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">lora_r</span><span class="p">)))</span>
            <span class="n">lora_dropout</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;lora_dropout&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">target_modules</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s2">&quot;lora_target_modules&quot;</span><span class="p">,</span>
                <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">use_peft</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">r</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">lora_r</span><span class="p">),</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">lora_alpha</span><span class="p">),</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">lora_dropout</span><span class="p">),</span>
                <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
                <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="s2">&quot;unsloth&quot;</span> <span class="k">if</span> <span class="n">gradient_checkpointing</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>
                <span class="n">use_rslora</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">loftq_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Unsloth GRPO model setup completed successfully&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup Unsloth GRPO model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_rewards" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_rewards</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_rewards" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup reward functions using the centralized registry system.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup reward functions using the centralized registry system.&quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up reward functions for GRPO...&quot;</span><span class="p">)</span>

    <span class="c1"># Get reward configurations</span>
    <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;rewards&#39;</span><span class="p">):</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">rewards_config</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;No reward configurations found, using default rewards&quot;</span><span class="p">)</span>
        <span class="n">rewards_config</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;length&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;min_length&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}},</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentiment&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;positive_weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}},</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;safety&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}},</span> <span class="p">{</span>
                            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;diversity&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">{</span>
                                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}},</span> <span class="p">]</span>

    <span class="c1"># Load reward functions from the registry</span>
    <span class="k">for</span> <span class="n">reward_config</span> <span class="ow">in</span> <span class="n">rewards_config</span><span class="p">:</span>
        <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;length&#39;</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">reward_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="p">{})</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1">#  SPECIAL CASE: custom reward function passed directly</span>
            <span class="k">if</span> <span class="n">reward_type</span> <span class="o">==</span> <span class="s1">&#39;custom&#39;</span> <span class="ow">and</span> <span class="s1">&#39;reward_function&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="n">reward_func</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;reward_function&#39;</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot; Loaded custom reward function (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="c1"># Store directly - no registry needed</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                    <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;custom&quot;</span>
                <span class="p">})</span>
                <span class="k">continue</span>  <span class="c1"># Skip registry lookup</span>

            <span class="c1"># Use the rewards registry to get reward functions</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardRegistry</span> <span class="k">as</span> <span class="n">RewardsRegistry</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.rewards.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">RewardConfig</span><span class="p">,</span> <span class="n">RewardType</span>

            <span class="c1"># Map common variations to standard names</span>
            <span class="n">reward_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;math&#39;</span><span class="p">:</span> <span class="s1">&#39;math_reasoning&#39;</span><span class="p">,</span>
                <span class="s1">&#39;code&#39;</span><span class="p">:</span> <span class="s1">&#39;code_quality&#39;</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">reward_type</span> <span class="o">=</span> <span class="n">reward_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_type</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Convert reward type string to enum</span>
                <span class="n">reward_type_enum</span> <span class="o">=</span> <span class="n">RewardType</span><span class="p">[</span><span class="n">reward_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>

                <span class="c1"># Create RewardConfig with weight and params</span>
                <span class="n">reward_cfg</span> <span class="o">=</span> <span class="n">RewardConfig</span><span class="p">(</span>
                    <span class="n">reward_type</span><span class="o">=</span><span class="n">reward_type_enum</span><span class="p">,</span>
                    <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Weight will be applied separately</span>
                    <span class="n">params</span><span class="o">=</span><span class="n">params</span>
                <span class="p">)</span>

                <span class="c1"># Get reward function from registry</span>
                <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                    <span class="n">reward_type</span><span class="p">,</span> <span class="n">reward_cfg</span><span class="p">)</span>
                <span class="c1"># Extract the callable compute method</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot; Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward from registry (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                <span class="c1"># Reward type not in enum, try registry by name</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Reward type &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; not in RewardType enum, trying registry by name&quot;</span><span class="p">)</span>
                <span class="n">reward_func_obj</span> <span class="o">=</span> <span class="n">RewardsRegistry</span><span class="o">.</span><span class="n">get_reward_function</span><span class="p">(</span>
                    <span class="n">reward_type</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">,</span> <span class="s1">&#39;compute&#39;</span><span class="p">):</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span><span class="o">.</span><span class="n">compute</span>
                <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reward_func_obj</span><span class="p">):</span>
                    <span class="n">reward_func</span> <span class="o">=</span> <span class="n">reward_func_obj</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39; is not callable, skipping&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot; Loaded </span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2"> reward by name (weight: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

            <span class="c1"># Store reward function with metadata</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">reward_func</span><span class="p">,</span>
                <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">weight</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">reward_type</span>
            <span class="p">})</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Failed to load reward function &#39;</span><span class="si">{</span><span class="n">reward_type</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error details:&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">continue</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
            <span class="s2">&quot;No reward functions were loaded! Adding a simple default length reward.&quot;</span><span class="p">)</span>
        <span class="c1"># Add a simple fallback reward so training doesn&#39;t fail</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">default_length_reward</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">length</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">length</span> <span class="o">/</span> <span class="mf">20.0</span> <span class="o">*</span> <span class="mf">0.5</span>
            <span class="k">elif</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mf">200.0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">1.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="n">default_length_reward</span><span class="p">,</span>
            <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;default_length&quot;</span>
        <span class="p">})</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added default length reward as fallback&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot; Configured </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions successfully&quot;</span><span class="p">)</span>

    <span class="c1"># Log summary of loaded rewards</span>
    <span class="n">reward_summary</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">rf</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">rf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">])</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reward functions: </span><span class="si">{</span><span class="n">reward_summary</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_trainer</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.setup_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup TRL GRPOTrainer with Unsloth model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup TRL GRPOTrainer with Unsloth model.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRPOTrainer</span><span class="p">,</span> <span class="n">GRPOConfig</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting up TRL GRPOTrainer with Unsloth model&quot;</span><span class="p">)</span>

        <span class="c1"># Handle both dict and object config</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                 <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                             <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-4</span><span class="p">)</span>
            <span class="n">save_interval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
            <span class="n">eval_interval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
            <span class="n">kl_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="n">cliprange</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_epochs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_batch_size&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-4</span><span class="p">)</span>
            <span class="n">save_interval</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
            <span class="n">eval_interval</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_interval&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
            <span class="n">kl_coef</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="n">cliprange</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>

        <span class="c1"># Get max sequence length from model config</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

        <span class="c1"># CRITICAL: Calculate max_prompt_length and max_completion_length</span>
        <span class="n">max_prompt_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_seq_length</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>  <span class="c1"># 60% for prompt</span>
        <span class="n">max_completion_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
            <span class="n">max_seq_length</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">)</span>  <span class="c1"># 40% for completion</span>

        <span class="c1"># Determine evaluation and save strategy based on eval_dataset</span>
        <span class="n">has_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="c1"># Set save strategy</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="s2">&quot;steps&quot;</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.precision_handler</span><span class="w"> </span><span class="kn">import</span> <span class="n">PrecisionHandler</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_precision_from_config</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">validate_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>
        <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">log_precision_info</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="s2">&quot;GRPO (Unsloth)&quot;</span><span class="p">)</span>
        <span class="n">precision_args</span> <span class="o">=</span> <span class="n">PrecisionHandler</span><span class="o">.</span><span class="n">get_training_args_precision</span><span class="p">(</span>
            <span class="n">precision</span><span class="p">)</span>
        <span class="c1"># Evaluation parameters</span>
        <span class="n">eval_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;eval_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;per_device_eval_batch_size&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>
        <span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;metric_for_best_model&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;greater_is_better&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">load_best_model_at_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;load_best_model_at_end&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Adjust eval strategy based on eval_dataset availability</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span> <span class="k">if</span> <span class="n">eval_strategy</span> <span class="o">!=</span> <span class="s1">&#39;no&#39;</span> <span class="k">else</span> <span class="s1">&#39;epoch&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eval_strategy</span> <span class="o">=</span> <span class="s1">&#39;no&#39;</span>
            <span class="n">eval_steps</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Logging parameters</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">logging_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;logging_strategy&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
        <span class="n">save_total_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;save_total_limit&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Report to</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;report_to&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">loggers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loggers</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;loggers&#39;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="n">loggers</span> <span class="ow">and</span> <span class="n">report_to</span> <span class="o">==</span> <span class="s1">&#39;none&#39;</span><span class="p">:</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="n">loggers</span>

        <span class="c1"># Run name</span>
        <span class="n">run_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="s1">&#39;run_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;unsloth_grpo&#39;</span><span class="p">)</span>

        <span class="c1"># Optimizer parameters</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;adamw_torch&#39;</span><span class="p">)</span>
        <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;lr_scheduler&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>
        <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_ratio&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

        <span class="c1"># Additional training parameters</span>
        <span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
            <span class="s1">&#39;use_gradient_checkpointing&#39;</span><span class="p">,</span>
            <span class="s1">&#39;gradient_checkpointing&#39;</span><span class="p">,</span>
            <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">group_by_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;group_by_length&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">data_seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;data_seed&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">47</span><span class="p">)</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s2">&quot;max_steps&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>

        <span class="c1"># GRPO specific parameters</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;kl_coef&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">kl_coef</span><span class="p">)</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">,</span> <span class="s1">&#39;cliprange&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">cliprange</span><span class="p">)</span>
        <span class="n">loss_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;loss_type&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
        <span class="n">scale_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;scale_rewards&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;group&#39;</span><span class="p">)</span>
        <span class="n">mask_truncated_completions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;mask_truncated_completions&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">top_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;top_p&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">num_generations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;num_generations&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">)</span>
        <span class="c1"># TRL GRPOConfig supports GRPO variants: &quot;grpo&quot;, &quot;dapo&quot;, &quot;dr_grpo&quot;</span>
        <span class="n">VALID_GRPO_LOSS_TYPES</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;grpo&quot;</span><span class="p">,</span> <span class="s2">&quot;dapo&quot;</span><span class="p">,</span> <span class="s2">&quot;dr_grpo&quot;</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">loss_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss_type</span> <span class="o">=</span> <span class="s2">&quot;grpo&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">loss_type</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="c1"># &quot;sigmoid&quot; is a DPO loss type, not valid for GRPO - raise error</span>
        <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;loss_type=&#39;sigmoid&#39; is a DPO/IPO loss type and is not valid for GRPO training. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Valid GRPO loss types are: </span><span class="si">{</span><span class="n">VALID_GRPO_LOSS_TYPES</span><span class="si">}</span><span class="s2"> use grpo&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">loss_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">VALID_GRPO_LOSS_TYPES</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unknown loss_type=&#39;</span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s2">&#39; for GRPO. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Valid GRPO loss types are: </span><span class="si">{</span><span class="n">VALID_GRPO_LOSS_TYPES</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Adjust save strategy to save on epoch</span>
        <span class="n">save_strategy</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="k">else</span> <span class="s2">&quot;steps&quot;</span>

        <span class="c1"># Create GRPO configuration</span>
        <span class="n">grpo_config</span> <span class="o">=</span> <span class="n">GRPOConfig</span><span class="p">(</span>
            <span class="c1"># Output and logging</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="n">logging_steps</span><span class="p">,</span>
            <span class="n">logging_strategy</span><span class="o">=</span><span class="n">logging_strategy</span><span class="p">,</span>
            <span class="n">report_to</span><span class="o">=</span><span class="n">report_to</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="c1"># Evaluation</span>
            <span class="n">eval_strategy</span><span class="o">=</span><span class="n">eval_strategy</span><span class="p">,</span>
            <span class="n">eval_steps</span><span class="o">=</span><span class="n">eval_steps</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
            <span class="n">metric_for_best_model</span><span class="o">=</span><span class="n">metric_for_best_model</span><span class="p">,</span>
            <span class="n">greater_is_better</span><span class="o">=</span><span class="n">greater_is_better</span><span class="p">,</span>
            <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="n">load_best_model_at_end</span><span class="p">,</span>

            <span class="c1"># Checkpointing</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="n">save_interval</span><span class="p">,</span>
            <span class="n">save_strategy</span><span class="o">=</span><span class="n">save_strategy</span><span class="p">,</span>
            <span class="n">save_total_limit</span><span class="o">=</span><span class="n">save_total_limit</span><span class="p">,</span>

            <span class="c1"># Training parameters</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">warmup_ratio</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>

            <span class="c1"># Optimizer and scheduler</span>
            <span class="n">optim</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="n">lr_scheduler_type</span><span class="p">,</span>

            <span class="c1"># GRPO specific parameters</span>
            <span class="n">max_prompt_length</span><span class="o">=</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">max_completion_length</span><span class="o">=</span><span class="n">max_completion_length</span><span class="p">,</span>
            <span class="n">num_generations</span><span class="o">=</span><span class="n">num_generations</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
            <span class="n">loss_type</span><span class="o">=</span><span class="n">loss_type</span><span class="p">,</span>
            <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
            <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span>
            <span class="n">scale_rewards</span><span class="o">=</span><span class="n">scale_rewards</span><span class="p">,</span>
            <span class="n">mask_truncated_completions</span><span class="o">=</span><span class="n">mask_truncated_completions</span><span class="p">,</span>

            <span class="c1"># Seeds</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">data_seed</span><span class="o">=</span><span class="n">data_seed</span><span class="p">,</span>

            <span class="c1"># Performance</span>
            <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="n">gradient_checkpointing</span><span class="p">,</span>
            <span class="n">group_by_length</span><span class="o">=</span><span class="n">group_by_length</span><span class="p">,</span>
            <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

            <span class="c1"># Precision</span>
            <span class="o">**</span><span class="n">precision_args</span><span class="p">,</span>

            <span class="c1"># Other settings</span>
            <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">missing</span> <span class="o">=</span> <span class="n">extract_extra_and_missing_params</span><span class="p">(</span>
            <span class="n">backend_config</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;grpo&#39;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">missing</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">grpo_config</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="c1"># Rest of your code stays the same...</span>

        <span class="c1"># Get max_seq_length for text truncation in reward functions</span>
        <span class="c1"># Use conservative limit: most reward models (e.g., toxic-bert) have max_length=512</span>
        <span class="c1"># Truncate to min(512, model_max_seq_length) to prevent tensor</span>
        <span class="c1"># shape mismatches</span>
        <span class="n">model_max_seq_length</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># Default</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">model_max_seq_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model_max_seq_length</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="c1"># Use conservative 512 limit for reward functions (most reward</span>
        <span class="c1"># models expect this)</span>
        <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">model_max_seq_length</span><span class="p">)</span>

        <span class="c1"># # Create trainer with reward functions</span>
        <span class="c1"># self.trainer = GRPOTrainer(</span>
        <span class="c1">#     model=self.model,</span>
        <span class="c1">#     tokenizer=self.tokenizer,</span>
        <span class="c1">#     train_dataset=self.train_dataset,</span>
        <span class="c1">#     eval_dataset=self.eval_dataset,</span>
        <span class="c1">#     args=grpo_config,</span>
        <span class="c1">#     reward_funcs=self._combined_reward_function if self.reward_functions else None,</span>
        <span class="c1"># )</span>
        <span class="c1"># # Create GRPO trainer</span>

        <span class="n">use_rewards_directly</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> 
            <span class="s1">&#39;use_rewards_directly&#39;</span><span class="p">,</span> 
            <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">use_rewards_directly</span><span class="p">:</span>
            <span class="c1"># Use functions directly (no wrapper)</span>
            <span class="n">reward_funcs</span> <span class="o">=</span> <span class="n">use_rewards_directly</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Using </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">)</span><span class="si">}</span><span class="s2"> reward functions DIRECTLY&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use combined wrapper (default)</span>
            <span class="n">reward_funcs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combined_reward_function</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; Using _combined_reward_function wrapper&quot;</span><span class="p">)</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
        <span class="n">should_use_pure_trl</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PURE_TRL_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span>

        <span class="k">if</span> <span class="n">should_use_pure_trl</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;PURE_TRL_MODE enabled - using pure TRL API&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">reward_funcs</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span><span class="w"> </span><span class="nn">unsloth</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Detected Unsloth environment&quot;</span><span class="p">)</span>

                <span class="c1"># Unsloth expects a list of functions</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="c1"># Already a list (direct mode)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Passing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">)</span><span class="si">}</span><span class="s2"> functions directly&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                        <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>  <span class="c1"># List of functions</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Single function (wrapper mode) - wrap it for Unsloth</span>
                    <span class="c1"># logger.info(&quot;Wrapping _combined_reward_function for Unsloth&quot;)</span>
                    <span class="c1"># def unsloth_reward_wrapper(prompts=None, completions=None, **kwargs):</span>
                    <span class="c1">#     if completions is None:</span>
                    <span class="c1">#         return [0.0] * (len(prompts) if prompts else 1)</span>
                    <span class="c1">#     return reward_funcs(completions, **kwargs)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                        <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>  <span class="c1"># List with wrapper</span>
                    <span class="p">)</span>

            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using pure TRL (no Unsloth)&quot;</span><span class="p">)</span>

                <span class="c1"># Pure TRL can accept either format</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_funcs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="c1"># Direct mode: pass list as-is</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                        <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">reward_funcs</span><span class="o">=</span><span class="n">reward_funcs</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Wrapper mode: wrap in list</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">GRPOTrainer</span><span class="p">(</span>
                        <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">args</span><span class="o">=</span><span class="n">grpo_config</span><span class="p">,</span>
                        <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">processing_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">reward_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">reward_funcs</span><span class="p">],</span>  <span class="c1"># Wrap single function in list</span>
                    <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;GRPO trainer setup completed successfully!&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TRL GRPOTrainer setup completed&quot;</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to setup GRPO trainer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute GRPO training with Unsloth optimizations.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute GRPO training with Unsloth optimizations.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting Unsloth GRPO training&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Setup components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="n">use_rewards_directly</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_value</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;use_rewards_directly&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_rewards_directly</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_rewards</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping setup_rewards() - using reward functions directly from config&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_trainer</span><span class="p">()</span>

        <span class="c1"># Start training</span>
        <span class="n">training_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Get output directory</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_dir</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="p">,</span>
                                 <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;./output/grpo&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                                                             <span class="s1">&#39;logging&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;./output/grpo&#39;</span>

        <span class="c1"># Save model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

        <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

        <span class="c1"># Compile results</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;training_time&quot;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
            <span class="s2">&quot;final_loss&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">training_result</span><span class="p">,</span>
                <span class="s1">&#39;training_loss&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s2">&quot;total_steps&quot;</span><span class="p">:</span> <span class="n">training_result</span><span class="o">.</span><span class="n">global_step</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">training_result</span><span class="p">,</span>
                <span class="s1">&#39;global_step&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;model_path&quot;</span><span class="p">:</span> <span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;training_history&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
            <span class="s2">&quot;num_reward_functions&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_functions</span><span class="p">),</span>
            <span class="s2">&quot;num_datasets&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">datasets</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                    <span class="s1">&#39;datasets&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unsloth GRPO training completed in </span><span class="si">{</span>
<span class="w">                </span><span class="n">training_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">training_result</span><span class="p">,</span> <span class="s1">&#39;training_loss&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final loss: </span><span class="si">{</span><span class="n">training_result</span><span class="o">.</span><span class="n">training_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GRPO training failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.train_step" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></code>

<a href="#backends.unsloth.rl.grpo.grpo.UnslothGRPOTrainer.train_step" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Execute a single training step.</p>
<p>NOTE: For Unsloth GRPO, the actual training is handled by TRL's GRPOTrainer,
so this method is not used during training. It's implemented to satisfy
the TrainerBase abstract method requirement.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/unsloth/rl/grpo/grpo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Execute a single training step.</span>

<span class="sd">    NOTE: For Unsloth GRPO, the actual training is handled by TRL&#39;s GRPOTrainer,</span>
<span class="sd">    so this method is not used during training. It&#39;s implemented to satisfy</span>
<span class="sd">    the TrainerBase abstract method requirement.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This method is required by TrainerBase but not used in Unsloth GRPO</span>
    <span class="c1"># because TRL&#39;s GRPOTrainer handles the training loop internally</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
        <span class="s2">&quot;train_step() called but Unsloth GRPO uses TRL&#39;s internal training loop&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<hr />
<h2 id="specialized-trainers">Specialized Trainers<a class="headerlink" href="#specialized-trainers" title="Permanent link">&para;</a></h2>
<h3 id="classificationtrainer"><code>ClassificationTrainer</code><a class="headerlink" href="#classificationtrainer" title="Permanent link">&para;</a></h3>
<p>Specialized trainer for text classification tasks.</p>


<div class="doc doc-object doc-class">



<a id="backends.trl.sft.Classification_trainer.ClassificationTrainer"></a>
    <div class="doc doc-contents first">



        <p>Complete Classification Trainer for text and token classification.</p>
<p>Supports:
- Text Classification (sentiment, topic classification, etc.)
- Token Classification (NER, POS tagging, etc.)</p>
<p>Uses standard Transformers Trainer (NOT TRL) for proper classification.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ClassificationTrainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Complete Classification Trainer for text and token classification.</span>

<span class="sd">    Supports:</span>
<span class="sd">    - Text Classification (sentiment, topic classification, etc.)</span>
<span class="sd">    - Token Classification (NER, POS tagging, etc.)</span>

<span class="sd">    Uses standard Transformers Trainer (NOT TRL) for proper classification.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize trainer with config.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task_type</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; ClassificationTrainer initialized for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; ClassificationTrainer initialized for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model and tokenizer based on task type.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskType</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Add padding token if missing</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>

        <span class="c1"># Ensure pad_token_id is set (required for data collator batching)</span>
        <span class="c1"># For Llama and similar tokenizers, we need to set it on both tokenizer and config</span>
        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>

        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># If pad_token was added, get its ID from the tokenizer</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>  <span class="c1"># If it&#39;s the unk token, use eos instead</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="c1"># Fallback: use eos_token_id if available</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not get pad_token_id from tokenizer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set pad_token_id on tokenizer (multiple ways to ensure it sticks)</span>
        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Set directly on tokenizer</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
            <span class="c1"># Also set on tokenizer&#39;s special_tokens_map if it exists</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;special_tokens_map&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="s1">&#39;pad_token&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">special_tokens_map</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">special_tokens_map</span><span class="p">[</span><span class="s1">&#39;pad_token&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span>
            <span class="c1"># Set on tokenizer config if it exists</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;init_kwargs&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39;pad_token_id&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">init_kwargs</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">init_kwargs</span><span class="p">[</span><span class="s1">&#39;pad_token_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pad_token_id</span>
            <span class="c1"># Also try setting via __setattr__ to ensure it persists</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>

        <span class="c1"># Final check: ensure pad_token_id is set (critical for batching)</span>
        <span class="n">final_pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">final_pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;pad_token_id is still None after setup! This will cause batching errors.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_token_id must be set for batching. Tokenizer configuration issue.&quot;</span><span class="p">)</span>

        <span class="c1"># Determine precision and quantization settings</span>
        <span class="n">use_8bit</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">torch_dtype</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">device_map</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>  <span class="c1"># Keep on CPU initially</span>

        <span class="c1"># Check if precision is set and configure accordingly</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">:</span>
            <span class="n">precision_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">precision_value</span> <span class="o">==</span> <span class="s2">&quot;bf16&quot;</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">():</span>
                <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
            <span class="k">elif</span> <span class="n">precision_value</span> <span class="o">==</span> <span class="s2">&quot;fp16&quot;</span><span class="p">:</span>
                <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>

        <span class="c1"># For 4B+ models, use lower precision dtype to reduce memory</span>
        <span class="c1"># NOTE: 8-bit quantization (BitsAndBytes) requires PEFT adapters for fine-tuning</span>
        <span class="c1"># Since we&#39;re not using PEFT for classification, we skip 8-bit quantization</span>
        <span class="c1"># and rely on BF16/FP16 precision instead</span>
        <span class="n">model_size_estimate</span> <span class="o">=</span> <span class="s2">&quot;4B&quot;</span> <span class="k">if</span> <span class="s2">&quot;4B&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span> <span class="ow">or</span> <span class="s2">&quot;4b&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;unknown&quot;</span>
        <span class="n">use_8bit</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Disable 8-bit quantization for classification (requires PEFT)</span>
        <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Ensure we use lower precision dtype for 4B models</span>
        <span class="k">if</span> <span class="n">torch_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="c1"># Default to BF16 if supported, else FP16</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">():</span>
                <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using BF16 precision for 4B model to reduce memory usage (8-bit quantization disabled - requires PEFT)&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP16 precision for 4B model to reduce memory usage (8-bit quantization disabled - requires PEFT)&quot;</span><span class="p">)</span>

        <span class="c1"># Load appropriate model based on task</span>
        <span class="c1"># Load on CPU first with appropriate precision/quantization to avoid OOM</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;num_labels&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="s2">&quot;ignore_mismatched_sizes&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>  <span class="c1"># Keep on CPU</span>
            <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">torch_dtype</span> <span class="k">if</span> <span class="n">torch_dtype</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">}</span>

        <span class="c1"># Add quantization config if using 8-bit</span>
        <span class="k">if</span> <span class="n">use_8bit</span> <span class="ow">and</span> <span class="n">quantization_config</span><span class="p">:</span>
            <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;quantization_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>

        <span class="c1"># Remove None values</span>
        <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded AutoModelForSequenceClassification with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># TOKEN_CLASSIFICATION</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
                <span class="o">**</span><span class="n">model_kwargs</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded AutoModelForTokenClassification with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>

        <span class="c1"># Ensure model stays on CPU (device_map should handle this, but double-check)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_8bit</span><span class="p">:</span>  <span class="c1"># 8-bit models handle device_map automatically</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Only move to CPU if not already there and not using device_map</span>
                <span class="n">current_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
                <span class="k">if</span> <span class="n">current_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model moved to CPU to avoid OOM during setup&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model already on CPU (via device_map)&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">move_error</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not verify/move model to CPU: </span><span class="si">{</span><span class="n">move_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Resize token embeddings if we added tokens</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>

        <span class="c1"># CRITICAL: Set pad_token_id on model config (required for DataCollatorWithPadding)</span>
        <span class="c1"># This is often the missing piece that causes &quot;Cannot handle batch sizes &gt; 1&quot; errors</span>
        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
            <span class="c1"># Also try setting on model.config if it&#39;s a dict-like object</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Set model.config.pad_token_id = </span><span class="si">{</span><span class="n">pad_token_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Enable gradient checkpointing to reduce memory usage (helps with OOM)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_enable&#39;</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Gradient checkpointing enabled to reduce memory usage&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not enable gradient checkpointing: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Apply PEFT (LoRA) if enabled</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">peft_enabled</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

            <span class="c1"># Get target modules from config or auto-detect</span>
            <span class="n">target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">target_modules</span>
            <span class="k">if</span> <span class="n">target_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Auto-detect based on model architecture</span>
                <span class="k">if</span> <span class="s2">&quot;distilbert&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_lin&quot;</span><span class="p">,</span> <span class="s2">&quot;k_lin&quot;</span><span class="p">,</span> <span class="s2">&quot;v_lin&quot;</span><span class="p">,</span> <span class="s2">&quot;out_lin&quot;</span><span class="p">]</span>
                <span class="k">elif</span> <span class="s2">&quot;bert&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">]</span>
                <span class="k">elif</span> <span class="s2">&quot;roberta&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Auto-detected target modules: </span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Create PEFT config</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lora_rank</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;SEQ_CLS&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span> <span class="k">else</span> <span class="s2">&quot;TOKEN_CLS&quot;</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span>
            <span class="p">)</span>

            <span class="c1"># Apply PEFT</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model loaded successfully&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load and prepare dataset.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskType</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load dataset with trust_remote_code for compatibility</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">,</span>
                    <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                    <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                    <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load dataset with trust_remote_code: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Fallback without trust_remote_code</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">,</span>
                    <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span>
                <span class="p">)</span>

        <span class="c1"># Limit samples if specified</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_samples</span><span class="p">))</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Limited dataset to </span><span class="si">{</span><span class="n">max_samples</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

        <span class="c1"># Apply column mapping if provided (must be done before splitting)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applying column mapping: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># Rename columns: old_name -&gt; new_name</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Split into train/eval (90/10)</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
        <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">split</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>

        <span class="c1"># Tokenize based on task type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Tokenize text classification data.&quot;&quot;&quot;</span>
                <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                    <span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">text_column</span><span class="p">],</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
                <span class="p">)</span>
                <span class="c1"># Get labels and convert to 0-indexed if needed (PyTorch expects 0-indexed)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">label_column</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">min_label</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">min_label</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># Labels are 1-indexed, convert to 0-indexed</span>
                        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
                <span class="n">result</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
                <span class="k">return</span> <span class="n">result</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># TOKEN_CLASSIFICATION</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;Tokenize token classification data with label alignment.&quot;&quot;&quot;</span>
                <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                    <span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokens_column</span><span class="p">],</span>
                    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
                <span class="p">)</span>

                <span class="c1"># Align labels with tokens</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tags_column</span><span class="p">]):</span>
                    <span class="n">word_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">word_ids</span><span class="p">(</span><span class="n">batch_index</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">label_ids</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="kc">None</span>

                    <span class="k">for</span> <span class="n">word_idx</span> <span class="ow">in</span> <span class="n">word_ids</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">word_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="c1"># Special tokens get -100</span>
                            <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">word_idx</span> <span class="o">!=</span> <span class="n">previous_word_idx</span><span class="p">:</span>
                            <span class="c1"># First token of a word gets the label</span>
                            <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">word_idx</span><span class="p">])</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Other tokens of the same word get -100</span>
                            <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
                        <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="n">word_idx</span>

                    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

                <span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
                <span class="k">return</span> <span class="n">tokenized</span>

        <span class="c1"># Apply tokenization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">tokenize_function</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">tokenize_function</span><span class="p">,</span>
            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">remove_columns</span><span class="o">=</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span>
        <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Dataset loaded - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup_training</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup trainer with appropriate settings.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskType</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Configuring trainer...&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Configuring trainer...&quot;</span><span class="p">)</span>

        <span class="c1"># Clear GPU cache before creating trainer to avoid OOM errors</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">cache_error</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not clear GPU cache: </span><span class="si">{</span><span class="n">cache_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Training arguments</span>
        <span class="c1"># For quick testing: use max_steps=10, then revert to full training</span>
        <span class="n">max_steps_for_testing</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Set to None for full training, or 10 for quick testing</span>
        <span class="n">training_args_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="s2">&quot;run_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="p">,</span>
            <span class="s2">&quot;per_device_train_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="s2">&quot;per_device_eval_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="s2">&quot;warmup_ratio&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">,</span>
            <span class="s2">&quot;eval_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;eval_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span><span class="p">,</span>
            <span class="s2">&quot;save_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;save_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval</span><span class="p">,</span>
            <span class="s2">&quot;load_best_model_at_end&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">load_best_model_at_end</span><span class="p">,</span>
            <span class="s2">&quot;metric_for_best_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">metric_for_best_model</span><span class="p">,</span>
            <span class="s2">&quot;greater_is_better&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">greater_is_better</span><span class="p">,</span>
            <span class="s2">&quot;logging_steps&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
            <span class="s2">&quot;logging_dir&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">/logs&quot;</span><span class="p">,</span>
            <span class="c1"># Use precision from model config, default to BF16 if CUDA supports it (for memory efficiency)</span>
            <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="ow">and</span> 
                    <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="ow">and</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;fp16&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;bf16&quot;</span><span class="p">:</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="ow">and</span> 
                    <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="ow">and</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;bf16&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> 
                    <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()),</span>  <span class="c1"># Auto-enable BF16 if supported</span>
            <span class="s2">&quot;report_to&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>  <span class="c1"># Disable wandb/tensorboard</span>
            <span class="s2">&quot;save_total_limit&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># Keep only 2 checkpoints</span>
            <span class="s2">&quot;push_to_hub&quot;</span><span class="p">:</span> <span class="kc">False</span>
        <span class="p">}</span>

        <span class="c1"># Add gradient_accumulation_steps if specified in config (helps with OOM)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">training_args_dict</span><span class="p">[</span><span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
        <span class="c1"># Set either max_steps (for quick testing) or num_train_epochs (for full training)</span>
        <span class="c1"># Don&#39;t pass num_train_epochs at all when max_steps is set (TrainingArguments doesn&#39;t like both)</span>
        <span class="k">if</span> <span class="n">max_steps_for_testing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">training_args_dict</span><span class="p">[</span><span class="s2">&quot;max_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_steps_for_testing</span>
            <span class="c1"># Don&#39;t include num_train_epochs when max_steps is set</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">training_args_dict</span><span class="p">[</span><span class="s2">&quot;num_train_epochs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span>
            <span class="c1"># Don&#39;t include max_steps when num_train_epochs is set</span>

        <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">**</span><span class="n">training_args_dict</span><span class="p">)</span>

        <span class="c1"># Ensure pad_token_id is set before creating data collator (required for batching)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>  <span class="c1"># Make sure it&#39;s not the unk token</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Fallback: use eos_token_id if available</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="c1"># Fallback: use eos_token_id if available</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not set pad_token_id: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Final check: ensure pad_token_id is set (critical for batching)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;pad_token_id is still None before creating data collator! This will cause batching errors.&quot;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_token_id must be set for batching. Tokenizer configuration issue.&quot;</span><span class="p">)</span>

        <span class="c1"># Choose data collator based on task</span>
        <span class="c1"># Explicitly pass pad_token_id to ensure it&#39;s used</span>
        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_token_id must be set before creating data collator&quot;</span><span class="p">)</span>

        <span class="c1"># Create a wrapper class to ensure pad_token_id is always set before batching</span>
        <span class="k">class</span><span class="w"> </span><span class="nc">SafeDataCollatorWithPadding</span><span class="p">(</span><span class="n">DataCollatorWithPadding</span><span class="p">):</span>
            <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
                <span class="c1"># Ensure pad_token_id is set before batching (critical fix)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># Try to set it from eos_token_id</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="c1"># If still None, try to get it from pad_token</span>
                        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">pad_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">pad_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_id</span>
                                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                            <span class="k">except</span><span class="p">:</span>
                                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="k">class</span><span class="w"> </span><span class="nc">SafeDataCollatorForTokenClassification</span><span class="p">(</span><span class="n">DataCollatorForTokenClassification</span><span class="p">):</span>
            <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
                <span class="c1"># Ensure pad_token_id is set before batching (critical fix)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">pad_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">pad_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_id</span>
                                <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                            <span class="k">except</span><span class="p">:</span>
                                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
            <span class="n">data_collator</span> <span class="o">=</span> <span class="n">SafeDataCollatorWithPadding</span><span class="p">(</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span>  <span class="c1"># Optimize for tensor cores</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># TOKEN_CLASSIFICATION</span>
            <span class="n">data_collator</span> <span class="o">=</span> <span class="n">SafeDataCollatorForTokenClassification</span><span class="p">(</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span>
            <span class="p">)</span>

        <span class="c1"># Compute metrics function</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Compute classification metrics.&quot;&quot;&quot;</span>
            <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># For token classification, flatten and filter</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="c1"># Remove ignored indices (-100)</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

            <span class="c1"># Calculate metrics</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">),</span>
                <span class="s1">&#39;f1&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">}</span>

        <span class="c1"># Clear CUDA cache before creating trainer</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

        <span class="c1"># Create trainer with error handling for OOM</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
                <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
                <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
                <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
            <span class="p">)</span>

        <span class="k">except</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">oom_error</span><span class="p">:</span>
            <span class="c1"># Check if it&#39;s actually an OOM error</span>
            <span class="n">is_oom</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">oom_error</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;out of memory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">oom_error</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">is_oom</span><span class="p">:</span>
                <span class="c1"># Clear cache and try to provide helpful error message</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

                <span class="n">error_msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;CUDA out of memory when creating trainer. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;This usually means other processes are using GPU memory. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Try: (1) Free GPU memory by stopping other processes, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;(2) Reduce batch_size in config, (3) Use a smaller model. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Original error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">oom_error</span><span class="p">)[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">oom_error</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Re-raise if it&#39;s not an OOM error</span>
                <span class="k">raise</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Trainer configured&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Trainer configured successfully&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train the model.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAINING&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_training</span><span class="p">()</span>

        <span class="c1"># Clear CUDA cache before training to avoid OOM</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Cleared CUDA cache before training&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;out of memory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;OOM&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CUDA OOM during training: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> CUDA Out of Memory error during training.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Suggestions:&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Reduce batch_size in your config&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Increase gradient_accumulation_steps to maintain effective batch size&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Reduce max_seq_length&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Use a smaller model&quot;</span><span class="p">)</span>
                <span class="k">raise</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Training completed&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training completed&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">train_result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the model.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EVALUATION&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="c1"># Ensure pad_token is set before evaluation (required for batching)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>

        <span class="c1"># Also ensure pad_token_id is set (critical for batching)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>  <span class="c1"># If it&#39;s the unk token, use eos instead</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="c1"># Fallback: use eos_token_id if available</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not get pad_token_id in evaluate(): </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Set pad_token_id if we found one</span>
            <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>

            <span class="c1"># Final check: ensure pad_token_id is set (critical for batching)</span>
            <span class="n">final_pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">final_pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">error_msg</span> <span class="o">=</span> <span class="s2">&quot;pad_token_id is still None in evaluate()! Cannot handle batch sizes &gt; 1 without padding token.&quot;</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting evaluation...&quot;</span><span class="p">)</span>
        <span class="n">eval_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

        <span class="c1"># Calculate perplexity from loss (if available)</span>
        <span class="k">if</span> <span class="s2">&quot;eval_loss&quot;</span> <span class="ow">in</span> <span class="n">eval_result</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">eval_result</span><span class="p">[</span><span class="s2">&quot;eval_perplexity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eval_result</span><span class="p">[</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not calculate perplexity: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Evaluation Results:&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">eval_result</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation completed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_result</span><span class="p">)</span><span class="si">}</span><span class="s2"> metrics computed&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eval_result</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            output_dir: Directory to save to (defaults to config output_dir)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Path where model was saved</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="si">}</span><span class="s2">/final_model&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_path</span> <span class="o">=</span> <span class="n">output_dir</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Saving model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model saved&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model saved successfully&quot;</span><span class="p">)</span>

        <span class="c1"># Store for push_to_hub</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="o">=</span> <span class="n">save_path</span>

        <span class="k">return</span> <span class="n">save_path</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run complete training experiment.</span>

<span class="sd">        This is the main method that backend_factory calls!</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CLASSIFICATION TRAINING - </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting classification experiment: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Setup</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_training</span><span class="p">()</span>

            <span class="c1"># Train</span>
            <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Evaluate</span>
            <span class="n">eval_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

            <span class="c1"># Save</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

            <span class="c1"># Return complete results</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
                <span class="s1">&#39;eval_results&#39;</span><span class="p">:</span> <span class="n">eval_result</span><span class="p">,</span>
                <span class="s1">&#39;model_path&#39;</span><span class="p">:</span> <span class="n">model_path</span><span class="p">,</span>
                <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">}</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; EXPERIMENT COMPLETE&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Task: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Train Loss: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Eval Accuracy: </span><span class="si">{</span><span class="n">eval_result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_accuracy&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Eval F1: </span><span class="si">{</span><span class="n">eval_result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_f1&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Model: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment completed successfully: </span><span class="si">{</span><span class="n">results</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">results</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize trainer with config.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize trainer with config.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">task_type</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; ClassificationTrainer initialized for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; ClassificationTrainer initialized for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">()</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Evaluate the model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate the model.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EVALUATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># Ensure pad_token is set before evaluation (required for batching)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>

    <span class="c1"># Also ensure pad_token_id is set (critical for batching)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>  <span class="c1"># If it&#39;s the unk token, use eos instead</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="c1"># Fallback: use eos_token_id if available</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not get pad_token_id in evaluate(): </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set pad_token_id if we found one</span>
        <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>

        <span class="c1"># Final check: ensure pad_token_id is set (critical for batching)</span>
        <span class="n">final_pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">final_pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">error_msg</span> <span class="o">=</span> <span class="s2">&quot;pad_token_id is still None in evaluate()! Cannot handle batch sizes &gt; 1 without padding token.&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting evaluation...&quot;</span><span class="p">)</span>
    <span class="n">eval_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

    <span class="c1"># Calculate perplexity from loss (if available)</span>
    <span class="k">if</span> <span class="s2">&quot;eval_loss&quot;</span> <span class="ow">in</span> <span class="n">eval_result</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">eval_result</span><span class="p">[</span><span class="s2">&quot;eval_perplexity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">eval_result</span><span class="p">[</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">])))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not calculate perplexity: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Evaluation Results:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">eval_result</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation completed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_result</span><span class="p">)</span><span class="si">}</span><span class="s2"> metrics computed&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eval_result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.run_experiment" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">run_experiment</span><span class="p">()</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.run_experiment" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Run complete training experiment.</p>
<p>This is the main method that backend_factory calls!</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">run_experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run complete training experiment.</span>

<span class="sd">    This is the main method that backend_factory calls!</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CLASSIFICATION TRAINING - </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting classification experiment: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_training</span><span class="p">()</span>

        <span class="c1"># Train</span>
        <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Evaluate</span>
        <span class="n">eval_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

        <span class="c1"># Save</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

        <span class="c1"># Return complete results</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;task_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
            <span class="s1">&#39;eval_results&#39;</span><span class="p">:</span> <span class="n">eval_result</span><span class="p">,</span>
            <span class="s1">&#39;model_path&#39;</span><span class="p">:</span> <span class="n">model_path</span><span class="p">,</span>
            <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span>
        <span class="p">}</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; EXPERIMENT COMPLETE&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Task: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;task_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Train Loss: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Eval Accuracy: </span><span class="si">{</span><span class="n">eval_result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_accuracy&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Eval F1: </span><span class="si">{</span><span class="n">eval_result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_f1&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Model: </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment completed successfully: </span><span class="si">{</span><span class="n">results</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Experiment failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">raise</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.save_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.save_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the trained model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>output_dir</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory to save to (defaults to config output_dir)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Path where model was saved</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Save the trained model.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_dir: Directory to save to (defaults to config output_dir)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Path where model was saved</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="si">}</span><span class="s2">/final_model&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">output_dir</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Saving model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model saved&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model saved successfully&quot;</span><span class="p">)</span>

    <span class="c1"># Store for push_to_hub</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_last_save_path</span> <span class="o">=</span> <span class="n">save_path</span>

    <span class="k">return</span> <span class="n">save_path</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_data</span><span class="p">()</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_data" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load and prepare dataset.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load and prepare dataset.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskType</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading dataset: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Load dataset with trust_remote_code for compatibility</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
                <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to load dataset with trust_remote_code: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Fallback without trust_remote_code</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">split</span>
            <span class="p">)</span>

    <span class="c1"># Limit samples if specified</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">max_samples</span><span class="p">:</span>
        <span class="n">max_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_samples</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Limited dataset to </span><span class="si">{</span><span class="n">max_samples</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>

    <span class="c1"># Apply column mapping if provided (must be done before splitting)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Applying column mapping: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Rename columns: old_name -&gt; new_name</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">column_mapping</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Split into train/eval (90/10)</span>
    <span class="n">split</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">split</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">split</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>

    <span class="c1"># Tokenize based on task type</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Tokenize text classification data.&quot;&quot;&quot;</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">text_column</span><span class="p">],</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
            <span class="p">)</span>
            <span class="c1"># Get labels and convert to 0-indexed if needed (PyTorch expects 0-indexed)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">label_column</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">min_label</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">min_label</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Labels are 1-indexed, convert to 0-indexed</span>
                    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
            <span class="n">result</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="k">else</span><span class="p">:</span>  <span class="c1"># TOKEN_CLASSIFICATION</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Tokenize token classification data with label alignment.&quot;&quot;&quot;</span>
            <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tokens_column</span><span class="p">],</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span>
            <span class="p">)</span>

            <span class="c1"># Align labels with tokens</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tags_column</span><span class="p">]):</span>
                <span class="n">word_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">word_ids</span><span class="p">(</span><span class="n">batch_index</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
                <span class="n">label_ids</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">for</span> <span class="n">word_idx</span> <span class="ow">in</span> <span class="n">word_ids</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">word_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># Special tokens get -100</span>
                        <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">word_idx</span> <span class="o">!=</span> <span class="n">previous_word_idx</span><span class="p">:</span>
                        <span class="c1"># First token of a word gets the label</span>
                        <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">word_idx</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Other tokens of the same word get -100</span>
                        <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
                    <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="n">word_idx</span>

                <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

            <span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
            <span class="k">return</span> <span class="n">tokenized</span>

    <span class="c1"># Apply tokenization</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">tokenize_function</span><span class="p">,</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="o">=</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing train dataset&quot;</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">tokenize_function</span><span class="p">,</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="o">=</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span>
        <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Tokenizing eval dataset&quot;</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Dataset loaded - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dataset loaded - Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Eval: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_model" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_model</span><span class="p">()</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_model" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load model and tokenizer based on task type.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load model and tokenizer based on task type.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskType</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Load tokenizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
        <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Add padding token if missing</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>

    <span class="c1"># Ensure pad_token_id is set (required for data collator batching)</span>
    <span class="c1"># For Llama and similar tokenizers, we need to set it on both tokenizer and config</span>
    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>

    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># If pad_token was added, get its ID from the tokenizer</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">pad_token_id</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>  <span class="c1"># If it&#39;s the unk token, use eos instead</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># Fallback: use eos_token_id if available</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not get pad_token_id from tokenizer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Set pad_token_id on tokenizer (multiple ways to ensure it sticks)</span>
    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Set directly on tokenizer</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
        <span class="c1"># Also set on tokenizer&#39;s special_tokens_map if it exists</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;special_tokens_map&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="s1">&#39;pad_token&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">special_tokens_map</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">special_tokens_map</span><span class="p">[</span><span class="s1">&#39;pad_token&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span>
        <span class="c1"># Set on tokenizer config if it exists</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;init_kwargs&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39;pad_token_id&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">init_kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">init_kwargs</span><span class="p">[</span><span class="s1">&#39;pad_token_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pad_token_id</span>
        <span class="c1"># Also try setting via __setattr__ to ensure it persists</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="c1"># Final check: ensure pad_token_id is set (critical for batching)</span>
    <span class="n">final_pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">final_pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;pad_token_id is still None after setup! This will cause batching errors.&quot;</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_token_id must be set for batching. Tokenizer configuration issue.&quot;</span><span class="p">)</span>

    <span class="c1"># Determine precision and quantization settings</span>
    <span class="n">use_8bit</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch_dtype</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">device_map</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>  <span class="c1"># Keep on CPU initially</span>

    <span class="c1"># Check if precision is set and configure accordingly</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">:</span>
        <span class="n">precision_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">precision_value</span> <span class="o">==</span> <span class="s2">&quot;bf16&quot;</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">():</span>
            <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
        <span class="k">elif</span> <span class="n">precision_value</span> <span class="o">==</span> <span class="s2">&quot;fp16&quot;</span><span class="p">:</span>
            <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>

    <span class="c1"># For 4B+ models, use lower precision dtype to reduce memory</span>
    <span class="c1"># NOTE: 8-bit quantization (BitsAndBytes) requires PEFT adapters for fine-tuning</span>
    <span class="c1"># Since we&#39;re not using PEFT for classification, we skip 8-bit quantization</span>
    <span class="c1"># and rely on BF16/FP16 precision instead</span>
    <span class="n">model_size_estimate</span> <span class="o">=</span> <span class="s2">&quot;4B&quot;</span> <span class="k">if</span> <span class="s2">&quot;4B&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span> <span class="ow">or</span> <span class="s2">&quot;4b&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;unknown&quot;</span>
    <span class="n">use_8bit</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Disable 8-bit quantization for classification (requires PEFT)</span>
    <span class="n">quantization_config</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Ensure we use lower precision dtype for 4B models</span>
    <span class="k">if</span> <span class="n">torch_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="c1"># Default to BF16 if supported, else FP16</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">():</span>
            <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using BF16 precision for 4B model to reduce memory usage (8-bit quantization disabled - requires PEFT)&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using FP16 precision for 4B model to reduce memory usage (8-bit quantization disabled - requires PEFT)&quot;</span><span class="p">)</span>

    <span class="c1"># Load appropriate model based on task</span>
    <span class="c1"># Load on CPU first with appropriate precision/quantization to avoid OOM</span>
    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;num_labels&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="p">,</span>
        <span class="s2">&quot;ignore_mismatched_sizes&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;device_map&quot;</span><span class="p">:</span> <span class="n">device_map</span><span class="p">,</span>  <span class="c1"># Keep on CPU</span>
        <span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">torch_dtype</span> <span class="k">if</span> <span class="n">torch_dtype</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="p">}</span>

    <span class="c1"># Add quantization config if using 8-bit</span>
    <span class="k">if</span> <span class="n">use_8bit</span> <span class="ow">and</span> <span class="n">quantization_config</span><span class="p">:</span>
        <span class="n">model_kwargs</span><span class="p">[</span><span class="s2">&quot;quantization_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantization_config</span>

    <span class="c1"># Remove None values</span>
    <span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model_kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">}</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded AutoModelForSequenceClassification with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>  <span class="c1"># TOKEN_CLASSIFICATION</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded AutoModelForTokenClassification with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_labels</span><span class="si">}</span><span class="s2"> labels&quot;</span><span class="p">)</span>

    <span class="c1"># Ensure model stays on CPU (device_map should handle this, but double-check)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">use_8bit</span><span class="p">:</span>  <span class="c1"># 8-bit models handle device_map automatically</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Only move to CPU if not already there and not using device_map</span>
            <span class="n">current_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
            <span class="k">if</span> <span class="n">current_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model moved to CPU to avoid OOM during setup&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model already on CPU (via device_map)&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">move_error</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not verify/move model to CPU: </span><span class="si">{</span><span class="n">move_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Resize token embeddings if we added tokens</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>

    <span class="c1"># CRITICAL: Set pad_token_id on model config (required for DataCollatorWithPadding)</span>
    <span class="c1"># This is often the missing piece that causes &quot;Cannot handle batch sizes &gt; 1&quot; errors</span>
    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;config&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
        <span class="c1"># Also try setting on model.config if it&#39;s a dict-like object</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Set model.config.pad_token_id = </span><span class="si">{</span><span class="n">pad_token_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Enable gradient checkpointing to reduce memory usage (helps with OOM)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;gradient_checkpointing_enable&#39;</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Gradient checkpointing enabled to reduce memory usage&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not enable gradient checkpointing: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Apply PEFT (LoRA) if enabled</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">peft_enabled</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

        <span class="c1"># Get target modules from config or auto-detect</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">target_modules</span>
        <span class="k">if</span> <span class="n">target_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Auto-detect based on model architecture</span>
            <span class="k">if</span> <span class="s2">&quot;distilbert&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_lin&quot;</span><span class="p">,</span> <span class="s2">&quot;k_lin&quot;</span><span class="p">,</span> <span class="s2">&quot;v_lin&quot;</span><span class="p">,</span> <span class="s2">&quot;out_lin&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="s2">&quot;bert&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="s2">&quot;roberta&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;dense&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">]</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Auto-detected target modules: </span><span class="si">{</span><span class="n">target_modules</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Create PEFT config</span>
        <span class="n">peft_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
            <span class="n">r</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lora_rank</span><span class="p">,</span>
            <span class="n">lora_alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lora_alpha</span><span class="p">,</span>
            <span class="n">lora_dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lora_dropout</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
            <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;SEQ_CLS&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span> <span class="k">else</span> <span class="s2">&quot;TOKEN_CLS&quot;</span><span class="p">,</span>
            <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span>
        <span class="p">)</span>

        <span class="c1"># Apply PEFT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Model loaded successfully&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_training" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">setup_training</span><span class="p">()</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.setup_training" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Setup trainer with appropriate settings.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">setup_training</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Setup trainer with appropriate settings.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.sft.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskType</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Configuring trainer...&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Configuring trainer...&quot;</span><span class="p">)</span>

    <span class="c1"># Clear GPU cache before creating trainer to avoid OOM errors</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">cache_error</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not clear GPU cache: </span><span class="si">{</span><span class="n">cache_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Training arguments</span>
    <span class="c1"># For quick testing: use max_steps=10, then revert to full training</span>
    <span class="n">max_steps_for_testing</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Set to None for full training, or 10 for quick testing</span>
    <span class="n">training_args_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
        <span class="s2">&quot;run_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">run_name</span><span class="p">,</span>
        <span class="s2">&quot;per_device_train_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
        <span class="s2">&quot;per_device_eval_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">per_device_batch_size</span><span class="p">,</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
        <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
        <span class="s2">&quot;warmup_ratio&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">,</span>
        <span class="s2">&quot;eval_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="s2">&quot;eval_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">eval_interval</span><span class="p">,</span>
        <span class="s2">&quot;save_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="s2">&quot;save_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval</span><span class="p">,</span>
        <span class="s2">&quot;load_best_model_at_end&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">load_best_model_at_end</span><span class="p">,</span>
        <span class="s2">&quot;metric_for_best_model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">metric_for_best_model</span><span class="p">,</span>
        <span class="s2">&quot;greater_is_better&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">greater_is_better</span><span class="p">,</span>
        <span class="s2">&quot;logging_steps&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;logging_dir&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">/logs&quot;</span><span class="p">,</span>
        <span class="c1"># Use precision from model config, default to BF16 if CUDA supports it (for memory efficiency)</span>
        <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="ow">and</span> 
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;fp16&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;bf16&quot;</span><span class="p">:</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="ow">and</span> 
                <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">precision</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;bf16&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">)</span> <span class="k">else</span> 
                <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()),</span>  <span class="c1"># Auto-enable BF16 if supported</span>
        <span class="s2">&quot;report_to&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>  <span class="c1"># Disable wandb/tensorboard</span>
        <span class="s2">&quot;save_total_limit&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># Keep only 2 checkpoints</span>
        <span class="s2">&quot;push_to_hub&quot;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">}</span>

    <span class="c1"># Add gradient_accumulation_steps if specified in config (helps with OOM)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">training_args_dict</span><span class="p">[</span><span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
    <span class="c1"># Set either max_steps (for quick testing) or num_train_epochs (for full training)</span>
    <span class="c1"># Don&#39;t pass num_train_epochs at all when max_steps is set (TrainingArguments doesn&#39;t like both)</span>
    <span class="k">if</span> <span class="n">max_steps_for_testing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">training_args_dict</span><span class="p">[</span><span class="s2">&quot;max_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_steps_for_testing</span>
        <span class="c1"># Don&#39;t include num_train_epochs when max_steps is set</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">training_args_dict</span><span class="p">[</span><span class="s2">&quot;num_train_epochs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">epochs</span>
        <span class="c1"># Don&#39;t include max_steps when num_train_epochs is set</span>

    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">**</span><span class="n">training_args_dict</span><span class="p">)</span>

    <span class="c1"># Ensure pad_token_id is set before creating data collator (required for batching)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s1">&#39;pad_token&#39;</span><span class="p">:</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">})</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>  <span class="c1"># Make sure it&#39;s not the unk token</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Fallback: use eos_token_id if available</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="c1"># Fallback: use eos_token_id if available</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not set pad_token_id: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Final check: ensure pad_token_id is set (critical for batching)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;pad_token_id is still None before creating data collator! This will cause batching errors.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_token_id must be set for batching. Tokenizer configuration issue.&quot;</span><span class="p">)</span>

    <span class="c1"># Choose data collator based on task</span>
    <span class="c1"># Explicitly pass pad_token_id to ensure it&#39;s used</span>
    <span class="n">pad_token_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pad_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pad_token_id must be set before creating data collator&quot;</span><span class="p">)</span>

    <span class="c1"># Create a wrapper class to ensure pad_token_id is always set before batching</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">SafeDataCollatorWithPadding</span><span class="p">(</span><span class="n">DataCollatorWithPadding</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
            <span class="c1"># Ensure pad_token_id is set before batching (critical fix)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Try to set it from eos_token_id</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="c1"># If still None, try to get it from pad_token</span>
                    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">pad_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">pad_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_id</span>
                            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="k">except</span><span class="p">:</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="k">class</span><span class="w"> </span><span class="nc">SafeDataCollatorForTokenClassification</span><span class="p">(</span><span class="n">DataCollatorForTokenClassification</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
            <span class="c1"># Ensure pad_token_id is set before batching (critical fix)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;pad_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">pad_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">pad_id</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">unk_token_id</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_id</span>
                            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
                        <span class="k">except</span><span class="p">:</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s1">&#39;eos_token_id&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TEXT_CLASSIFICATION</span><span class="p">:</span>
        <span class="n">data_collator</span> <span class="o">=</span> <span class="n">SafeDataCollatorWithPadding</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span>  <span class="c1"># Optimize for tensor cores</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># TOKEN_CLASSIFICATION</span>
        <span class="n">data_collator</span> <span class="o">=</span> <span class="n">SafeDataCollatorForTokenClassification</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span>
        <span class="p">)</span>

    <span class="c1"># Compute metrics function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute classification metrics.&quot;&quot;&quot;</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># For token classification, flatten and filter</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">==</span> <span class="n">TaskType</span><span class="o">.</span><span class="n">TOKEN_CLASSIFICATION</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="c1"># Remove ignored indices (-100)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

        <span class="c1"># Calculate metrics</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">),</span>
            <span class="s1">&#39;f1&#39;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;precision&#39;</span><span class="p">:</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="c1"># Clear CUDA cache before creating trainer</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

    <span class="c1"># Create trainer with error handling for OOM</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">eval_dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
            <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
        <span class="p">)</span>

    <span class="k">except</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">oom_error</span><span class="p">:</span>
        <span class="c1"># Check if it&#39;s actually an OOM error</span>
        <span class="n">is_oom</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">oom_error</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;out of memory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">oom_error</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">is_oom</span><span class="p">:</span>
            <span class="c1"># Clear cache and try to provide helpful error message</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

            <span class="n">error_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory when creating trainer. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;This usually means other processes are using GPU memory. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Try: (1) Free GPU memory by stopping other processes, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(2) Reduce batch_size in config, (3) Use a smaller model. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Original error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">oom_error</span><span class="p">)[:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">oom_error</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Re-raise if it&#39;s not an OOM error</span>
            <span class="k">raise</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Trainer configured&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Trainer configured successfully&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="backends.trl.sft.Classification_trainer.ClassificationTrainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">()</span></code>

<a href="#backends.trl.sft.Classification_trainer.ClassificationTrainer.train" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Train the model.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/aligntune/backends/trl/sft/Classification_trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the model.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAINING&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_training</span><span class="p">()</span>

    <span class="c1"># Clear CUDA cache before training to avoid OOM</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Cleared CUDA cache before training&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;out of memory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;OOM&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CUDA OOM during training: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> CUDA Out of Memory error during training.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Suggestions:&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Reduce batch_size in your config&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Increase gradient_accumulation_steps to maintain effective batch size&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Reduce max_seq_length&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Use a smaller model&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Training completed&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training completed&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><p>options:
 show_source: true
 heading_level: 3</p>
<p><strong>Note:</strong> Only available for TRL backend.</p>
<hr />
<h2 id="usage-examples">Usage Examples<a class="headerlink" href="#usage-examples" title="Permanent link">&para;</a></h2>
<h3 id="sft-training">SFT Training<a class="headerlink" href="#sft-training" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.backend_factory</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_sft_trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_sft_trainer</span><span class="p">(</span>
 <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-3.2-3B-Instruct&quot;</span><span class="p">,</span>
 <span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;tatsu-lab/alpaca&quot;</span><span class="p">,</span>
 <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;trl&quot;</span>
<span class="p">)</span>

<span class="c1"># Train</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># Evaluate</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

<span class="c1"># Save</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

<span class="c1"># Predict</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s2">&quot;What is AI?&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="rl-training">RL Training<a class="headerlink" href="#rl-training" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">aligntune.core.backend_factory</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_rl_trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">create_rl_trainer</span><span class="p">(</span>
 <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;microsoft/DialoGPT-medium&quot;</span><span class="p">,</span>
 <span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;Anthropic/hh-rlhf&quot;</span><span class="p">,</span>
 <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;dpo&quot;</span><span class="p">,</span>
 <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;trl&quot;</span>
<span class="p">)</span>

<span class="c1"># Train</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># Evaluate</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

<span class="c1"># Save</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">()</span>

<span class="c1"># Push to Hub</span>
<span class="n">url</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;username/my-model&quot;</span><span class="p">)</span>
</code></pre></div>
<hr />
<h2 id="next-steps">Next Steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="../backend-factory/">Backend Factory</a> - Trainer creation functions</li>
<li><a href="../configuration/">Configuration Classes</a> - Configuration options</li>
<li><a href="../../user-guide/sft/">User Guide</a> - Usage guide</li>
</ul></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
                <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/python.min.js"></script>
                <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/yaml.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../.."</script>
    
    <script src="../../js/base.js"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
